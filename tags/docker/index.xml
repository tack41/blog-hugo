<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>docker on tack41&#39;s blog</title>
    <link>https://blog.tack41.net/tags/docker/</link>
    <description>Recent content in docker on tack41&#39;s blog</description>
    <image>
      <url>https://blog.tack41.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://blog.tack41.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 25 Jun 2022 00:00:00 +0900</lastBuildDate><atom:link href="https://blog.tack41.net/tags/docker/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DockerコンテナのMariaDBのメジャーバージョンアップ</title>
      <link>https://blog.tack41.net/posts/2022/06/25_01/</link>
      <pubDate>Sat, 25 Jun 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/06/25_01/</guid>
      <description>TL;DR Docker HubにあるMariaDBの公式イメージのメジャーバージョンアップを行う場合、環境変数MARIADB_AUTO_UPGRADEにnon-emptyな値に設定したほうがよい 経緯 Redmineで利用しているMariaDBのバージョンアップを行った。10.4.25から10.6.8に一気に上げた。
途中10.5.15を経由したのだが、その際に以下のメッセージが出たのが気になった。
redmine_db | 2022-06-25 05:16:20+00:00 [Note] [Entrypoint]: MariaDB upgrade (mysql_upgrade) required, but skipped due to $MARIADB_AUTO_UPGRADE setting Docker HubのMariaDB公式サイトを見に行くと確かに以下の記述がある。
Set MARIADB_AUTO_UPGRADE to a non-empty value to have the entrypoint check whether mysql_upgrade/mariadb-upgrade needs to run, and if so, run the upgrade before starting the MariaDB server. Before the upgrade, a backup of the system database is created in the top of the datadir with the name system_mysql_backup_*.</description>
    </item>
    
    <item>
      <title>DockerコンテナのZabbixからDockerホストの監視</title>
      <link>https://blog.tack41.net/posts/2021/07/02_01/</link>
      <pubDate>Fri, 02 Jul 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/07/02_01/</guid>
      <description>Ubuntu20.04で構築しているDocker環境にて
Dockerコンテナで構築したZabbix serverでDockerホストにzabbix agentをインストールして監視する場合、Zabbix serverの接続元IPがDocker内部IPになってしまう。既定ではDockerコンテナのIPは毎回変わるため、zabbic agent側でzabbix serverのIPを指定できない(configファイルに記載が必須)。
Dockerホスト1台で運用する環境であれば、内部IPを固定してしまえばよい。
当方では、2台でActive-Standbyで運用しており、自サーバがActiveの場合は内部IPでアクセスが来るが、Standbyの場合には(自サーバでないActiveサーバの)外部IPでアクセスが来るため、serverとして2つのIPを指定したい。
https://www.zabbix.com/forum/zabbix-help/379138-one-node-monitored-by-2-differents-zabbix-servers
によると、configのSERVER値に複数のIPをカンマ区切りで指定することもできるらしい。
一方で、SERVER値にはホスト名の指定もできるので、ホスト名に対するAレコードを複数登録して動作確認したところ、こちらも問題なく動作した。なお、PTRレコードは不要。
環境によっては、IP直指定よりもDNSの方がよいというところもあるだろう。</description>
    </item>
    
    <item>
      <title>ZabbixのDockerイメージバージョンアップ時にtimezoneエラー</title>
      <link>https://blog.tack41.net/posts/2020/10/21_01/</link>
      <pubDate>Wed, 21 Oct 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/10/21_01/</guid>
      <description>Dockerにて、本家のイメージを使って運用している。
4.0.22から4.0.24にアップしたところ、以下のエラーが出て監視画面が表示されなくなってしまった。
DateTime::__construct(): Invalid date.timezone value &amp;#39;&amp;#34;Asia/Tokyo&amp;#34;&amp;#39;, we selected the timezone &amp;#39;UTC&amp;#39; for now. よくよくみると、「Asia/Tokyo」の前後にダブルクォーテーションとシングルクォーテーションがついている。ひょっとしてと思い、Dockerで環境変数を指定している箇所
PHP_TZ=&amp;#34;Asia/Tokyo&amp;#34; をダブルクォーテーションなしで
PHP_TZ=Asia/Tokyo と修正したところ、無事表示されるようになった。</description>
    </item>
    
    <item>
      <title>サーバ台数1-2台でDocker or Kubernetes</title>
      <link>https://blog.tack41.net/posts/2020/08/03_01/</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/08/03_01/</guid>
      <description>私の勤めている会社では、サーバは全部で4台、そのうち3台はパッケージシステムやADが動作しているWindowsサーバでそのまま運用するだけ(過去に開発されて引き継いだAccessアプリはこの3台のWindows上で動作) 内製アプリは残りの1台でやりくりしています。とは言え利用者は限られているのでリソース的には余裕です。
Dockerで複数コンテナを立てて運用していましたが、Kubernetesが流行っていることも知っていたので是非導入したいと思い、チャレンジしていました。 結論としては、うちの規模では割りに合わない、Docker運用に戻すことにしました。
Dockerのメリットは
コンテナ化することで複数のサーバを独立に動作させることができる PublicなDockerイメージからDockerfileでイメージを構築する形にすれば、Dockerfileさえあればどの環境でも同じように動作させることができる docker-composeを利用すれば、コンテナ起動時の連携設定等も行える Kubernetesのメリットは、上記に加えて
同一イメージのコンテナを複数立てて負荷分散する設定を簡単に行える Blue-Greenデプロイのように既存の環境を維持したままのDeployが設定で簡単にできる あたりが一例としてあると思います。 一方でDockerに対するKubernetesのデメリットとして
DBの運用が難しい PVCを使えばできるようだが、壁は低くない 非Publicなコンテナを利用するのであれば、別途Registryサーバが必要 ネットワーク構成が複雑、外部に公開するためにまぁまぁの設定が必要 複数ノードで負荷分散を可能にするための抽象化だが、そこまでいらない場合にはつらい 現状では、内製アプリが死んでも即困る状況ではなく、気付いたらDockerコンテナを起動すれば良い程度の状況なので、Kubernetesで複数コンテナを分散運用する必要もなく&amp;hellip; ただDBだけは守る必要があるので、しっかりバックアップしてすぐに復旧できるようにしたい。となるとDockerでホストVolumeを使ってやるくらいがメンテしやすい。
このような理由でDockerに戻します。 その上で、DBのバックアップやリストアなどの手順をAnsibleでコード化しておく、あたりが今のインフラ規模ではベストだと判断しました。
Kuberetesのソリューションには、シングルで運用できるminikubeやmicrok8s,k3sなどのソリューションがあり簡単に始められますが、運用にあたっては同一コンテナの負荷分散が必要、のような必要性がないと難しいと思いました。お金をかけられるのであれば、EKSなどのマネージドサービスがベストだと思います。</description>
    </item>
    
    <item>
      <title>IaCの壁</title>
      <link>https://blog.tack41.net/posts/2020/07/12_01/</link>
      <pubDate>Sun, 12 Jul 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/07/12_01/</guid>
      <description>社内のLinuxサーバは極力Ansibleで状態を管理し、サービスはDockerコンテナで運用している(DB除く)。いわゆるIaC(Infrastracture as Code)を実践しているつもり。 これの何が嬉しいかというと、正直なところ個人的にコマンド一発で全てが出来上がるのが楽しい、というところが大きかったりする。ピタゴラスイッチ、ルーブ・ゴールドバーグ・マシンを見ているような爽快感、とでも言うのだろうか。
そんな感覚はない場合、紙の手順書をコードに置き換えるのは面倒と感じるのもわかる。何が面倒かと言えばコードには曖昧さが許されないことだと思う。手順書は曖昧に書いて「言わなくてもわかるよね」という雰囲気で終わらせることもできるが、コードは書いたようにしか動かない。コードに落とすためには対象のプログラム・システムの仕様を正確に理解しないといけないし、何をもって正常とするのか、それはどんなケースでも正常と言えるのか、突き詰めて考えないといけない。この辺りが利用する組織や文化によって大きな壁になるのだと思う。
ただ、慣れてしまえばむしろ誰かが決めた書式・ルールに従って手順書を書く手間、変更された際に保守する手間もなくなるし、手元の仮想化環境などで簡単に再現してテストできる、最高の環境になる。</description>
    </item>
    
    <item>
      <title>Kubernetesでコンテナ動作させる際の基本</title>
      <link>https://blog.tack41.net/posts/2020/07/09_01/</link>
      <pubDate>Thu, 09 Jul 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/07/09_01/</guid>
      <description>思い切ってKubernetesを構築、試験運用を始めました。Ubuntu Server 20.04のMicroK8sです。
docker-compose で動作するところは確認できていたので余裕かと思っていたのですが、はまってしまいました。
症状は、 CrashLoopBackOffで再起動が続く状態。これ当然まともにコンテナが起動せずに終了してしまっているからなんですが、手元の環境ではDockerfileとdocker-composeの合わせ技で奇跡的にうまく動作していたため、Kubernetes側の問題だろうとあれこれ調査して時間を浪費してしまいました。
KubernetesではDockerfileによるbuild済みのコンテナイメージを起動します。docker-composeに記載している処理は、Kubernetesのyamlに記載するか、Dockerfileに記載する必要があります。 が、Kubernetesのyamlに同じ内容を記述できるとは限らず、また記述できても同じ動作をするかはわかりません。ですので、極力Dockerfileに記載してdocker-compose.ymlはシンプルにとどめておいたほうがよさそうと感じました。
また、内部の名前解決用に使用しているDNSは、解決できないと8.8.8.8にforwardしてしまう。Kubernetesの外の社内サーバを名前で参照する場合には、dnsConfigなどの設定でforward先を変更する必要がある。
https://qiita.com/sugimount/items/1873d9d332a25f5b0167</description>
    </item>
    
    <item>
      <title>CIの導入について検討</title>
      <link>https://blog.tack41.net/posts/2018/08/27_02/</link>
      <pubDate>Mon, 27 Aug 2018 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/08/27_02/</guid>
      <description>一人で開発していても、テストやデプロイにミスが出る可能性はある。 CIの導入を検討した。
結論としては、CI用途のサーバーを別途導入することはしない。現在主に開発しているC#プロジェクトでは、CIにもWindowsが必要となる。ライセンス費用が必要だし、Dockerでお手軽に再構築できる環境としたいため。
やりたいことは以下の通り
リポジトリのPRコードのビルド テスト、結果通知、OKならmerge DBの構成情報に関して、リポジトリと実環境で差異がないかチェック 1,2点目はWindowsを避ける以上、不可能。開発時に自端末でテストを行い、PRのコメントに記載する運用で対応。 3点目は、毎日定時に実行する普通のバッチでなんとかなるレベル。
テストに関して、DBに関連するところは一切やっていない。面倒なので。 一方で内製アプリの殆どはDBのデータを持ってきてそのまま表示し、加工して更新する程度のものがほとんどのため、結果ほとんどテストがない状態。 本番環境に接続する際には専用のクラスを利用しているので、テスト環境用にも同様のクラスを作成し、テスト実行時にはそちらを利用してDB接続するようにしてテストを行うようにする。まずこちらが優先。
Dockerでdumpファイルから空のデータベースを作成するDockerfileを作成し、開発にすぐに利用できるようにする。
その上で、上記の運用で品質をさらに高めていく。</description>
    </item>
    
    <item>
      <title>Docker Container 起動失敗</title>
      <link>https://blog.tack41.net/posts/2018/08/27_01/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/08/27_01/</guid>
      <description>Docker Hostのスタートアップサービスにて、Docker ContainerをBuild, Upするスクリプトを実行しているのですが、以下のようなエラーが大量に発生してUpしていませんでした。
8月 26 03:07:44 sever-name dockerd-current[864]: time=&amp;#34;2018-08-26T03:07:44.615597202+09:00&amp;#34; level=error msg=&amp;#34;could not calculate checksum for \&amp;#34;fb1077f711d4fc436c0b6e115f8cdb0c871f46c818ec998efbf489df5e4a4de5\&amp;#34;, \&amp;#34;devmapper: Unknown device fb1077f711d4fc436c0b6e115f8cdb0c871f46c818ec998efbf489df5e4a4de5\&amp;#34;&amp;#34; ... 8月 26 03:07:44 server-name dockerd-current[864]: time=&amp;#34;2018-08-26T03:07:44.617971873+09:00&amp;#34; level=error msg=&amp;#34;migration failed for 866ae31005298fd6f1bb2944418eb34969b16ead2a18ed332fa011a311f3b4b2, err: open /var/lib/docker/graph/60e65a8e4030022260a4f84166814b2683e1cdfc9725a9c262e90ba9c5ae2332/json: no such file or directory&amp;#34; ... ログの内容を見ると、以下のissueと同じように見える。再起動前にDockerのバージョンが1.13.1-74 に上がったようだし&amp;hellip;
https://github.com/moby/moby/issues/20147
対処方法は記事からは判明せず。
スタートアップスクリプトを手動で実行したところ、普通にupしたので、docker containerが起動していなければスクリプトを再度実行するcronジョブを登録することで暫定対処した。</description>
    </item>
    
    <item>
      <title>CentOS7のDocker構築ではまったこと</title>
      <link>https://blog.tack41.net/posts/2018/08/16_01/</link>
      <pubDate>Thu, 16 Aug 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/08/16_01/</guid>
      <description>storage driverがdevice mapperの場合のディスク容量 device mapperの場合は、既定のディスク容量が10GBほどとなる。Oracle DatabaseのDockerコンテナをbuildするとこける。
storage driverを最初からoverlay2 にするための方法 インストール時にデバイスタイプにLVMを指定すると、Dockerのstorage dirverはdevice mapperになる。
https://docs.docker.com/storage/storagedriver/select-storage-driver/#supported-backing-filesystems
基本ディスクを選んで、xfsを選んでやる必要がある。
さらに、CentOS7 1511(minimal)の場合は上記の手順でもやはりdevice mapperが既定となる。overlayを使用するための設定がされていないためと想像される。
https://docs.docker.com/storage/storagedriver/overlayfs-driver/
CentOS7 1804(minimal)で基本ディスク(xfs)でインストールすれば、overlay2がstorage driverとして設定される。</description>
    </item>
    
    <item>
      <title>DockerのHostの設定変更のcontainerへの反映</title>
      <link>https://blog.tack41.net/posts/2018/01/21_02/</link>
      <pubDate>Sun, 21 Jan 2018 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/01/21_02/</guid>
      <description>Host側でのresolv.confを変更したのだが、containerには、docker-compose restartやstop -&amp;gt; startでは反映されない。 一度downしてからupする必要がある。</description>
    </item>
    
    <item>
      <title>Dockerでstorageにoverlayを使う際の注意事項(2016/2時点,CentOS7)</title>
      <link>https://blog.tack41.net/posts/2016/02/09_02/</link>
      <pubDate>Tue, 09 Feb 2016 02:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2016/02/09_02/</guid>
      <description>Dockerでstorage driverにoverlayを使ってはまったこと。
2016/2時点 CentOS7でのdocker(1.8.2)においては、コンテナのファイルが2GBを超えると、読み込めなくなるようだ。
mariadbにて、dumpファイルの取り込みまでは問題ないのだが、これを一旦停止し、再度立ち上げようとすると「27: File too large」というメッセージが出て起動できない。 ググってみたところ、どうもこのメッセージはMariaDBというよりもOSが出しているようだ。そのことに気づいてoverlayをdevicemapperに戻したところ、現象は発生しなくなった。
開発者サイドでも、まだoverlayは何が起こるかわからない、というスタンスらしいので、要注意。</description>
    </item>
    
    <item>
      <title>Dockerでのmysql利用時の注意</title>
      <link>https://blog.tack41.net/posts/2016/02/09_01/</link>
      <pubDate>Tue, 09 Feb 2016 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2016/02/09_01/</guid>
      <description>Dockerでmysqlを利用する際にはまったこと。
Dockerfile等で初期データを流し込みたい場合、mysqld_safeを「バックグラウンド」で起動しておいてmysqlコマンドで流しこみを行うのだが、
nohup mysqld_safe &amp;amp; mysql -u root &amp;lt; init.sql のように実行してしまうと、 mysqlサーバが起動する前にコマンドが帰ってきてしまうため2行目で「mysql.sockがない」という旨のエラーが返ってきてしまう。
このような場合、1行目の後に以下のようなループを噛ませるとうまく行くはず。(bashの場合)
nohup mysqld_safe &amp;amp; for {1..10}; do if [ -e /var/lib/mysql/mysql.sock ]; then break fi sleep 1 done </description>
    </item>
    
  </channel>
</rss>
