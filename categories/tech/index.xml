<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>tech on tack41&#39;s blog</title>
    <link>https://blog.tack41.net/categories/tech/</link>
    <description>Recent content in tech on tack41&#39;s blog</description>
    <image>
      <url>https://blog.tack41.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://blog.tack41.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 24 Jan 2023 00:00:00 +0900</lastBuildDate><atom:link href="https://blog.tack41.net/categories/tech/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Microsoftアカウントの種類</title>
      <link>https://blog.tack41.net/posts/2023/01/24_01/</link>
      <pubDate>Tue, 24 Jan 2023 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2023/01/24_01/</guid>
      <description>TL;DR Microsoftよりログインを求められるアカウントには「個人アカウント」と「組織アカウント」の2種類がある。どちらかしか利用できないサービスがあるので注意 経緯 職場では、クライアントは基本Windows10で構築していますが、自分のPCのみ先行してWindows11をインストールしています。
Windows 11のMicrosoftストアでAmazonアプリストアが使えるようになったため、使ってみようとしたところ、結構苦戦しました。
Amazonアプリストアが利用できるようになった当初は、私の環境ではMicrosoftアカウントでのログインが必須でした。当時、会社のドメインで個人と組織の2種類のアカウントを持っていて、どちらを使ってもダメという状況でした。その後いろいろ調べて以下のことが分かってきました。
Microsoftのサービスにログインするアカウントには2種類ある([Microsoftアカウント]と[職場または学校アカウント]の違い) 個人アカウント(Microsoftアカウント)&amp;hellip;個人が自身のメールアドレスで作成するアカウント。 組織アカウント(職場または学校アカウント)&amp;hellip;企業の管理者が作成するアカウント 以前は同一アカウント名で両者を別に作成できていたが、今は組織アカウントがある状態では個人アカウントは作成できない。 MS365はどちらのアカウント向けにもサービスがあるが、後述の通りどちらか一方しか対応しないものもある。 Windowsの設定で紐づけるアカウントについて OneDriveなどに連携するため、利用するMS365のアカウントを使う必要がある ADログインしている場合、個人アカウントを利用できない? 私の環境ではそのように見えましたが未検証です。 Microsoftストアのアカウントについて 少なくともWeb版においては、組織アカウントでは決済情報を登録できず、購入ができません。別途個人アカウントが必要です。 Visual Studioを購入する際に気づきました Windows内のMicrosoft Storeでは、Windowsのアカウントが職場アカウントである状態でMicrosoft Storeのアカウントを個人アカウントにしようとすると、いくら認証情報を入れても元に戻る現象が発生して処理が進みません。 WindowsとMicrosoft Storeで同じアカウントを利用する必要があるのかもしれません。 とてもややこしかったです。また忘れそうなので備忘のためにメモ。
なお、2023年1月現在、私の環境ではMicrosoftストアへのログインなしにAmazonストアアプリがインストールできました。</description>
    </item>
    
    <item>
      <title>Echo Budsの充電問題</title>
      <link>https://blog.tack41.net/posts/2022/12/02_01/</link>
      <pubDate>Fri, 02 Dec 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/12/02_01/</guid>
      <description>TL;DR Amazon Echo Budsはケースのバッテリーがなくなると操作不可。ケースのバッテリーはケースを開けた状態のLEDで判別 経緯 Amazon Echo Budsを利用して、すぐにバッテリーがなくなると思うことが多かった。前回使った際に接続先のスマホでは十分なバッテリー残量が表示されていた気がするのに、いざ使おうとケースから取り出すと、バッテリー切れのためかケースもイヤホンも反応しない。
さすがにおかしいと思い、スマホのAlexaアプリに接続したところ、イヤホンのバッテリーは十分だがケースのバッテリーがわずかだとわかった。おそらく、以下のような話と思われる。
イヤホンとは別にケースにもバッテリーがある ケースのバッテリーが切れると、イヤホンも操作できない 充電時には、まずイヤホン、次にケースが充電される 充電時にケースを閉じていると(普通そうだと思うが&amp;hellip;)、イヤホンの充電ができた時点で(充電OKを示す)緑色のランプが点灯する 2点目はあまりに残念。フォーラムで回答されていることから仕様なのだと思われる。他社のイヤホンをそれほど使ったことはないのだが、そういうものなのだろうか?
https://jp.amazonforum.com/s/question/0D56Q0000AKLLhdSQH
またそれと相まって4点目が罠。ケースも充電されたら緑になればよいと思うのだが、仕様としては蓋を閉じているときはイヤホン、開けたときはケースのバッテリーを示すということのよう。</description>
    </item>
    
    <item>
      <title>Windows 11 22H2更新後にHyper-Vゲストがネットワーク接続不可</title>
      <link>https://blog.tack41.net/posts/2022/10/21_01/</link>
      <pubDate>Fri, 21 Oct 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/10/21_01/</guid>
      <description>TL;DR Windows 11 22H2更新後にHyper-Vの外部ネットワークへの接続が不通に。仮想スイッチを新規作成して物理NICを新しい方に付け替えてVMに割り当てると解決した 経緯 Windows 11 22H2に更新しました。Windows Updateでは出てこなかったので、アップグレードアシスタントをダウンロードして手動で適用しました。
再起動せずに使用していたその日は問題なかったのですが、翌日、Hyper-Vのゲストがネットワークにつながらない&amp;hellip;ネットワークにつながっていると認識はしているが、他と一切通信できないのかDHCPでのIP取得ができない
ひとまず、ゲストOS上でNICの無効→有効、OSの再起動をしても状況変わらず。原因はOSの更新以外に思い当たらないため、「windows 22H2 Hyper-V Guest cannot connect」あたりでGoogle検索したところ、以下の記事を発見。
https://learn.microsoft.com/en-us/answers/questions/881974/windows-11-22h2-broke-custom-virtual-switches-in-h.html
6月の記事なのでもう解消している可能性はあるが、仮想スイッチが壊れて同様の症状が発生したとのことで、該当のゲストを別の仮想スイッチに割り当てて解消したとのこと。
問題のゲストは、External設定でホストの物理NICを割り当てた仮想スイッチを割り当てていました。新規にExternal仮想スイッチを作成して、問題の仮想スイッチはInternalに変更。ホストの物理NICを新規仮想スイッチに割り当ててゲストに割り当てたところ、ネットワークに接続できるようになりました。
まだまだ不具合があるのかもしれませんので、この辺のトラブルシューティングを楽しむぐらいでないと22H2はまだ早いのかも。</description>
    </item>
    
    <item>
      <title>FortigateのDNSは配下のサーバに設定しちゃダメ</title>
      <link>https://blog.tack41.net/posts/2022/10/13_01/</link>
      <pubDate>Thu, 13 Oct 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/10/13_01/</guid>
      <description>TL;DR FortigateのDNSに配下のサーバを設定しちゃダメ。Fortigate標準がよい。 経緯 Fortigateのファームウェアを6.2.xから6.4.xにバージョンアップしました。直後にインターネットに繋がらなくなってしまいました。
Fortigateはtransparenteモードで使っており、Fortigateを外すと解消するので原因がFortigateであることは特定できました。
調査すると、まず名前解決に失敗しているように見えました。ルータ配下にFortigateを経由してPCやサーバにつながる構成になっています。PPPoEでプロバイダに接続しているルータでは名前解決はできてました。YAMAHA RTXシリーズを利用しており、SSHでログインしてnslookupで確認できます。
ですが、社内に設置したWindowsのAD兼DNSサーバでは名前解決に失敗しています。FortigateのDNSはこのWindowsサーバを指定していたため同様に名前解決ができず、FortiCloudが参照できないと警告が出ていました。
そこで、DNS設定をFortigate標準のものに変えたところ、警告が解消され、他のPCでもインターネットに接続できるようになりました。
今回の現象に対する推測ですが、Fortigateのバージョンアップにより、FortiCloudから最新のデータを取得できるまで通信をブロックする動きだったのではないかと。FortiCloudと通信するためにDNSで名前解決しようとしたところ、参照するDNSサーバ(AD兼DNSのWindowsサーバ)がFortigateの配下にあるため通信出来なかったと思われます。
その後、FortigateのDNSをForigate標準にしたことで、事前設定されたForitigateのDNSサーバに通信する形となってブロックされずに通信でき、FortiCloudの設定が完了してブロックが解除されたのではないかとおもわれる。
Fortigateが参照するDNSを配下のサーバにすると、今回のように通信ブロックをきっかけにFortigate自身が動作不能となる恐れがあることがわかった。Fortigate標準の設定やGoogleの8.8.8.8など、インターネット側の信頼できるサーバを指定すべきということだろう。</description>
    </item>
    
    <item>
      <title>PlantUMLからMermaidに乗り換えられなかった</title>
      <link>https://blog.tack41.net/posts/2022/10/07_01/</link>
      <pubDate>Fri, 07 Oct 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/10/07_01/</guid>
      <description>TL;DR Mermaidは動作環境が多くて使いやすそうだが、まだまだPlantUMLでしかできないことも多い 経緯 開発資料の作成の際、クラス図をPlantUMLで書いている。正確には、PlantUMLのコードをgit管理しつつ、PlantUMLのサイトで画像に変換してからMarkdownで参照している。VScodeでライブプレビューしようとするとJavaのインストールが必要で面倒だし、GitHubで参照する際には画像にしないとだめ。
Mermaid形式だと、GitHubがMarkdown内での記述に対する表示に公式に対応していて、VSCodeでも拡張機能をインストールすればプレビューできる。
移行してみたが、断念。理由はクラス図におけるpackage/namespaceに対応していないため。開発はDDDを意識していて、Domain,Presentation,UseCase,Infrastructureといった層を開発言語(主にC#)のnamespace/packageに対応させている。
まあそれは管理のしやすさからだけだが、少なくともクラス図上ではそれぞれの層を含めて記述し、Presentation層からInfrastructure層を呼ぶようなルール違反がないことを確認できるようにしたい。だが、Mermaidではまだ対応していないよう。GitHubのmermaid-jsのIssuesを見ると、要望自体はあがっているようだが&amp;hellip;
https://github.com/mermaid-js/mermaid/issues/1052
開発文書は、Markdownで書いてGitHubで直接閲覧することが多くなってきているので、GitHubが対応してくれればローカルにJava入れるのもよいのだが、まだ時期尚早か。
Draw.io でも書けるが、お絵かきソフトなのでクラスの情報が見た目にしか残らず、抵抗感がある。</description>
    </item>
    
    <item>
      <title>Ansible変数未定義、または空の場合にfailさせる</title>
      <link>https://blog.tack41.net/posts/2022/09/30_01/</link>
      <pubDate>Fri, 30 Sep 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/09/30_01/</guid>
      <description>TL;DR Ansibleで複数の変数の存在チェック、文字列の場合は空のチェックをしたい場合は ansible.builtin.fail: msg: Varialbe &amp;#39;{{ item }}&amp;#39; is not defined or empty. when: &amp;gt; item is not defined or item is none or ( item is string and item | length == 0 ) loop: - &amp;#39;{{ var1 }}&amp;#39; - &amp;#39;{{ var2 }}&amp;#39; #nolog: true # Hide credencials, but suppress message. 経緯 Ansibleで引数が定義されていて、空でないかどうかチェックしたい。1個ずつやるのもだるいのでloopでまとめて。 以下でできるかと思ったのだが&amp;hellip;
ansible.builtin.fail: msg: Varialbe &amp;#39;{{ item }}&amp;#39; is not defined or empty. when: &amp;gt; item is not defined or item is none or item | length == 0 loop: - &amp;#39;{{ var1 }}&amp;#39; - &amp;#39;{{ var2 }}&amp;#39; これだと、変数に数字が設定されていると型がstringにはならず、lengthの実行でlen()メソッドがないと言われてこけてしまう。このため、以下のように型がstringかチェックしたうえでlengthチェックさせる。また、内容がパスワードなどを含む場合はno_log: trueとするとよい。ただしその場合エラー時のメッセージも簡略化されてどの変数でこけたのか、別途調査が必要となる。</description>
    </item>
    
    <item>
      <title>Ansibleで変数の存在チェック</title>
      <link>https://blog.tack41.net/posts/2022/09/29_01/</link>
      <pubDate>Thu, 29 Sep 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/09/29_01/</guid>
      <description>TL;DR Ansibleでvariableの存在チェックをしたい場合は when: &amp;gt; var1 is defined and var1 is not none and var1 | length &amp;gt; 0 経緯 Ansibleのwhenで変数が定義されていて値が存在していたら実行したいケースがありました。
まず注意しなければいけないのは、この評価はPythonではなく、Jinja2で実行されるということ。このため
when: &amp;gt; var1.length &amp;gt; 0 という表現は使えず
when: &amp;gt; var1 | length &amp;gt; 0 とする必要があります。同様に
when: &amp;gt; var1 is not None という表現は使えず(Jinja2エンジンではisはテストを指定するキーワードで、Noneというテストは存在しない。noneなら存在する)
when: &amp;gt; var 1 is not none と指定する必要がある。
最初は、
when: &amp;gt; var1 is defined and var1 | length &amp;gt; 0 くらいでやっていたのですが、変数は定義されているが値が未設定、という場合にvar1はNoneTypeという型になり、lengthが使えないため、最終的に
when: &amp;gt; var1 is defined and var1 is not none and var1 | length &amp;gt; 0 という書き方に落ち着きました。</description>
    </item>
    
    <item>
      <title>ChromebookでVisual Studio Code Server</title>
      <link>https://blog.tack41.net/posts/2022/09/27_04/</link>
      <pubDate>Tue, 27 Sep 2022 16:20:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/09/27_04/</guid>
      <description>TL;DR ChromebookでVScodeを使うのであればVisual Studio Code Serverが良いかも。 LinuxではなくChromeブラウザ上で動作するため、日本語変換の不安定さが解消されているように見える。 経緯 前の記事でChromebookのcrostiniによるLinux VMにインストールしたVS Codeの日本語変換の切り替えの不安定さに絶望していたのですが、以下の記事を見つけました。
【起動5秒】ChromebookでVSCodeを超快適に使う
上記記事はCoderという会社が開発、公開しているようでしたが、本家Microsoftのものに関する記事を見つけ、インストールしました。ひょっとしたら両者同じものなのかもしれませんが、調べきれていません。
VS Code Serverの使い方
記事にある通り、wget -O- https://aka.ms/install-vscode-server/setup.sh | shを実行してインストールし、code-server serve-localを実行して表示されるローカルホストのURLにアクセスするとVSCodeが起動しました。すごい!! 全画面表示すれば違いがほとんどわかりません。
現時点ではローカルホストへの接続のみ一般公開されているようですが、将来的には外部サーバで稼働してブラウザでリモートからアクセスして編集、といったことができるかもしれません。そうなると、バックグラウンド問題で開発作業と相性が悪いiPadにも日の目が当たるかもしれません。
バックエンド側は以前と同様Linux環境で動いているのですが、不安定な日本語切り替えを含むフロント部分がChromeOS側で動くため安定しており、今のところ快適です。</description>
    </item>
    
    <item>
      <title>Ansible Moleculeでテスト</title>
      <link>https://blog.tack41.net/posts/2022/09/27_03/</link>
      <pubDate>Tue, 27 Sep 2022 15:48:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/09/27_03/</guid>
      <description>TL;DR Ansible Moleculeでのテストの実装はコツがいる 経緯 Ansible MoleculeでAnsibleのroleをテストしたが、結構コツがいるようだったので、メモ。
まず、現時点(2022/9/27)で日本語で言及している記事自体が少ない。以下は参照にさせていただいた。
MoleculeでAnsibleのRoleをテストする - その１ Molecule 3を試す ポイントは以下。
以下の流れで行う(https://molecule.readthedocs.io/en/latest/getting-started.html#run-test-sequence-commands) molecule create (1.Dockerコンテナの生成、起動) molecule converge (2.対象ののロールの実行) molecule verify (3.テスト) molecule destroy molecule testで一連の動作をまとめて実行できるとの記載があるが、自分の環境ではverifyがされていないので利用していない 途中でコケたら、molecule loginでコンテナにログインして実際のコマンドを実行するなどして確認する 1.Dockerコンテナの生成、起動 molecule.ymlを設定する imageにてDockerコンテナのタグを指定する 例えばubuntu:22.04を指定した場合、python3がインストールされていないためにansibleの各種タスクが実行できずにコケる。また、sudoもインストールされていないため、該当のタスクがbecome: yesを指定しているとやはりコケる。対策としてcommandを指定する。 platforms: - name: instance image: ubuntu:22.04 command: - &amp;#34;apt update&amp;#34; - &amp;#34;apt install -y sudo python3&amp;#34; pre_build_image: true 2.対象ののロールの実行 converge.ymlを設定する&amp;hellip;が、通常初期値で問題ないはず。他のタスクも実行したい場合は修正が必要なのかも 3.テスト verify.ymlを設定する。 assertタグでうまくいけばTrueとなるよう設定する。ファイルの存在をチェックする場合は以下のような感じ - name: Register if file exists stat: path: &amp;#34;/path/to/file&amp;#34; register: path_to_file - name: Check if file exists ansible.</description>
    </item>
    
    <item>
      <title>MariaDB(MySQL)の設定ファイルは.cnf</title>
      <link>https://blog.tack41.net/posts/2022/09/27_02/</link>
      <pubDate>Tue, 27 Sep 2022 12:33:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/09/27_02/</guid>
      <description>TL;DR MySQL(MariaDB)の設定ファイルの拡張子は.cnf .confではだめ。includedirでもだめ。 経緯 サーバに直接インストールしていたZabbixを、Raspberry Pi4上のDockerコンテナに移行しました。以前x64上のDockerコンテナで稼働していたことがあるので構築はかんたんに済み、移行もOK。が、併せてZabbixのメジャーバージョンアップを行うとupgrade処理の途中でコケる。日本語を含むデータの変換で失敗している。
show variable like &#39;%char%&#39;を実行すると、system,clinentがlatinになってる&amp;hellip; 設定ファイルにはutf8mb4を設定しているのになぜか反映されない。
設定ファイルconf/custom.confを/etc/mysql/conf.dにマウントしていたのだが、VScodede拡張子を.cnfに変えるとVScode上でファイルの認識が変わり、コンテナを再起動すると文字コードが正しく認識された。
公式サイトを見ればわかる話ではあるのですが、htmlファイルを.html,.htmのどちらでも認識するのと同じ感覚で&amp;hellip;また、includedirに指定されたフォルダにおいていたので、読んでくれるだろうと思いこんでました。
この設定ファイルは以前Dockerコンテナで運用していた際に使用していたものでしたが、当時からバージョンアップがうまく行かない問題があり、これが原因だった可能性があります。
ちゃんと公式サイトを見ましょうというお話でした。</description>
    </item>
    
    <item>
      <title>Chromebook CM5500を買って後悔</title>
      <link>https://blog.tack41.net/posts/2022/09/27_01/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/09/27_01/</guid>
      <description>TL;DR Chromebook CM5500買って後悔してる Chrome内ですべて作業ができるなら、という判断基準はそのとおり。Linux環境でのCLIでの開発もヘビーにやると厳しい。 次買うなら、Windowsでテンキーなしモデルかな 経緯 メインパソコンとして、ASUS Chromebook Flip CM5 (CM5500)を買って使っています。もともとメインで使っていた中古のMacbook Airが基盤不良で修理代が高額となったため買い替えました。もう中古は懲り懲りということで新品でした。
検討ポイントは以下
Chromebook 今はやっているので、使ってみたい。Linux環境はあるようなので、Windows上のWSLと同様な感じで開発環境は整備できるはず それなりのスペック Chromebookには安価なモデルも多数ありますが、いくらOSが軽量とはいえ開発作業に師匠が出ると嫌なので、それなりのスペックのものを選びました AMD Ryzen 5 3500C/2.1GHz/4コア 8GBメモリ M.2 SSD 8GB Windowsの同スペックと比較すると、割高? 買ってしばらくはたまにしか使わず、まずまず使えるといった感じでした。
画面が360度回転し、タッチ対応のため、タブレットとしても使える その用途ではほとんど使ってないけど 外付けキーボードを利用する際に、テントモードであればモニタの近くで使えるのもよいです がっつり使うようになると、以下の点が気になりました。
キーボードの動作がおかしいことがある OS上は日本語キーボードとして認識しているはずなのに、VScodeで入力時にコロン、セミコロンあたりが英語キーボード入力となり、yaml,json入力時にイラッとします。 VScodeで、英数キーによるIME OFF, かなキーによるIME ONが動作せず、かな英数キーを押さないといけないことがあります 必ず発生するわけでもなく、発生してもしばらくすると何故か治るのも謎。 テンキーが邪魔 テンキーは使わないので不要なのですが、このサイズのノートパソコンだとどうしてもついてきてしまいます。EnterやBackspaceの押し間違いが発生してイラッとします。 モニターが光沢液晶 最大の誤算でした。大抵そこまで明るくないところで使うので問題ないのですが、明るい部屋で使う際にはかなりのストレスです。 非光沢シート調達中 非対応アプリ多数 Windows,Macは対応していて、Linuxはギリ対応していても、Chromebookには全然対応してない、ということはしょっちゅうです。rootとってごにょごにょすればできるかもしれないけど面倒だし、Linuxにインストールするにしても、毎回Linuxを起動してアプリ起動するのは面倒だし、アプリ間連携も全くできません とはいえ買ってしまったので、なんとか非光沢液晶シート、外付けキーボードで使い倒そうとは思っています。が、よほどのケースでない限り、他人にはおすすめできないですね。</description>
    </item>
    
    <item>
      <title>pythonでSeleniumを利用する際の注意事項</title>
      <link>https://blog.tack41.net/posts/2022/09/21_01/</link>
      <pubDate>Wed, 21 Sep 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/09/21_01/</guid>
      <description>TL;DR pythonのDockerコンテナでSeleniumを実行したスクレイピングで色々はまった。 経緯 とあるサイトにログインして表示される情報をcronで取得したいと思い、pythonのDockerコンテナを利用してChrome,ライブラリ等をインストールしてプログラムを作成した。結構はまったポイントがあったので備忘のため記録する。
オプションが必要 --headless: まぁ当然 --no-sandbox: 利用するDockerコンテナがrootで動くために必要 --disable-dev-shm-usage: /dev/shmの容量不足でクラッシュするのを防ぐために必要(https://stackoverflow.com/questions/53902507/unknown-error-session-deleted-because-of-page-crash-from-unknown-error-cannot) --user-agent=Mozilla...: 今回アクセスしたサイトでは、ユーザーエージェントを変えないとForbiddenが返ってきた XPathによるアクセスはやめた方がよい 階層が深いと何やってるのかわからなくなるし、調査するのも大変。 find_element(By.ID,&amp;quot;...&amp;quot;)を使う。IDあればID、なければクラス名とか、AタグであればLINK_TEXTとか 該当のターゲットだけで一位にならないのであれば、一位となる上位の要素を取得してそこからfind_elementするとか 画面の描画をsleepで待つのはやめた方がよい 対象の要素があれば、以下のように取得する from selenium.webdriver.support.wait import WebDriverWait ele_email: WebElement = WebDriverWait(driver, timeout=TIMEOUT_PAGE_LOAD).until( lambda d: d.find_element(By.NAME,&amp;#34;some_name&amp;#34;)) 画面の描画完了待ちであれば、以下のように記述する WebDriverWait(driver, TIMEOUT_PAGE_LOAD).until( lambda d: d.execute_script(&amp;#39;return document.readyState&amp;#39;) == &amp;#39;complete&amp;#39;) sourceを確認しながら1画面ずつ進める 処理が進んでたと思ったらエラーページでした、だとつらいので。 logger.debug(driver.page_source) </description>
    </item>
    
    <item>
      <title>python3 メール送信時に本文なしだと弾かれる</title>
      <link>https://blog.tack41.net/posts/2022/09/12_01/</link>
      <pubDate>Mon, 12 Sep 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/09/12_01/</guid>
      <description>TL;DR python3(3.7.3)環境でMIMETextを使ってメール本文を作成する場合に、メールが送信されない → 本文を追加 or 件名変更でなぜか解決&amp;hellip; 経緯 python3(3.7.3)の環境で、Pythonによるスクリプトの実行結果をメール通知している。あるメールアドレスに集約しているのだが、一部のメールが届かない。
そのホストから送信している別の件名のメールは届いている 通知メールは本文空文字でMIMETextで作成している 本文に適当な文字を入れると届く、空白ではだめ 件名を変えると届く 送信ホストのメールログを見ると、送信処理自体は正常終了している。 件名の変更、または本文の追加で解消されることから、利用しているメールサーバによるウィルスチェックに引っかかったのではないかと推測しているが、詳細は非公開のため不明。
メール本文は何か設定しておいた方が無難ということか。</description>
    </item>
    
    <item>
      <title>sudoでNOPASSWD設定しても反映されない場合は最終行に</title>
      <link>https://blog.tack41.net/posts/2022/08/30_01/</link>
      <pubDate>Tue, 30 Aug 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/08/30_01/</guid>
      <description>TL;DR sudoでNOPASSWD設定しても有効にならない場合は、最終行に記述するとうまくいく。なぜ&amp;hellip; 経緯 sudo時に毎回パスワードを入力するのが手間なため、visudoコマンドでNOPASSWDを設定してもなぜか反映されない。 ユーザー名がt-tack41のようにハイフンが含まれているのだが、vimのシンタックスハイライトでハイフンの前のtまでしかユーザー名として認識されていないように見えたため、ダブルクォーテーション、シングルクォーテーションで囲ったり、ハイフンの前にバックスラッシュでエスケープしてもダメ。
&amp;quot;t-tack41&amp;quot; &#39;t-tack41&#39; t\-tack41 &amp;quot;t\-tack41&amp;quot; そこで色々調べている最中にhilotter氏のブログ記事を発見。
sudoでNOPASSWD設定しても反映されない現象に遭遇
この記事は2015年7月の記事で、この記事自身も馬場氏の2010年1月のブログ記事 sudoでNOPASSWDが効かない時の対応方法にある内容を実行したらなぜか直ったとある。
その方法は、NOPASSWDの設定行を設定ファイルの一番後ろに書けばよいということ。理由に関する記載はない。
いや、まさかね～、そんな古い記事だし、そんな理由で直るわけが&amp;hellip;. と思ってやってみたら見事に直った!!!
その後、上記記事のタイトルなどでググると同様の記事が多数あり、その中のteratailの記事で原因が判明。sudoersの設定は最終行に近い方が優先されるので、所属するグループでパスワードを有効にしない設定が下にあればそちらが優先されてしまうとのこと。
sudo をパスワードなしで実行できるようにしたい
実際、今回記載した下の方にグループに対するパスワード有効の設定があったため、そのグループから抜けたうえで再度試したところパスワードなしの設定が有効になった。ユーザー名のハイフンは関係なかったです。</description>
    </item>
    
    <item>
      <title>Hugo PaperModにDisqusコメント機能を追加</title>
      <link>https://blog.tack41.net/posts/2022/08/15_01/</link>
      <pubDate>Mon, 15 Aug 2022 07:37:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/08/15_01/</guid>
      <description>TL;DR Hugo PaperModeテーマにDisqusによるコメント機能を追加するには以下を実施する。画面に反映されるまで数分かかる? config.yml 以下を追加 ... disqusShortname: blog-hugo-tack41 ... params: ... comments: true ... layouts/partials/comments.htmlを以下の内容で作成 {{ template &amp;#34;_internal/disqus.html&amp;#34; . }} 経緯 ブログは、過去に書いてきたものも含めてこのHugo(PaperModテーマ)に移行している。
過去のブログは、コメントがあるものもあるのでそのまま残しているのだが、一部いまだにコメントを頂けるものがある。
コメントがあると、見てもらえているという実感がわき、やる気が出る。ということで本ブログも遅まきながらコメント機能を追加した。
利用したのはDisqusのBasicプラン。Disqus側の設定方法は各種サイトにあるのだが、本ブログで利用しているHugo](https://gohugo.io/)のPaperModテーマに対するものがなく、手間取った。
検索してヒットした、同様の設定をしているDavid Spencerさんのサイトの設定をもとに以下を修正したところ、動作した。デプロイ直後では動作せず、数分してリロードしてから動作した。
まずconfig.ymlに以下の設定を追加
... disqusShortname: blog-hugo-tack41 ... params: ... comments: true ... 次にlayouts/partials/comments.htmlを以下の内容で作成する
{{ template &amp;#34;_internal/disqus.html&amp;#34; . }} </description>
    </item>
    
    <item>
      <title>Accessでグラフ</title>
      <link>https://blog.tack41.net/posts/2022/07/30_02/</link>
      <pubDate>Sat, 30 Jul 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/07/30_02/</guid>
      <description>TL;DR AccessのグラフはModernとClassicの2種類。細かい要件は無くて手っ取り早くきれいなグラフを作るならModern、調整が必要な場合はClassic。(Classicならどんなグラフも可能とは言ってない) 経緯 Accessでグラフを作ることになり調査。最新のMS365のAccessでは、ModernとClassicの2つがあることが分かった。
Modernは、今どきのおしゃれな感じのグラフがパッとできる。が、マーカーのサイズを調整したりとか、凡例の位置を微調整したりとか、細かいところができない。
一方Classicは、見た目は古臭くて野暮ったいが、かなり細かい調整ができる。
MicrosoftとしてはModernを売っていきたいのだろが、Classic出ないとできないことがまだ結構ある印象。それでも長期的にはModernに統一される可能性はあるので、Modernで十分な場合は採用し、そうでない場合のみClassicとするのがよいだろう。</description>
    </item>
    
    <item>
      <title>Growiで相対リンク</title>
      <link>https://blog.tack41.net/posts/2022/07/30_01/</link>
      <pubDate>Sat, 30 Jul 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/07/30_01/</guid>
      <description>TL;DR GROWIで相対リンクを記述する際はPukiwiki like linkerを使おう リンクは[[こちら&amp;gt;./link_to_page]] 経緯 社内のマニュアル等の共有にGROWIを利用している。日本語の全文検索ができ、Markdownの記述ができるので過去のGitBook形式からの移行が容易というのがポイントだった。
が、文書間の相対リンクがうまくいかない。例えば、/manuals/topページにて/manuals/top/system-Aへのリンクを張りたい場合、自分のパスも含めて以下のように記載する必要がある。
[System-Aのマニュアル](./top/system-A) いまいちだなぁと思いつつ、仕様とあきらめて利用していた。ところが、最新バージョン5.0がリリースされ、これまでパス形式のリンクが既定のところがID形式に変更された。
この結果、/manuals/topにアクセスした際にブラウザに表示されるURLが、バージョンアップ前は
https://docs.example.com/manuals/top と表示されているところが
https://docs.example.com/62b3acabcd2f9c94de9c3b20f のようなID表示となってしまった。すると上記の相対リンクは
https://docs.example.com/top/system-A へのリンクと解釈され、文書が存在しないと表示されてしまう&amp;hellip;
で、本家のLinkの貼り方に関する説明を確認し、方法は3種類あり、Pukiwiki like linkerがもっとも柔軟性があるとのことだったので試したところ、特に何もインストールせずに利用でき、自分のパスを含めずに相対パスを作成することができた
[[System-Aのマニュアル&amp;gt;./system-A]] ただ、当然GitBookとの互換性はなくなる。
今回は互換性よりも相対パスを記載できないことによる文書構造の硬直化がイヤだったのでPukiwiki like linkerを採用した。
Markdown標準方式でも同様の記述ができるようになるとよいのだが。
[2022.8.16追記]
Slackにて不具合委報告したところ、5.1.1より修正されました。</description>
    </item>
    
    <item>
      <title>Raspbian 11でapt経由でzabbixを利用する際はnginx利用不可</title>
      <link>https://blog.tack41.net/posts/2022/06/28_01/</link>
      <pubDate>Tue, 28 Jun 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/06/28_01/</guid>
      <description>TL;DR Raspbian 11でapt経由でzabbix6をインストールする場合、nginxは事実上利用できずapache2を利用することになる。 zabbix-nginx-confパッケージをインストールするとなぜかapache2がインストールされてしまう。 経緯 Raspberry Pi 4(8GB)にRaspbian OS 11 Liteをインストールしてzabbixサーバを構築しようとした。リポジトリを追加するためのパッケージは以下
https://repo.zabbix.com/zabbix/6.0/raspbian/pool/main/z/zabbix-release/zabbix-release_6.0-3+debian11_all.deb
Raspbian 10の時と同じ手順で進める。Webサーバはnginx。設定は問題なく完了するのだが、Webを見に行くと、Apache2の既定のメッセージが出てしまう。
実際、サービスを確認するとnginxのほかにapahce2が起動しており、apache2はポートをbindできずにエラーとなっている。
が、途中でapache2を入れた記憶はない。よくよく調べていくとdpkg rdepends zabbix-nginx-confでなぜかapache2をインストールしているっぽい。nginxはインストールしないのに。
明らかな不具合だと思い、forumに報告。ひとまずはapache2で構築した。</description>
    </item>
    
    <item>
      <title>DockerコンテナのMariaDBのメジャーバージョンアップ</title>
      <link>https://blog.tack41.net/posts/2022/06/25_01/</link>
      <pubDate>Sat, 25 Jun 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/06/25_01/</guid>
      <description>TL;DR Docker HubにあるMariaDBの公式イメージのメジャーバージョンアップを行う場合、環境変数MARIADB_AUTO_UPGRADEにnon-emptyな値に設定したほうがよい 経緯 Redmineで利用しているMariaDBのバージョンアップを行った。10.4.25から10.6.8に一気に上げた。
途中10.5.15を経由したのだが、その際に以下のメッセージが出たのが気になった。
redmine_db | 2022-06-25 05:16:20+00:00 [Note] [Entrypoint]: MariaDB upgrade (mysql_upgrade) required, but skipped due to $MARIADB_AUTO_UPGRADE setting Docker HubのMariaDB公式サイトを見に行くと確かに以下の記述がある。
Set MARIADB_AUTO_UPGRADE to a non-empty value to have the entrypoint check whether mysql_upgrade/mariadb-upgrade needs to run, and if so, run the upgrade before starting the MariaDB server. Before the upgrade, a backup of the system database is created in the top of the datadir with the name system_mysql_backup_*.</description>
    </item>
    
    <item>
      <title>Apple Business ManagerによるApple製品の管理</title>
      <link>https://blog.tack41.net/posts/2022/05/19_01/</link>
      <pubDate>Thu, 19 May 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/05/19_01/</guid>
      <description>TL;DR 一度Apple Business Manager(ABM)管理外で作成したアカウントと同じアカウントは作成できない。削除してしばらく立っていてもダメ。新規アカウントであることが前提。 Apple Business Manager(ABM)で管理をするなら、ABMに対応するMDM(Mobile Device Management)は必須 ABM管理下のアカウントはアプリを追加できないのが最大のネック。App Storeのアカウントのみ個人アカウントとすれば逃げられるが&amp;hellip; ABMで管理するデバイスは、購入時に申請してABMに追加してもらうのがベスト あとで追加もできるが、結構大変 デバイスは初期化される 経緯 Apple Business Manager(ABM)のアカウントが取得できたため、これを利用していろいろ試してみた。現状は以下の通り
iPhoneは全営業、iPadは一部営業に配布済み ABM配下でない、個別に作ったApple IDを利用 MDMは一部iPhoneのみ導入済み ABMの画面を見て、MDMがなくてもアプリの配布くらいはできて、Apple Configuratorで作成したプロファイルの配布くらいはできるだろうと思っていた。
なので、MDM配下でない既存のデバイスに対しても設定やアプリの配布もできると考えていた&amp;hellip;
まず、個別に作ったApple IDをABM管理下に移行できないかとためした。が、やってみた限り、できない。また、個別に作ったアカウントを削除し、2-3ヶ月立った状態で同じアカウントを作ってもNG。すでに他で利用されている旨のメッセージが表示される。
ABMでのアカウントは、これまでに作っていない新規アカウントが前提となることがわかった。
上記を踏まえ、新規という前提でApple IDの作成は簡単にできた。作ったIDでiPadにログインし、App Storeで何もできないことも確認できた。
また、App Storeのアカウントを個人アカウントにすることでAppStoreから自由にインストールできることも確認できた。おそらく、ABMでデバイス登録ができていないため、制限がゆるいのだと思われる。
既存のデバイスをABMに登録するには、MacにデバイスをUSBケーブルで接続し、Apple Configuratorで該当のデバイスを「準備」する必要がある。これが以下の点で大変だった。
https://support.apple.com/ja-jp/guide/apple-business-manager/axm200a54d59/web
デバイスは初期化される。 対象のデバイスはWiFiに接続されていないとネットワークエラーとなる。初期化された状態のまま処理してもダメ。Wi-Fi接続までは済ませておく必要がある。 処理の途中で再起動が行われた場合、再起動後にWiFiの情報がクリアされていた場合は、すばやく登録する必要がある これが遅れるとやはりネットワークエラーとなる 上記をクリアしても、最終的にエラーで処理が完了しない が、ABM上ではデバイスが登録されている。 上記を経てわかったのは、デバイスをABM上で登録できたとしても、ABMでアプリをデバイスに割り当てることはできない。それはMDMの仕事ということらしい&amp;hellip;ABMでできるのは必要なライセンスの確保(有料アプリの場合は支払)のみ。
今後は以下の方針で行こうと考えている。
デバイス新規購入時は、ABMにデバイス登録するよう代理店に申請し、MDMも合わせて登録する ABMのデバイス登録とMDM利用はセットで考える 協力をもらえる人に関しては、ABM管理外のIDをABM管理下に移行してもらう 一から設定が必要となるため、望み薄か&amp;hellip; 新入社員等で新規にApple IDを作成する場合は、ABMで作成してデバイスをMDM管理にする 既存のデバイスの手動登録は大変だが、なんとかやってみる 上記ケース以外では何もしない、そのまま </description>
    </item>
    
    <item>
      <title>ChromeOSのclipboardの履歴はcrostiniで使えない</title>
      <link>https://blog.tack41.net/posts/2022/04/28_01/</link>
      <pubDate>Thu, 28 Apr 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/04/28_01/</guid>
      <description>ChromeOSでは、 [search + v] というショートカットで過去にclipboardにコピーされた内容を5件まで表示し、選択してペーストできる機能があります。が、これ、crostini環境のterminalやvscodeには貼り付けられません。一覧表示まではできるのですが、選択しても貼り付けられないのです。
通常の[ctrl + v]で直近の内容のペーストはできるので、同じ対応が上記コピー履歴からの貼り付けまでは対応していないようです。残念です。</description>
    </item>
    
    <item>
      <title>Azure ADをIdPとしたGoogle WorkspaceのSSO設定</title>
      <link>https://blog.tack41.net/posts/2022/04/04_02/</link>
      <pubDate>Mon, 04 Apr 2022 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/04/04_02/</guid>
      <description>TL;DR 公開されている手順通りには行かないなぁ 経緯 Google Cloud Identity Freeで作成したWorkspaceのアカウントに対し、Azure ADをIdPとしたSSO設定を行いました。故あって2回行いましたが、2回とも試行錯誤したので今後のためにメモ
Azure ADにて[Enterprise Application]-&amp;gt;[New Application]より「Google Cloud / G Suite Connector by Microsoft」を追加 [Manage]-[Single sign-on]より、[Basic configuration]-[Edit]をクリック 以下のとおり入力して保存する(ドメイン名を「example.com」とする) Identifier (Entity ID) google.com/a/example.com https://google.com/a/example.com https://google.com google.com Reply URL (Assertion Consumer Service URL) https://google.com/a/example.com https://www.google.com/ (Default) Sign on URL https://www.google.com/a/example.com/ServiceLogin?continue=https://console.cloud.google.com [Attributes &amp;amp; Claims]-[Edit]をクリック [Additional claims]を4つとも削除する [SAML Signing Certificate]より「Certificate (Base64)」(※1)をダウンロード [Set up Google Cloud / G Suite Connector by Microsoft]のLogin URLの内容をコピー [Manage]-[Users and groups]にてSSO対象とするユーザーアカウントを登録 Google Adminにログインし、[Security]-[Authentication]-[SSO with third party IdP]をクリック [Thirt-party SSO profile for your organization]の編集アイコンをクリックし、以下のように設定して保存する Set up SSO with third-party identity provider: ON Sign-in URL: (※2を貼り付け) Sign-out URL: https://login.</description>
    </item>
    
    <item>
      <title>RedmineのDBをPostgreSQLからMariaDBに移行</title>
      <link>https://blog.tack41.net/posts/2022/04/04_01/</link>
      <pubDate>Mon, 04 Apr 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/04/04_01/</guid>
      <description>TL;DR クラウドの設定変更には時間がかかる場合があります。設定変更が反映されることを前提に後続の作業を行う場合は、最低でも2日待って後続の作業をしたほうが良いです。 経緯 Google Cloud Identity FreeでWorkspaceと最初の管理者アカウント(ここではuser@example.comとする)を作成しました。次にadmin@example.comアカウントを作成し、Super Admin権限を付与しました。さらに最初に作成したuser@example.comのSuper Admin権限を削除しました。user@example.comアカウントのSuper Admin権限をadmin@example.comに移動した形です。
次に、Azure ADをIdPとしたSSOを行いました。user@example.comアカウントでうまくログインできないため、Google側の設定を見ようと思い、admin.google.comにadmin@example.comでログインしようとすると、SSO先のAzureログイン画面に転送されてしまい、ログインできません。当然user@example.comも同様です。つみました&amp;hellip;
最初、SSOの設定は既定で全アカウントに適用されるのかと思いました。が、だとしたらこのような事例が頻発するはずで、実際Googleのドキュメントを見ると、管理者アカウントはSSOから除外されるとありました。
となると、最初に行った管理者権限の移動が反映されていない可能性がありそう。権限を移動してから12時間程度だったため、クラウドの設定は1日¥見ておいたほうが良いとするとありうる話。念のためサポートから問い合わせを入れましたが無料での利用のため、期待薄。
設定から27時間たったあたりで再度admin.google.comにログインしようとすると、SSOに転送されずにろぐいんできました。
クラウドの設定変更は最大1日程度、とは聞いていましたがたいてい遅くとも1時間以内には反映されるため甘く見て失敗しました。設定の反映が遅延されることを考慮し、遅延するとうまく行かない後続の作業は2日は開けて作業したほうが良さそうです。</description>
    </item>
    
    <item>
      <title>RedmineのDBをPostgreSQLからMariaDBに移行</title>
      <link>https://blog.tack41.net/posts/2022/04/01_01/</link>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/04/01_01/</guid>
      <description>TL;DR Redmine 4.2.5にて、yaml_dbを利用することでPostgreSQL(14.2)からMariaDB(10.4.24)に移行できました 経緯 GCPのVMの無料枠(e2-small,Mem:1GB,HDD:30GB)で以下のDockerコンテナクラスタ(docker-compose)でredmineを運用しています。
redmine: 4.2.5-alpihne postgres: 14.2-alpine steveltn/https-portal: 1.21.1 環境が激poorなこともありますが、たまにアクセスするとページが表示されるまで10秒近く待たされることも。そこで、より軽量と思われるMySQL系のMariaDB(10.4.24)に移行しました。パフォーマンスが改善されたかどうかは、現在様子見です。
以下の手順を踏みました。
コンテナクラスタを停止 docker-compose.ymlにMariaDBコンテナを追加し、redmineコンテナから接続できるようnetwork設定し、rootた上で起動 docker-compose execコマンドでredmineコンテナに接続 apk-add mariadb-clientを実行してクライアントツールをインストール /usr/src/redmine/config/database.ymlのバックアップを取得した上で、記述をMariaDBに接続できるよう(adapterはmysql2) mysqlコマンドでMariaDBコンテナに接続し、Install Redmineの手順を参考にDBを作成 Install Redmine](https://www.redmine.org/projects/redmine/wiki/redmineinstall)の手順を参考にrake db:migrateでDBを初期化 /usr/src/redmine/Gemfileにgem &amp;quot;yaml_db&amp;quot;の記述を追加してgem bundle updateを実行。エラーとなるが、途中yaml_dbのインストールが成功していればOK /usr/src/redmine/config/database.ymlを更にバックアップした上で、前にバックアップしていたPostgreSQL用の設定に戻してRAILS_ENV=production bundle exec rake db:data:dumpを実行。/usr/src/redmine/db/data.ymlにバックアップが作成される /usr/src/redmine/config/database.ymlをMariaDBの設定に戻し、RAILS_ENV=production bundle exec rake db:data:loadを実行。 mysqlコマンドでMariaDBコンテナに接続し、データがリストアされていることを確認 docker-compose.ymlのPostgreSQLコンテナの記述を削除し、redmineコンテナからMariaDBコンテナに接続するよう設定を修正した上で起動。 参考サイト: https://hnron.hatenablog.com/entry/2015/08/18/012738</description>
    </item>
    
    <item>
      <title>アルファメールプレミアでDBバックアップ</title>
      <link>https://blog.tack41.net/posts/2022/03/26_01/</link>
      <pubDate>Sat, 26 Mar 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/03/26_01/</guid>
      <description>TL;DR アルファメール(プレミア)ではshellの直接実行はできない。が、phpのexecを利用すればほぼ同じことができます。 経緯 自社のWEBサイトを大塚商会のアルファメールプレミアでMovable Typeを利用して運用しています。バックアップに関して、コンテンツファイルはFTP(over TLS)でCLIで取得できますが、DBに関してはphpMyAdminを利用してブラウザからボタンポチポチで取得していました。
WEBコンソールのメニューの中に「cron設定」という項目があるのに気づいて調べたところ、拡張子が「.cgi」または「.php」のファイルの一覧から選んで指定時刻に実行してくれるということのようでした。
こういうバッチ的な利用が可能なのであれば、execでOSコマンドも実行できるのでは、と思ってmysqldump叩いてみたところ実行できました。これはありがたいということで、AWS SDK for PHPのpackaged phar版をダウンロードしてS3へのアップロードまでできました。
注意事項として、認証情報をファイルから取得する場合、そのファイルを含むパスに認証をかけないと危険です。
定期的に実行したいというより、サイトを更新したときに実行できれば良いので、ブラウザで該当のphpファイルを直接呼び出しています。
phpMyAdminから手動でダウンロードしてS3にアップというのは地味に面倒なので、ブラウザ呼び出し一発でできるようになって工数削減できました。</description>
    </item>
    
    <item>
      <title>Active Directoryでログイン時にPowershell経由でexeを実行</title>
      <link>https://blog.tack41.net/posts/2022/03/23_01/</link>
      <pubDate>Wed, 23 Mar 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/03/23_01/</guid>
      <description>TL;DR Active Directoryでログイン時にexeファイルを実行する場合はStart-Processでの実行が必要 経緯 Emotetが流行っているので、EmocheckをActive Directory のログインスクリプトに仕込んでみていた。
単体では実行できるので問題ないと考えていたが、どうもActive Directory のグループポリシーでログイン時に起動する設定をすると何故か実行されない。イベントログを見ると一応対象として認識されているのだが&amp;hellip;
Powershell から外部ファイルを実行するにはいくつか方法があるが、以下のように実行するとダメなようだった。
$proc = New-Object &amp;#34;System.Diagnostics.Process&amp;#34; $psi = New-Object &amp;#34;System.Diagnostics.ProcessStartInfo&amp;#34; $psi.FileName = $emocheck_Exe $psi.Arguments = &amp;#34;-output $reportDir -quiet -json&amp;#34; $psi.CreateNoWindow = $true; $psi.UseShellExecute = $false $psi.WindowStyle = [System.Diagnostics.ProcessWindowStyle]::Hidden $proc.StartInfo = $psi $proc.Start() 以下のように設定することでログイン時に実行されるようになった。
Start-Process -WindowStyle Hidden -FilePath $emocheck_Exe -ArgumentList &amp;#34;-output $reportDir -quiet -json&amp;#34; -WorkingDirectory $currentDir </description>
    </item>
    
    <item>
      <title>Google Cloud Identity FreeでChromebook運用時の注意点</title>
      <link>https://blog.tack41.net/posts/2022/01/06_01/</link>
      <pubDate>Thu, 06 Jan 2022 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2022/01/06_01/</guid>
      <description>TL;DR 物理的な質感はFire TVよりよい。 機能的にはちょい劣る 素のChromecast(with Google TVじゃない方)とは完全に上位互換 Googleへのこだわりがなく、Amazon Primeの機能を利用するのであればFire TVが無難か 経緯 現在2台のモニタにFire TV Stick(無印,4K)を利用しています。妻の実家に使用しなくなったChromecastを譲渡して使ってもらっているのですが、Google Photoの動画のキャスト時にかなりの確率で止まってしまう等パフォーマンスに難が出てきたので最新のChromecast with Google TVを買って解消できないかと思い購入しました。
LANアダプタもセットで。計10,000ほどで、高かったかも。
昨年Pixel6を購入していてクーポンが余っていたため、使ってしまおうという動機もありました。
せっかくなので、手持ちのFire TV Stickとの比較もしてみました。自分の使用用途しか考慮していません。
比較 Fire TV Stick Chromecast with Google TV Chromecast 備考 YouTube OK OK NG 機器単体での再生 AmazonPrime OK OK NG 機器単体での再生 GoogleCast AirReciever等でOK OK OK Kids制限 OK OK - 複数アカウント OK OK - AirPlay AirReciever等でOK AirReciever等でOK NG 写真の選択表示 OK(Amazon photos) NG(壁紙設定のみ) NG(同左) 実家でCastに利用しているのはiPhone,iPadなのでAirPlayで動画を再生できればよかったのですが、AirRecieverではそもそもGooglePhotoの画面を表示できませんでした。他のスマホの操作画面であれば映るのですが&amp;hellip;
AirRecieverはソフト自体は有名ですが作者の情報が不明で、利用には不安を感じているのですが、GoogleCastが目的であればChromecast系では利用せずに済みます。
Chromecast with Google TVについて 色を白じゃないのを買ったのですが、電源ケーブルとアダプタは白だった&amp;hellip; だったら販売も白だけにしてくれよと思う&amp;hellip; 箱や質感はさすがGoogleといった感じで、Fire TV Stickよりよいです。 Googleアカウントのパスワードに「{」という記号を含んでいたのですが、どうもその場合に相性が悪いらしくGoogleアカウントの登録がエラーに。さらにリモコンで手動で登録しようとしてもこの記号がソフトウェアキーボードに表示されない&amp;hellip; 仕方ないのでGoogleアカウントのパスワードを変更しました。 写真(Google Photos)を機器単体で自由に選んで表示することができない。壁紙、スクリーンセーバーとしてしか設定できない。これができれば自分でとった写真や動画を大画面で見られて最高なのに、なぜGoogleはやらないんだろう&amp;hellip; 結論 Fire TV StickになくてChromecast with Google TVにしかできない機能は見当たらない。逆はある。質感、ブランドなどにこだわりがなければFire TV Stickのほうが良さそう。</description>
    </item>
    
    <item>
      <title>Google Cloud Identity FreeでChromebook運用時の注意点</title>
      <link>https://blog.tack41.net/posts/2021/11/26_01/</link>
      <pubDate>Fri, 26 Nov 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/11/26_01/</guid>
      <description>TL;DR Google Cloud Identity Freeで作ったアカウントをChromebookで利用すると、個人で作ったアカウントとは初期値等が異なります。
経緯 リモート接続用の端末をコストを抑えて運用するため、Google Cloud Identity Freeでアカウントを作成してChromebookに利用しています。できることは制限されますが、紛失時にアカウントをロックして利用できなくするくらいのことはできます。
個人でもChromebookを利用しているのですが、いくつか初期値などが異なっていました。
Google Driveが利用できない Admin Consoleで、[アプリ]-[Google Workspace]-[サービスのステータス]で「ドライブとドキュメント」がオフになっていたので、オンにすることで利用できるようになります。Driveのファイルを操作するSpreadsheetやDocumentも同時に利用可能になります。
PINログインが設定できない Admin Consoleで、[デバイス]-[Chrome]-[設定]-[ユーザーとブラウザ]で[セキュリティ]-[ロックのクイック解除]で「PIN」にチェックを入れると利用できるようになります。
https://office-kabu.jp/chromebook/gsuite-pin-fingerprint-setting-01
マルチログインで2番目にログインできない 初期値では、マルチログインで、最初のセッションとしてはログインできますが、2番めのセッションとしては指定できません。マルチログイン アクセスを管理するを実行します。</description>
    </item>
    
    <item>
      <title>AD環境のWindowsをAnsibleで操作する(非AD環境)</title>
      <link>https://blog.tack41.net/posts/2021/11/25_01/</link>
      <pubDate>Thu, 25 Nov 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/11/25_01/</guid>
      <description>TL;DR Active Directryに参加していないWindow10をWSL2のUbuntu20.04にインストールしたAnsibleで操作する環境を構築しました。kerberos認証が必要ない分、AD参加済みの環境よりは簡単な手順でした。
手順 Windows 10 WSL2を有効にし、Ubuntu20.04をインストール
リモート接続を受け付けるための設定(要管理者権限)
Invoke-WebRequest -Uri https://raw.githubusercontent.com/ansible/ansible/devel/examples/scripts/ConfigureRemotingForAnsible.ps1 -OutFile ConfigureRemotingForAnsible.ps1 powershell -ExecutionPolicy RemoteSigned .\ConfigureRemotingForAnsible.ps1 Ubuntu20.04 最新のAnsibleをインストール
sudo apt update sudo apt install software-properties-common sudo apt-add-repository --yes --update ppa:ansible/ansible sudo apt install ansible https://docs.ansible.com/ansible/2.9_ja/installation_guide/intro_installation.html#ubuntu-ansible 以下のaptパッケージのインストール
python3-pip gcc pip3で以下のPythonライブラリをインストール
pywinrm inventory.ymlに以下の記述を記載
windows: hosts: 192.168.yy.yyy: ansible_connection: winrm ansible_user: user_name ansible_winrm_server_cert_validation: ignore ansible_winrm_transport: basic ansible_port: 5986 ansible -i inventory.yml 192.168.yyy.yyy -m win_ping が成功することを確認</description>
    </item>
    
    <item>
      <title>AD環境のWindowsをAnsibleで操作する</title>
      <link>https://blog.tack41.net/posts/2021/11/24_01/</link>
      <pubDate>Wed, 24 Nov 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/11/24_01/</guid>
      <description>TL;DR Active Directryに参加しているWindow10をWSL2のUbuntu20.04にインストールしたAnsibleで操作する環境を構築しました。複雑な手順が必要ですが、操作できることを確認しました。
手順 Windows 10 WSL2を有効にし、Ubuntu20.04をインストール
リモート接続を受け付けるための設定(要管理者権限)
Invoke-WebRequest -Uri https://raw.githubusercontent.com/ansible/ansible/devel/examples/scripts/ConfigureRemotingForAnsible.ps1 -OutFile ConfigureRemotingForAnsible.ps1 powershell -ExecutionPolicy RemoteSigned .\ConfigureRemotingForAnsible.ps1 Ubuntu20.04 最新のAnsibleをインストール
sudo apt update sudo apt install software-properties-common sudo apt-add-repository --yes --update ppa:ansible/ansible sudo apt install ansible https://docs.ansible.com/ansible/2.9_ja/installation_guide/intro_installation.html#ubuntu-ansible 以下のaptパッケージのインストール
python3-pip gcc python-dev libkrb5-dev krb5-user pip3で以下のPythonライブラリをインストール
pywinrm[kerberos] kerberos requests_kerberos pykerberos 以下の内容で/etc/krb5.confを修正
[libdefaults] default_realm = EXAMPLE.COM kdc_timesync = 1 ccache_type = 4 forwardable = true proxiable = true [realms] EXAMPLE.COM = { kdc = dc1.</description>
    </item>
    
    <item>
      <title>Hyper-Vでホストとゲストが通信できない</title>
      <link>https://blog.tack41.net/posts/2021/11/10_01/</link>
      <pubDate>Wed, 10 Nov 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/11/10_01/</guid>
      <description>TL;DR Hyper-Vでホストとゲストが通信できない場合、まず、Windowsの仮想NICができているか確認したほうが良いかも。
経緯 Hyper-Vでホストとゲストがどうしても通信できないということがありました。久々に利用したPCだったので設定がおかしくなってしまったのかも。
例えば外部スイッチにつないでホスト、ゲストともにゲートウェイまでは通信できるけどお互いへの通信ができない。別のPCからゲストへの通信はできる。 内部スイッチにつないでもだめ。
基本に立ち返ろうと、村嶋 修一氏のHyper-Vネットワークの基本を見たところ、外部ネットワークでホストと共有設定した場合、および内部ネットワークを作成した場合にホストに作成されるはずの仮想NICが無いことに気付きました。
http://www.vwnet.jp/windows/WS12R2/Hyper-V/Hyper-V_Network.htm
いったんスイッチを再作成しようと思い、内部ネットワークのスイッチを削除。 が、外部ネットワークのスイッチはエラーで削除できない。 これは内部的におかしくなっていると判断。いったんHyper-Vをアンインストール。 が、仮想NICが1つだけ残ってしまい、コントロールパネルのネットワーク接続からは削除できない(グレーアウトされている)ためデバイスマネージャーからアンインストール。 その後、再起動を経て再度Hyper-Vをインストールしたところ、外部/内部ネットワークのスイッチ作成時にホスト上に対応した仮想NIC(スイッチ名が「ExternalSwitch」であれば「vEthernet(ExternalSwitch)」というNIC)が作成されていることが確認できました。 ゲスト-ホスト間の通信も問題なし。
トラブルシューティングは、目先のエラーメッセージから安直に検索するのではなく、技術的な基礎に立ち返って原因を下から追いかけることが大事ということを改めて認識しました。</description>
    </item>
    
    <item>
      <title>Bootcampのセットアップは大変</title>
      <link>https://blog.tack41.net/posts/2021/10/04_01/</link>
      <pubDate>Mon, 04 Oct 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/10/04_01/</guid>
      <description>TL;DR MacBook Air Mid 2013でbootcamp上でWindows 10を動かしてそれなりに動作させるのには、以下の作業が必要でした。
Windows 10 21H1のISOでBootcampをセットアップ コンピューターが予期せず再起動されたか...とエラーが表示されてセットアップが進まなくなるので、Shift+F10キーを押してコマンドプロンプトを起動し、regeditを起動してHKEY_LOCAL_MACHINE\SYSTEM\Setup\Status\ChildCompletionのsetup.exeの値を1から3に変更 この時点でNICが未認識 Mac側のBootcampアシスタントで[アクション]-[Windowsサポートソフトウェアをダウンロード]より一式ダウンロードしてUSBメモリに保存 Windows側でUSBメモリ内のSetup.exeを実行 この時点で英数、かなキーを認識できず日本語切り替えがうまくいかない デバイスマネージャーでApple Keyboardをアンインストール。ドライバーのソフトウェアも削除 この時点で英語キーボードと認識され、記号の入力がキーボードの印字通りにならない Windowsの[設定]-[時刻と言語]-[言語]の[優先する言語]にある「日本語」をクリックして[オプション]をクリック。ハードウェアキーボードレイアウトを「英語キーボード(101/102キー)」から「日本語キーボード(106/109キー)に変更 経緯 奥さんが利用しているMac Book Air(Mid 2013)が128GBで、容量不足で作業が滞るため、余っていた1TB SSDに交換しました。
が、このモデル、現時点ではサポート終了で最新バージョンにアップグレードできない&amp;hellip; 最新のMac買えばと薦めたのですが、最近ほとんど使わないので要らないとのこと。もったいないのでBootcampでWindows 10を入れて2025年までは延命させようと作業しました。
このモデルではHigh Sierraまでしかサポートされていません。この状態でBootcampアシスタントでWindows 10 21H1のISOを利用してBootcampを実行すると、途中ハードウェアの認識エラーにより先に進まなくなります。
https://asterisk-works.com/how-to-install-boot-camp-on-macbook-nvme-ssd/
を参考にレジストリ値を変更することでとりあえずエラーは回避。ですがこの状態だとドライバがまともに入っていないようで、NIC未認識によりアップデートもできない状態。
Mac側でBootcampアシスタントで[アクション]-[Windowsサポートソフトウェアをダウンロード]より一式ダウンロードしてWindowsで認識できるFATフォーマットのUSBメモリに保存。3GB弱ありました。で、Windows側でSetup.exeを実行し、再起動させてNICをはじめ各種HWは認識されました。
日本語変換がうまくいきません。IMEの設定で無変換キー、ひらがなキーにIME-OFF/ONの設定をしてもダメ。インストールされたキーボードドライバではキーの認識がうまくいっていないようでした。そこでデバイスマネージャーでApple Keyboradをアンインストール、ドライバーソフトウェアの削除のチェックボックスも入れて再起動すると、認識するようになりました。
https://i-tsunagu.com/mac/keyboard-notrecognize/
が、記号類の認識がおかしい。「@」を入力しようとするとShift+2を実行する必要がある状態。英語キーボードとして認識されているようなので、Windowsの[設定]-[時刻と言語]-[言語]の[優先する言語]にある「日本語」をクリックして[オプション]をクリック。ハードウェアキーボードレイアウトを「英語キーボード(101/102キー)」から「日本語キーボード(106/109キー)に変更してキーボードの印字通りに入力できるようになりました。
いろんなサイトを調べながら結構大変な作業でした。これは素人では無理。最新でないHigh Sierraで実行したこともあるのかもしれませんが、Bootcampアシスタントというお手軽そうなツールがあるからと気軽に手を出すと痛い目を見るな(自分含め)と思いました。</description>
    </item>
    
    <item>
      <title>iOSでBluetoothイヤホンでリダイヤル無効</title>
      <link>https://blog.tack41.net/posts/2021/09/22_02/</link>
      <pubDate>Wed, 22 Sep 2021 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/09/22_02/</guid>
      <description>TL;DR iOSでBluetoothイヤホン(ヘッドセット)を利用していて、リダイヤル等の電話機能を利用したくない場合は[設定]-[Face IDとパスコード]-[音声ダイヤル],[不在着信時にかけなおす]をオフにするとよいです。
経緯 BluetoothヘッドセットとしてAFTERSHOKZ OPENMOVEを利用しています。自転車でも安心して利用できるし値段もお手頃で、主にPodcastを聞くのが目的な私には十分なものです。
が、たまに押し間違えたり、誤検知でリダイヤルが実行されてしまうことがあります。感覚的に1-2週間に1回は発生している感覚で、めちゃくちゃ焦るし相手によってはお詫びの電話を入れる必要があるしで、何とかしたいと思っていました。
同じような人は多いらしくて、例えば以下のサイトに対処方法が記載されていました。 https://ameblo.jp/nararinn/entry-12649433416.html
[設定]-[Face IDとパスコード]より[音声ダイヤル],[不在着信にかけなおす]をオフにする どうも、Bluetooth機器によるボタン操作はiOS側では音声コントロールとして認識されているようですね。上記設定をすることでリダイヤルを誤爆することはなくなりました。</description>
    </item>
    
    <item>
      <title>楽天モバイルの普段使いは時期尚早か(2021/09)</title>
      <link>https://blog.tack41.net/posts/2021/09/22_01/</link>
      <pubDate>Wed, 22 Sep 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/09/22_01/</guid>
      <description>TL;DR 楽天モバイルは、公式サイトのエリア図で赤く表示されている地域でも地下、マンションなどでは届きづらいことが結構あります(2021.09現在)。普段使いでの利用はまだ避けた方がよいかもしれません。
経緯 私のスマホの利用は、Wifi環境がある自宅での利用がほとんどで、友達も少なくて電話連絡など月に1,2回あるかどうかです。
名古屋市内に住んでいますが、公式サイトの通信エリアを見ると真っ赤になっているため、まぁ問題ないだろうと判断し、楽天モバイルに切り替えました。
友達が少ないことが幸いし全く問題を感じていなかったのですが、先日、マンション6階以上の自宅に電話がかかってきたので出たところ、相手の音が聞こえなくなる事象が10-30秒おきに発生し、最終的に2-3分の通話で通信が切れてしまいました。iPhoneのアンテナ表示を見ると1本だけ何とか立っている状況&amp;hellip;
慌てて1Fに降りるとMAX4本立って問題なく通話できるようになりました。
公式サイトのエリア図はあくまで障害物がない地上エリアの面積としてのカバー率で、マンションの上層階といった高さ方向や、建物の中、地下といった障害物のある環境での通信環境では大手携帯会社にはまだまだ及ばないのだと推測しています。
パートナー回線エリアであれば逆に良かったのかもしれませんが、自宅を含む名古屋市が楽天回線エリアのため発生する問題なのかもしれません。
ちなみに、別契約しているdocomo回線では自宅でもアンテナMAX4本立っています。
使用頻度が低い私のような人は運用でカバーできますが、そうでない人が、公式サイトのエリア状況だけをもとにメイン回線を楽天モバイルに切り替えるのは、まだ早いかなと思いました。</description>
    </item>
    
    <item>
      <title>自身のIPアドレスの重複検知</title>
      <link>https://blog.tack41.net/posts/2021/09/09_01/</link>
      <pubDate>Thu, 09 Sep 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/09/09_01/</guid>
      <description>TL;DR Ubuntuサーバ20.04で、重複しているIPを持つサーバから重複しているかどうかを検知する場合は
arping -I eth0 -0 -c 2 (IPアドレス) (eth0は適宜置き換え)を実行し、応答がある(戻り値:0)場合は重複あり、応答がない(戻り値:1)の場合は重複なしと判断します。
経緯 Ubuntu20.04 サーバ上で使用しているIPアドレスが重複しているかどうかを、そのIPアドレスを使用するサーバから検知したいと考えました。
arping, arp-scan等のコマンドを使うと説明するサイトが多数見つかるのですが、ほとんどが重複しているIPを持つ可能性のあるサーバとは別のサーバで実行することが前提のようで、うまくいきませんでした。
自身が同じIPアドレスを持っていると、そのIPアドレスを対象としたARPリクエストを送ってくれないようでTIMEOUTになってしまいます。
そこで、-0(数字のゼロ)オプションをつけると、ARPリクエストを送ってくれるようになりました。ただし、自分自身からは応答が帰ってきませんので、応答がある(戻り値:0)場合は重複あり、応答がない(戻り値:1)場合は重複なしと判断することになります。
このオプションは、ARPリクエスト送信時の送信元IPアドレスを0.0.0.0にするもののようで、これによりARPリクエスト自体が送られない問題を回避できるようです。
参考: Ubuntu20.04にインストールされるThomas Habetsさんのarpingのマニュアル</description>
    </item>
    
    <item>
      <title>Windowsの共有アクセス権にフルコントロールはダメ</title>
      <link>https://blog.tack41.net/posts/2021/08/30_01/</link>
      <pubDate>Mon, 30 Aug 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/08/30_01/</guid>
      <description>TL;DR Windowsをファイルサーバ等の目的でフォルダを共有する際は、共有アクセス権を「フルコントロール」にはせず、「変更」+「読取」にする。
「フルコントロール」にすると、作成したファイル、フォルダに対して権限の変更が可能になってしまう。
経緯 Windowsをファイルサーバ等の目的でフォルダを共有する際、共有フォルダ権限とNTFS権限の2つがあり、どのように設定するか迷うことも多いです。
NTFS権限のほうが細かく設定できるため、共有アクセス権限は「フルコントロール」にしてNTFS権限で制限すればよいとしているサイトを多く見かけます。当社もそのように設定していました。
ですが、このように設定すると、利用者が作成したファイルやフォルダに対して利用者自身がアクセス権の変更を行うことができてしまいます。作成したファイル・フォルダの「所有者」は利用者が設定されてしまうためです。
対応としては、NTFS権限はそのままで共有アクセス権限を「変更」+「読み取り」に変更すればよいです。</description>
    </item>
    
    <item>
      <title>Windowsのシステムディスク入れ替え</title>
      <link>https://blog.tack41.net/posts/2021/08/21_02/</link>
      <pubDate>Sat, 21 Aug 2021 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/08/21_02/</guid>
      <description>TL;DR WindowsでHDDからSSD換装などでシステムディスクを入れ替える際は
コピー先のディスク容量(パーティションサイズではなく)がコピー元より大きい場合: Windows標準のイメージバックアップからシステム修復ディスクによる復旧でOK コピー先のディスク容量(パーティションサイズではなく)がコピー元より小さい場合: 素直に有償のクローンソフトを使おう 経緯 HDDで動作しているWindows 10をSSDに入れ替える作業を行いました。この手の作業でベストなのは、　HDDで必要なデータをバックアップしておき、　SSD側ではWindowsをクリーンインストールしてバックアップからデータを復旧、必要なプログラムは再度インストールしてもらうことです。
ですが、インストール済みのソフトを再インストールする手段がない、バックアップで必要な設定が復旧できるかわからない、等の理由でできないことがあります。今回もそうでした。
Windows 10にはイメージバックアップを取る機能がありますが、復旧時に同じサイズのパーティションを作成します。コピー先のディスクサイズがコピー元より大きければ問題ないのですが、そうでないと一筋縄では行きません。今回、以下の作業を行いましたが、問題を解消できませんでした。
Windowsで使用しているドライブ(今回はCドライブのみ)を「ディスクの管理」でサイズを縮小し、コピー先より小さいサイズにした ディスクの最後尾に設定されていた回復ドライブを削除し、縮小したCドライブのパーティション以降はすべて空き領域とした 回復ドライブを削除すると、イメージバックアップからの復旧に必要となるシステム修復ディスクが作成できなくなるうことがあるので、事前に作成しておく 一旦再起動し、イメージバックアップを取得、復旧を試みた。 有償ソフトの存在はもちろん知っていましたが、なんとかお金をかけずにといろいろ行い、ディスクの読み書きを伴う作業なのでとにかく時間がかかってしまいました。が、数千円の有償ソフト使ってあっという間に解消しました。
自分の作業の時間単価を冷静に考えないとだめですね。</description>
    </item>
    
    <item>
      <title>一部サイトだけつながらない</title>
      <link>https://blog.tack41.net/posts/2021/08/04_01/</link>
      <pubDate>Wed, 04 Aug 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/08/04_01/</guid>
      <description>TL;DR DNSサーバのフォワーダをプロバイダ推奨の設定にしないと思わぬ障害に遭います
経緯 利用者より、ある取引先のWEBサイトがエラーで見られないとの連絡がありました。確認すると、Chrome,Edge,Firefox,IEのいずれもエラー。Chromeの場合はERR_SSL_PROTOCOL_ERR と表示されます。
10日ほど前にUTM(Fortigate)のFWのバージョンアップを行っていたので、まぁこれだろうと思って通信経路から外しても障害が解消しません。
SIMを搭載したiPad, iPhoneでキャリア網経由だと問題がなく、社内ネットワークに問題があることは分かりました。
ルータ直下にPCをつないでも症状は変わらず。ルータか、ONUより上流のキャリア側か、その間のLANケーブルか&amp;hellip;
WireSharkでパケットキャプチャをしてみましたが、私の技術力では原因を特定できず&amp;hellip;
ルータではフィルタリングをかけています。切り分けのため、予備機にフィルタリングを一切しない設定を実施。その配下にWindowsをつなぐのは怖いため、Linux(Lubuntu20.04)をセットアップし、IP固定、DNSは8.8.8.8としました。
Lubuntuで予備機に切り替える前に動作確認したところ症状が解消されていることを確認できました!!!
そこで、もともと問題が発生してたPC(Windows10)でnslookupをDNSサーバ指定なしで実行した結果と、8.8.8.8を指定した結果が異なっていることが判明&amp;hellip;
社内ではActive DirectoryのDNSを利用しています。DNSのキャッシュをクリアしましたが症状変わらず。フォワーダを確認したところ、かなり前にプロバイダから提供されて設定したグローバルアドレスでした。しかも現在はプロバイダを変更しています&amp;hellip;
現在のプロバイダではDNSはルータでのPPPoEによる自動取得となっているので、フォワーダとして社内のルータを指定し、キャッシュを削除したところ症状が解消しました。
ちなみに変更前のプロバイダも現在は自動取得を推奨しているので、だいぶ前から設定が正しくなかったことが分りました。
結論として、誤ったDNS情報をもとに異なったサーバを見に行き、そのサーバはおそらく古いサーバでTLSのバージョンが古く冒頭のエラーとなったものと思われます。
サーバとの通信経路上の問題かと思ったら、通信を始める前の社内DNSの問題というオチ。改めてDNSは通信の基盤であり障害時には真っ先に調査・切り分けしないといけないことを実感しました。</description>
    </item>
    
    <item>
      <title>7月に動作していた処理が8月にエラー</title>
      <link>https://blog.tack41.net/posts/2021/08/02_01/</link>
      <pubDate>Mon, 02 Aug 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/08/02_01/</guid>
      <description>TL;DR 0始まりの数字を10進数で解釈させたい場合は$((10#$val))のように記載する。
経緯 date +%mの結果は、8月の場合は&#39;08&amp;rsquo;となる。これを先頭の0を取って比較したいため$(($val))とやっていたところ、7月までは問題ないのだが8月になって以下のようなエラーが出る。
08: value too great for base (error token is &amp;#34;08&amp;#34;) bashでは一文字目が0の数字は8進数とみなされるため、08という表記はダメ、というエラー。
対応としては、$((10#$val))のように変数の頭に&#39;10#&amp;lsquo;をつけることで10進数で解釈させることができる。
https://stackoverflow.com/questions/8078167/printf-in-bash-09-and-08-are-invalid-numbers-07-and-06-are-fine
同じようなことは過去してきたと思ったのだが、今回初めて遭遇してかなりびっくりした。</description>
    </item>
    
    <item>
      <title>Accessの通貨型にはSystem.Decimal</title>
      <link>https://blog.tack41.net/posts/2021/07/21_01/</link>
      <pubDate>Wed, 21 Jul 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/07/21_01/</guid>
      <description>TL;DR .Net FrameworkからAccessの通貨型の列に値を設定する場合は、System.Decimal型を利用する。
経緯 伝票番号が11桁の数値となるシステムにて、値をSystem.Int64型に格納していた。最終的にAccessのテーブルに格納する必要があり、こちらは通貨型で整数部11桁で定義していた。
OleDb経由でParameterを利用して(SQLにべた書きせずにobject型の変数として渡す)INSERTしたところ、何のエラーも吐かずにこけた。
どうも、System.Int64(=long)が渡されるとAccess側ではLong型(-2,147,483,648 ～ 2,147,483,647)に変換しようとするらしい。ただ、該当の列に「1L」(System.Int64型)を与えるとこけるが、「1」(System.Int32)ではこけないので、値そのものではなく型の違いによるエラーなのだと思われる。DEBUG実行してもエラーをはかずにこけるので切り分けに時間がかかった&amp;hellip;
相手が通貨型11桁なのでそれに合わせてよしなに変換してくれるものと思っていたが甘かった。が、前回同じコードを実行した際にはエラーは起きなかったはずなのだが&amp;hellip; 仕様が変わったのか?
まぁ、特にAccessのような(レガシーな?)システムとの接続の際には、自動変換には期待せずこちらで必要な型が分かる場合は指定したほうが無難だと理解した。</description>
    </item>
    
    <item>
      <title>DockerコンテナのZabbixからDockerホストの監視</title>
      <link>https://blog.tack41.net/posts/2021/07/02_01/</link>
      <pubDate>Fri, 02 Jul 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/07/02_01/</guid>
      <description>Ubuntu20.04で構築しているDocker環境にて
Dockerコンテナで構築したZabbix serverでDockerホストにzabbix agentをインストールして監視する場合、Zabbix serverの接続元IPがDocker内部IPになってしまう。既定ではDockerコンテナのIPは毎回変わるため、zabbic agent側でzabbix serverのIPを指定できない(configファイルに記載が必須)。
Dockerホスト1台で運用する環境であれば、内部IPを固定してしまえばよい。
当方では、2台でActive-Standbyで運用しており、自サーバがActiveの場合は内部IPでアクセスが来るが、Standbyの場合には(自サーバでないActiveサーバの)外部IPでアクセスが来るため、serverとして2つのIPを指定したい。
https://www.zabbix.com/forum/zabbix-help/379138-one-node-monitored-by-2-differents-zabbix-servers
によると、configのSERVER値に複数のIPをカンマ区切りで指定することもできるらしい。
一方で、SERVER値にはホスト名の指定もできるので、ホスト名に対するAレコードを複数登録して動作確認したところ、こちらも問題なく動作した。なお、PTRレコードは不要。
環境によっては、IP直指定よりもDNSの方がよいというところもあるだろう。</description>
    </item>
    
    <item>
      <title>050番号の運用をやめた</title>
      <link>https://blog.tack41.net/posts/2021/06/27_01/</link>
      <pubDate>Sun, 27 Jun 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/06/27_01/</guid>
      <description>私がPC,スマホが好きなため、手元に多数の機器があります。
すべての端末で電話が取れるように出来たら、どの端末でも同じ環境で作業できると考えて050番号を運用していました。が、以下の理由でやめました。
SMSがとれない 現時点でSMSによる認証を完全に避けることは難しい。また、結局、通常の090,080,070の番号は必要。
SaaSで永続性に疑問がないのはTwillioくらいだが、こちらではSMS認証の目的で利用することは規約違反になる。
https://zenn.dev/kawabatas/articles/e996a7d59eeadf
最近の各種MVNOによる料金値下げで、電話番号付きとデータ専用での料金差がとても小さくなった LINEやFacebook Messenger等、ほとんどのメッセンジャーアプリには通話機能があり、それで用が足りることがほとんど。 もし電話番号出ないとダメなタイミングが発生したら、SIMを差し替えればよい。面倒だが、機会はほとんどないのでそれで充分 スマホの購入の際、SIMフリーであることは前提条件となる。現状、すべてSIMフリーではあるが。 NTTcomの050plusを利用していて、毎月わずかですが使わない機能にお金を払うことがなくなり、少し気が軽くなりました。</description>
    </item>
    
    <item>
      <title>Ubuntu20.04 でのsecondary IPの設定</title>
      <link>https://blog.tack41.net/posts/2021/06/24_01/</link>
      <pubDate>Thu, 24 Jun 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/06/24_01/</guid>
      <description>Ubuntu 20.04の2台構成で、サーバ固有のIPアドレスとは別にクラスタ用IPアドレスを割り振ることでクラスタを組もうとした際のメモ。
通信の送信元はクラスタIPで行いたい。Ubuntuで複数IPを割り当てると一方がSecondaryとなり、通信の送信元にはSecondaryでない方が使用される。これはsshサーバに接続してログに表示される接続元IPで確認。
サーバ固有のIPが192.168.1.191,クラスタIPが192.168.1.11の場合に、クラスタのマスタからメンバに降格してサーバ固有のIPのみ割り振られた状態で再度クラスタIPを追加すると、クラスタIPがSecondaryとなってしまう。/etc/netplan/99_config.yamlにて以下のように指定しているのだが。
network: version: 2 renderer: networkd ethernets: eth0: dhcp4: false dhcp6: false addresses: - 192.168.1.11/24 - 192.168.1.191/24 gateway4: 192.168.1.254 nameservers: addresses: [192.168.1.254] IPアドレスの順番を変えてもダメ。どうも、追加したIPアドレスが必ずSecondaryになるという仕様らしい。対応として一旦クラスタIPアドレスのみ割り当て、サーバ固有のIPアドレスを追加するという手順を踏んだところ、クラスタIPアドレスがSecondaryでない設定をすることができた。
&amp;hellip;と思っていたが、それでもうまくいかないケースが発生。 インストール時にサーバ固有IPを初期設定すると、/etc/netplan/00-installer-config.yamlに設定が書き込まれ、そちらも含めて設定しようとするらしく、/etc/netplan/99_config.yamlを書き換えてもサーバ固有IPが解放されない状態となった。これは/etc/netplan/00-installer-config.yamlを/etc/netplan/00-installer-config.yaml.disabledのようにリネームすることで解消した。
/etc/netplan/00-installer-config.yamlを作成しろという記事はあるが、/etc/netplan/00-installer-config.yamlを無効化しろという記載がない記事が多いので、落とし穴かもしれない。</description>
    </item>
    
    <item>
      <title>bashのfunctionの戻り値とexit status</title>
      <link>https://blog.tack41.net/posts/2021/06/23_01/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/06/23_01/</guid>
      <description>bashで戻り値とexit statusがごっちゃになっていたのでメモ。
[参考] https://www.shell-tips.com/bash/functions/ https://eng-entrance.com/linux-shellscript-function
戻り値 function func1(){ echo &amp;#34;2&amp;#34; echo &amp;#34;err&amp;#34; &amp;gt;&amp;amp;2 return 1 } return_value=`func1` rc=$? 上記コードでreturn_valueに格納される値「2」。function内で標準出力に出力した内容がすべて格納される。標準エラー出力に出力した内容は含まれない。
exit status 上記コードでrcに含まれる値「1」。8bitの範囲である0-255の範囲しか指定できない。</description>
    </item>
    
    <item>
      <title>Windowsバックアップの結果通知</title>
      <link>https://blog.tack41.net/posts/2021/06/15_01/</link>
      <pubDate>Tue, 15 Jun 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/06/15_01/</guid>
      <description>Windowsバックアップの結果通知は、タスクスケジューラにて成功/失敗のイベントログをトリガーにしたタスクを作るよう説明しているサイトが多い。 が、自社の環境ではちょいちょい通知が来ないことがある。イベントログを確認してみると記録はされている。イベントログのトリガは不安定と感じている。
そこで、直接成功/失敗のイベントログを見に行って、その結果をもとに通知するほうが確実と判断。現在テスト中。 以下がとても参考になった。
https://stackoverflow.com/questions/51769582/powershell-script-not-pulling-event-from-event-log
実際には以下のようなコードで運用している
# 何時間前までのログを対象にするか $PastHours=12 $StartAt = (Get-Date).AddHours(-$PastHours) # バックアップ成功時に記録されるイベントログ $FilterHashTable = @{ logname = &amp;#34;Microsoft-Windows-Backup&amp;#34; id = 4 StartTime = $StartAt } try{ $actions = (Get-WinEvent -FilterHashtable $FilterHashTable -ErrorAction Stop) if ($actions){ ForEach($action in $actions){ Write-Host &amp;#34;OK: Windows Backup Completed Successfully at $(($action.Task)),$(($action.TimeCreated))&amp;#34; Exit 0 } }else{ Write-Host &amp;#34;CRITICAL: Windows Backup has not run in past $PastHours hours&amp;#34; exit 1 } }catch [Exception] { Write-Host &amp;#34;CRITICAL: Windows Backup has not run in past $PastHours hours&amp;#34; Exit 1 } </description>
    </item>
    
    <item>
      <title>Windows10の機能更新プログラムの制御</title>
      <link>https://blog.tack41.net/posts/2021/05/20_01/</link>
      <pubDate>Thu, 20 May 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/05/20_01/</guid>
      <description>Windows 10では半年に1回、「機能更新プログラム」という大型アップデートが配布されます。つい先日、2021年の1回目となる「21H1」が公開されました。
機能更新プログラムは18か月間サポートされるため、過去2回分はスキップできるということになります。 https://docs.microsoft.com/ja-jp/lifecycle/announcements/windows-10-servicing-support-updates
18か月ぎりぎりまで引き延ばすと問題が出た際の対応が大変となるので避けたいところですが、ある程度は様子を見たいところです。WSUSの場合、以下の運用で対応できます。
WSUS管理コンソールの[オプション]-[自動承認]-[更新規則]にて、Windows 10PCが対象となるすべてのルールで「Upgrades」への承認ルールが設定されている場合は解除します
これで機能更新プログラムがWSUSに配布されても、PCには適用されない状態となります。 WSUS管理コンソールにて[オプション]-[製品と分類]-[分類]にて「Upgrades」のチェックをつける これで機能更新プログラムがWSUSサーバにダウンロードされるようになります。前述の承認ルールの設定によりPCへの適用はされません 機能更新プログラムの様子見が完了して適用するタイミングで、以下の手順で適用します。 先行して適用するPCと、様子見のPCで別のコンピューターグループを作成してPCを移動します。 WSUS管理コンソールの[更新プログラム]-[すべての更新プログラム] にて承認状態が[未承認]のものを検索すると機能更新プログラムが表示されるので、先行して適用するグループに対してのみ承認処理を行います 先行適用のPCに問題がなければ、様子見のPCを先行適用のコンピューターグループに移動して随時適用します。 </description>
    </item>
    
    <item>
      <title>MacBook Air(2017)のSSD換装</title>
      <link>https://blog.tack41.net/posts/2021/02/21_01/</link>
      <pubDate>Sun, 21 Feb 2021 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2021/02/21_01/</guid>
      <description>手持ちのMacBook Air(2017)は、2018年に再整備品をApple Storeで購入しているのですが、目に見えてもっさりした動作になりました。 アプリの起動、ブラウザでGoogle検索から結果をクリックして表示されるまでの時間など、あらゆる動作で数秒待たないと応答が返ってこない状態に。
ディスクの寿命と判断。興味もあったのでディスク交換を行うことにしました。 やっぱり再整備品はこういうリスクがあるのか&amp;hellip;
元々256GBを搭載していましたが、BootCampでWindowsと半分ずつにするとだいぶ厳しい状態だったので、思い切って1TBに換装することに。使用したのは以下。
https://www.amazon.co.jp/gp/product/B01CWWAENG/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;amp;psc=1
https://www.amazon.co.jp/gp/product/B00MVBC4HS/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;amp;psc=1
https://www.amazon.co.jp/gp/product/B07VXC9QMH/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;amp;psc=1
「MacBook Air SSD 交換」で検索して表示されるサイトを参考に交換を実施。あっさりと交換できました。 起動後、SSDが認識されずに焦りましたが、再度分解して端子をしっかり差し込みなおしたところ、認識しました。BootCampもOK
ダメなら新しいPCを購入するつもりもあったのですが、まだ長い付き合いになりそうです。手持ちのMacBook Air(2017)は、2018年に再整備品をApple Storeで購入しているのですが、目に見えてもっさりした動作になりました。 アプリの起動、ブラウザでGoogle検索から結果をクリックして表示されるまでの時間など、あらゆる動作で数秒待たないと応答が返ってこない状態に。
ディスクの寿命と判断。興味もあったのでディスク交換を行うことにしました。 やっぱり再整備品はこういうリスクがあるのか&amp;hellip;
元々256GBを搭載していましたが、BootCampでWindowsと半分ずつにするとだいぶ厳しい状態だったので、思い切って1TBに換装することに。使用したのは以下。
https://www.amazon.co.jp/gp/product/B01CWWAENG/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;amp;psc=1
https://www.amazon.co.jp/gp/product/B00MVBC4HS/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;amp;psc=1
https://www.amazon.co.jp/gp/product/B07VXC9QMH/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;amp;psc=1
「MacBook Air SSD 交換」で検索して表示されるサイトを参考に交換を実施。あっさりと交換できました。 起動後、SSDが認識されずに焦りましたが、再度分解して端子をしっかり差し込みなおしたところ、認識しました。BootCampもOK
ダメなら新しいPCを購入するつもりもあったのですが、まだ長い付き合いになりそうです。</description>
    </item>
    
    <item>
      <title>iPadのYouTubeでキーボードによる早送り</title>
      <link>https://blog.tack41.net/posts/2020/11/18_01/</link>
      <pubDate>Wed, 18 Nov 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/11/18_01/</guid>
      <description>iPadのYouTubeでキーボードで早送り、巻き戻しをしたいと考えた。 アプリであれば画面の右側/左側ダブルタップすれば(既定で)10秒早送り/巻き戻しとなるが、面倒なのと誤操作がたまに発生するのでキーボードで何とかしたいと考えた。
「ipad youtube ショートカット」あたりで検索すると多数ヒットするが、自分の環境(iPad Pro 9.7inch, iPadOS 14.2, Bluetoothキーボード)ではうまく動作しない。 Google ChromeでYouTubeの動画を全画面表示すると、右矢印、左矢印で15秒早送り、巻き戻しができることを確認。ただ、Chromeでも全画面表示を解除した場合やYouTubeアプリやSafariでは動作しない。</description>
    </item>
    
    <item>
      <title>Gitbookを使用する際のNode.jsのバージョンに注意(2020/11/9時点)</title>
      <link>https://blog.tack41.net/posts/2020/11/09_02/</link>
      <pubDate>Mon, 09 Nov 2020 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/11/09_02/</guid>
      <description>前の記事の続き。
scoopを無事再インストールして再度nodejs,gitbook-cliをインストールしようとしてもやはりエラーが出る。最新の15,およびLTSの14でもだめ。 どうもこれは問題になっているらしく、10まで戻らないとダメ見たい&amp;hellip;
https://github.com/GitbookIO/gitbook-cli/issues/110
nvmでバージョンを10.23.0に指定してインストールしたところ、正常に動作することを確認できた</description>
    </item>
    
    <item>
      <title>Windows 10のscoopでnodejsを運用する際にはまったこと</title>
      <link>https://blog.tack41.net/posts/2020/11/09_01/</link>
      <pubDate>Mon, 09 Nov 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/11/09_01/</guid>
      <description>Windows10でscoopでのパッケージ管理にはまり、node.jsもscoop経由でインストールして利用した際にはまったこと。
Gitbookを実行しようとしたところ、なぜかうまくいかない。これがうまくいかない理由はscoopとは関係なかったので別記事で。 いったん環境を切りにしようと思い、nodejsをアンインストールしようとするとこける
scoop uninstall nodejs scoop自体をアンインストールしようとしても同様。
scoop uninstall scoop エラーメッセージにて階層のかなり深いファイルにアクセスできないと表示されるので、エクスプローラーでファイルの存在は確認できる。が、ファイルを開こうとするとパスが長すぎるため開けない旨のエラーが出る。
どうも、nodeがネストされたフォルダにキャッシュ等を置こうとする仕様のために発生するようだ。
https://github.com/lukesampson/scoop/issues/737
Windows10では既定で260文字となっている
https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file#maximum-path-length-limitation
さしあたっては以下の記事にあるように、ネットワークドライブとして参照することで一時的にこの制限を回避できる http://office-qa.com/win/win187.htm
削除後、以下の記事にあるComputer\HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\FileSystem\LongPathsEnabledレジストリを1に変更して再起動後、症状は発生しなくなった
https://docs.microsoft.com/en-us/windows/win32/fileio/maximum-file-path-limitation#enable-long-paths-in-windows-10-version-1607-and-later</description>
    </item>
    
    <item>
      <title>監視結果通知メールの集約にGoogle Spreadsheet</title>
      <link>https://blog.tack41.net/posts/2020/10/21_02/</link>
      <pubDate>Wed, 21 Oct 2020 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/10/21_02/</guid>
      <description>各種バッチ処理の実行結果をメール通知するようにしています。
各サーバに直接見に行くよりはメールのほうが確認は楽なのですが、それでもメール件数が多いと大変で、リストを元に人手で確認すると漏れる可能性があることが心配でした。
そこで、メールに識別しやすいヘッダを懸命につけてGmailに飛ばし、Google Apps Scriptで識別子をもとに取得してGoogle Spreadsheetに結果を表示するようにしたところ、一気に楽になりました。
Spreadsheetの一覧をチェックして結果を通知するGoogle Apps Scriptも別途作成し、通知で何らかのエラーがあればSpreadsheetを見に行くようにしています。
手間はかかりましたがGoogle Apps Scriptの作成、トリガー登録は無料アカウントでもでき、claspというツールを使えばコードを手元で編集して簡単にアップできるので、ほかにも色々使えそうに思いました。</description>
    </item>
    
    <item>
      <title>ZabbixのDockerイメージバージョンアップ時にtimezoneエラー</title>
      <link>https://blog.tack41.net/posts/2020/10/21_01/</link>
      <pubDate>Wed, 21 Oct 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/10/21_01/</guid>
      <description>Dockerにて、本家のイメージを使って運用している。
4.0.22から4.0.24にアップしたところ、以下のエラーが出て監視画面が表示されなくなってしまった。
DateTime::__construct(): Invalid date.timezone value &amp;#39;&amp;#34;Asia/Tokyo&amp;#34;&amp;#39;, we selected the timezone &amp;#39;UTC&amp;#39; for now. よくよくみると、「Asia/Tokyo」の前後にダブルクォーテーションとシングルクォーテーションがついている。ひょっとしてと思い、Dockerで環境変数を指定している箇所
PHP_TZ=&amp;#34;Asia/Tokyo&amp;#34; をダブルクォーテーションなしで
PHP_TZ=Asia/Tokyo と修正したところ、無事表示されるようになった。</description>
    </item>
    
    <item>
      <title>PowershellでActiveDirectory情報取得で原因不明の不具合</title>
      <link>https://blog.tack41.net/posts/2020/10/09_01/</link>
      <pubDate>Fri, 09 Oct 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/10/09_01/</guid>
      <description>Active Directoryの情報をPowershellで取得し、管理資料に起こすスクリプトを作成。せっかくなので定期的にスクリプトを実行して差分がないかタスクスケジューラで定期実行してチェックする運用を構築していた時に問題が発生。
手動で実行する分には問題ないのだが、タスクスケジューラを通して実行するとなぜか以下問題が発生
ADのオブジェクトのSort-Objectでの並び替えが効かない Get-GPOReportで出力した一部XMLに差分が検知される。実際に比較してみると差分はないのだが&amp;hellip; https://social.technet.microsoft.com/Forums/ja-JP/a7e363fa-4553-4468-b123-a1e971c68a78/12525124641245812501123751239012356124271251812540124701254012?forum=powershellja
によると、手動実行とタスクスケジューラからの実行時で既定のモジュールパスが異なるということなので、それによるのかもしれない。が、プログラムがこけているわけではないので、原因はどれなのか得的できず、どれをロードすればよいのかわからない。
実行の都度生成されるファイルが変わってしまうようではチェックには使えないということで、タスクスケジューラによるチェックは断念した。
Powershellをタスクスケジューラから呼び出す処理はほかに多数書いており、問題になったことはない。Active Directoryを操作する際にはImport-Moduleで専用のモジュールを読み込んで処理をするのだが、こういった書き方をする場合に問題となるのかもしれない。 原因は不明。</description>
    </item>
    
    <item>
      <title>Emotetメール襲来</title>
      <link>https://blog.tack41.net/posts/2020/09/15_02/</link>
      <pubDate>Tue, 15 Sep 2020 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/09/15_02/</guid>
      <description>当社にもEmotetもメールが多数届いており、開いてしまったという問い合わせが来た。
Wordファイルを既定の保護モードで開き、[編集を有効にする]をクリックしなかったので事なきを得た。
ファイルをWindwos SandboxにLibreOfficeをインストールしてマクロを確認すると、意味不明な多数の文字列などが大量に記載されており、難読化されているようだった。
うーむ。UTMなどの追加対策をすべきか。</description>
    </item>
    
    <item>
      <title>zabbix起動時にエラー</title>
      <link>https://blog.tack41.net/posts/2020/09/15_01/</link>
      <pubDate>Tue, 15 Sep 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/09/15_01/</guid>
      <description>zabbix起動時に以下のエラーが表示されてログイン画面が表示されない。
DateTime::__construct(): Invalid date.timezone value &amp;#39;&amp;#34;Asia/Tokyo&amp;#34;&amp;#39;, we selected the timezone &amp;#39;UTC&amp;#39; for now. [再起動] 再起動ボタンを押しても同じ画面が再度表示されるだけ。zabbixは公式のDockerイメージ(zabbix/zabbix-web-nginx-mysqlのタグ「4.0-latet」を使用していた。「4.0.22」に戻したところ、正常に動作することを確認。原因は調査できていない。</description>
    </item>
    
    <item>
      <title>Accessでフォーム起動時に該当列が存在しないエラーの原因究明</title>
      <link>https://blog.tack41.net/posts/2020/09/05_01/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/09/05_01/</guid>
      <description>Access であるフォームを起動時に、特定の列が存在しない旨のエラーが表示された。その原因究明について。
該当フォームのレコードソースを見るとクエリが指定されており、エラーメッセージに表示された列が存在しないことを確認。ただ、どこから参照されているかがわからない。
該当フォームはマクロで起動されていたのでマクロを調べてみたが、フォームを起動する処理のみでおかしなところはない。 該当フォームの全てのコントロールのコントロールソースのプロパティを調べてみたが、エラーとなっている項目を参照している箇所はない。 VBAマクロにて該当フォーム内の全プロシージャを調べてみたが、やはり参照箇所はない。
最終的に、フォームの並び替えのプロパティで参照されていた。 かなり時間がかかってしまったが、次回同じようなことが起こった際には、ariawaseのようなツールでVBAをエクスポートしたあと、grepするほうが早くて確実だと思う。</description>
    </item>
    
    <item>
      <title>Gitbookで丸かっこを含むリンク先の指定</title>
      <link>https://blog.tack41.net/posts/2020/08/26_01/</link>
      <pubDate>Wed, 26 Aug 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/08/26_01/</guid>
      <description>Gitbookで丸かっこを含むリンク先(ローカルファイル変相対パス、URL)を指定する方法。
https://cipron81.hatenablog.com/entry/2016/07/03/002850
にある方法では、Visual Studio Code上のプレビューではうまくいくようだが、html出力した際にうまくいかない。 対処として、リンク先指定にて丸かっこをパーセントエスケープして指定する。
[例] test(1).txt → test%281%29.txt
Markdown上の表記と実際のリンク先が異なるのは気になるが、ほかに方法が見つからず。</description>
    </item>
    
    <item>
      <title>サーバ台数1-2台でDocker or Kubernetes</title>
      <link>https://blog.tack41.net/posts/2020/08/03_01/</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/08/03_01/</guid>
      <description>私の勤めている会社では、サーバは全部で4台、そのうち3台はパッケージシステムやADが動作しているWindowsサーバでそのまま運用するだけ(過去に開発されて引き継いだAccessアプリはこの3台のWindows上で動作) 内製アプリは残りの1台でやりくりしています。とは言え利用者は限られているのでリソース的には余裕です。
Dockerで複数コンテナを立てて運用していましたが、Kubernetesが流行っていることも知っていたので是非導入したいと思い、チャレンジしていました。 結論としては、うちの規模では割りに合わない、Docker運用に戻すことにしました。
Dockerのメリットは
コンテナ化することで複数のサーバを独立に動作させることができる PublicなDockerイメージからDockerfileでイメージを構築する形にすれば、Dockerfileさえあればどの環境でも同じように動作させることができる docker-composeを利用すれば、コンテナ起動時の連携設定等も行える Kubernetesのメリットは、上記に加えて
同一イメージのコンテナを複数立てて負荷分散する設定を簡単に行える Blue-Greenデプロイのように既存の環境を維持したままのDeployが設定で簡単にできる あたりが一例としてあると思います。 一方でDockerに対するKubernetesのデメリットとして
DBの運用が難しい PVCを使えばできるようだが、壁は低くない 非Publicなコンテナを利用するのであれば、別途Registryサーバが必要 ネットワーク構成が複雑、外部に公開するためにまぁまぁの設定が必要 複数ノードで負荷分散を可能にするための抽象化だが、そこまでいらない場合にはつらい 現状では、内製アプリが死んでも即困る状況ではなく、気付いたらDockerコンテナを起動すれば良い程度の状況なので、Kubernetesで複数コンテナを分散運用する必要もなく&amp;hellip; ただDBだけは守る必要があるので、しっかりバックアップしてすぐに復旧できるようにしたい。となるとDockerでホストVolumeを使ってやるくらいがメンテしやすい。
このような理由でDockerに戻します。 その上で、DBのバックアップやリストアなどの手順をAnsibleでコード化しておく、あたりが今のインフラ規模ではベストだと判断しました。
Kuberetesのソリューションには、シングルで運用できるminikubeやmicrok8s,k3sなどのソリューションがあり簡単に始められますが、運用にあたっては同一コンテナの負荷分散が必要、のような必要性がないと難しいと思いました。お金をかけられるのであれば、EKSなどのマネージドサービスがベストだと思います。</description>
    </item>
    
    <item>
      <title>mdbファイルが破損している場合</title>
      <link>https://blog.tack41.net/posts/2020/07/29_01/</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/07/29_01/</guid>
      <description>mdbファイルが破損している場合、最初のクエリ実行時にOleDbExceptionが発生します。 これをキャッチすれば破損を検知するロジックはとりあえず書けます。</description>
    </item>
    
    <item>
      <title>IaCの壁</title>
      <link>https://blog.tack41.net/posts/2020/07/12_01/</link>
      <pubDate>Sun, 12 Jul 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/07/12_01/</guid>
      <description>社内のLinuxサーバは極力Ansibleで状態を管理し、サービスはDockerコンテナで運用している(DB除く)。いわゆるIaC(Infrastracture as Code)を実践しているつもり。 これの何が嬉しいかというと、正直なところ個人的にコマンド一発で全てが出来上がるのが楽しい、というところが大きかったりする。ピタゴラスイッチ、ルーブ・ゴールドバーグ・マシンを見ているような爽快感、とでも言うのだろうか。
そんな感覚はない場合、紙の手順書をコードに置き換えるのは面倒と感じるのもわかる。何が面倒かと言えばコードには曖昧さが許されないことだと思う。手順書は曖昧に書いて「言わなくてもわかるよね」という雰囲気で終わらせることもできるが、コードは書いたようにしか動かない。コードに落とすためには対象のプログラム・システムの仕様を正確に理解しないといけないし、何をもって正常とするのか、それはどんなケースでも正常と言えるのか、突き詰めて考えないといけない。この辺りが利用する組織や文化によって大きな壁になるのだと思う。
ただ、慣れてしまえばむしろ誰かが決めた書式・ルールに従って手順書を書く手間、変更された際に保守する手間もなくなるし、手元の仮想化環境などで簡単に再現してテストできる、最高の環境になる。</description>
    </item>
    
    <item>
      <title>Kubernetesでコンテナ動作させる際の基本</title>
      <link>https://blog.tack41.net/posts/2020/07/09_01/</link>
      <pubDate>Thu, 09 Jul 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/07/09_01/</guid>
      <description>思い切ってKubernetesを構築、試験運用を始めました。Ubuntu Server 20.04のMicroK8sです。
docker-compose で動作するところは確認できていたので余裕かと思っていたのですが、はまってしまいました。
症状は、 CrashLoopBackOffで再起動が続く状態。これ当然まともにコンテナが起動せずに終了してしまっているからなんですが、手元の環境ではDockerfileとdocker-composeの合わせ技で奇跡的にうまく動作していたため、Kubernetes側の問題だろうとあれこれ調査して時間を浪費してしまいました。
KubernetesではDockerfileによるbuild済みのコンテナイメージを起動します。docker-composeに記載している処理は、Kubernetesのyamlに記載するか、Dockerfileに記載する必要があります。 が、Kubernetesのyamlに同じ内容を記述できるとは限らず、また記述できても同じ動作をするかはわかりません。ですので、極力Dockerfileに記載してdocker-compose.ymlはシンプルにとどめておいたほうがよさそうと感じました。
また、内部の名前解決用に使用しているDNSは、解決できないと8.8.8.8にforwardしてしまう。Kubernetesの外の社内サーバを名前で参照する場合には、dnsConfigなどの設定でforward先を変更する必要がある。
https://qiita.com/sugimount/items/1873d9d332a25f5b0167</description>
    </item>
    
    <item>
      <title>Accessはできることが多すぎる</title>
      <link>https://blog.tack41.net/posts/2020/06/28_01/</link>
      <pubDate>Sun, 28 Jun 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/06/28_01/</guid>
      <description>過去に開発された内製アプリをC#+RDBMSに置き換えていて思うこと。
kintoneやPowerAppsのようなローコード、ノーコードと言われる分野のアプリで置き換えようとすると機能が足りず、ガッカリして断念している。 ふと思うのは、むしろAccessが高機能すぎるのではないかということ。特にVBAはやろうと思えばなんでもできてしまう。会社の前の基幹アプリはAccess VBAでできていたし。
Accessが目指すべきなのは、クエリ、マクロ、フォームの組み合わせでできることに特化すべきで、それ以上のことは別のやり方でやってください、とすべきだったのではと思う。VBAは禁止。クエリもGUIで組み立てられるレベルまで、サブクエリは禁止、くらいでちょうど良い。
WordやExcelのVBAは、普通に作る分にはUI,データソース共に限られるので問題にならないが、AccessはなまじDBMSとしてテーブル、SQLをサポートしているので複雑なことまでやろうとしてしまう。グラフもそれなりに書けてしまうし。
他の言語がここ十何年で目覚ましい進歩を遂げて入り一方でVBAがここ何年もほとんど進化していないのは、できることが多すぎてそれらを維持したまま進化させるのが難しいという一面もあると思う。メインの利用者が非開発者でそのような進歩を望んでいないことも大きいと思うが。
最新の言語を書いた後にVBAのプアな機能を使ってコードを書くのはとても辛い&amp;hellip; Visual Studio Tools for OfficeもAccessはサポートしてないし。
ローコード、ノーコードアプリはスプレッドシートをデータソースとすることが多いので、AccessはExcelのみをデータソースとしてサポートする、くらいで良いと思うが、それってPowerBIだよねという話で、Accessはもはや不要な製品だと思う。
Accessの値段でAccessと同等の機能を持つ製品はなく、(自分も含めて)影響は大きいが、大規模な時代遅れなAccessのVBAの保守を任される開発者も、時代遅れなVBAを進化させることができずに細々とサポートするMicrosoftの開発者も不幸な今の状況を考えると、Accessは終了すべきと思う。長めの期間をとって移行のロードマップを示す必要はあるが。10年後にVBAバリバリのAccessアプリが残っている未来を想像したくない。</description>
    </item>
    
    <item>
      <title>sqlxの構造体へのscanでエラー</title>
      <link>https://blog.tack41.net/posts/2020/06/25_01/</link>
      <pubDate>Thu, 25 Jun 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/06/25_01/</guid>
      <description>最近golangでプログラムを書いてます。普段書いている.Net Framework(およびエコシステム)と比較すると物足りないところも多いですが、Visual Studio立ち上げずにサクサクかけて、クロスコンパイルしてどこでも動かせるのは良いです。
要約 sqlx のnon-struct dest type struct with &amp;gt;1 columns (33) というエラーの原因は、構造体のフィールドの頭文字を大文字にするとよいかも
内容 本当に初心者なので全く分かっていなかったのですが、golangのtypeはメソッドを埋め込んだりフィールドにスコープがあったりして、JavaやC#のクラスに近い位置づけなんですね。
sqlxを使ってScanしてnon-struct dest type struct with &amp;gt;1 columns (33)のようなエラーが出る原因は、フィールドの頭文字を小文字にしていたため。フィールドを小文字にするとprivate扱いになるよう。</description>
    </item>
    
    <item>
      <title>テスト対象プロジェクトのコンテンツファイルが必要なテスト実行時の注意</title>
      <link>https://blog.tack41.net/posts/2020/06/18_02/</link>
      <pubDate>Thu, 18 Jun 2020 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/06/18_02/</guid>
      <description>要約 テスト対象プロジェクトのコンテンツファイルが存在することが必要となるテストを行う場合は、テストクラスに[DeploymentItem(@&amp;quot;Files\contents.xlsx&amp;quot;, &amp;quot;Files&amp;quot;)]の記述が必要
内容 Targetプロジェクトにて、Files\contents.xlsxをコンテンツ指定しており、これを利用する機能をTargetTestプロジェクトから実行する場合、何も考えずに実行するとFiles\contents.xlsxが見つからない旨のエラー(File or Directory Not found)が出る。
で、そのあとにテスト単体を個別に実行するとうまくいく。[選択して実行]と[すべてを実行]では実行パスが違い、前者では何も指定しなくてもコンテンツもコピーされるが、後者ではされないためのようだ。
[http://blog.livedoor.jp/nanoris/archives/51825230.html:embed:cite]
対応としては、TestClassのアノテーションの下にDeploymentItemのアノテーションを追加するとうまくいった。
[TestClass] [DeploymentItem(@&amp;#34;Files\contents.xlsx&amp;#34;, &amp;#34;Files&amp;#34;)]` public class TestClass{ ... ディレクトリ「Files」も指定しないとDirectoryNotFoundExceptionとなった。コンテンツファイルをテストプロジェクトにコピーする必要はない。</description>
    </item>
    
    <item>
      <title>MSTest の実行順番</title>
      <link>https://blog.tack41.net/posts/2020/06/18_01/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/06/18_01/</guid>
      <description>要約 MSTestは、複数クラスのメソッドを交互に実行しうる。これが困る場合は1つのクラスにまとめるべきかもしれない
内容 テストクラスAで更新系のテストをまとめてクラス初期化時にデータ整備を行い、テストクラスBで参照系のテストをまとめてテスト実行時にデータ整備を行っていた。
MSTestでは標準で並列実行はしないので問題ないと思っていたが、タイミングによって参照系のテストがこけることがあった。よくよく調べてみると、参照系のテストの一部が終わった状態で更新系のテストに移り、そこでデータが更新されてしまった状態で残りの参照系のテストが行われ、データが合わない状態だった。
並列実行しないというのはメソッド単位の話で、クラス単位のメソッドの実行順位が入れ子になることはあるようだ。成功したり、失敗したりするヤなパターンとなる。
対応として参照系、更新系を同一クラスにまとめ、全メソッドに対してメソッド実行時にデータ整備を行うこととした。
参照系のテストのみであればデータ整備はクラス初期化時でよいのだが、更新系が混ざる場合は参照系を含む全メソッドでメソッド実行時にデータ整備を行わないといけないということか。</description>
    </item>
    
    <item>
      <title>USB2,3のポート</title>
      <link>https://blog.tack41.net/posts/2020/06/16_01/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/06/16_01/</guid>
      <description>要約 USB機器がうまく動作しない場合、特にそれがUSB2.0の機器の場合はPCにUSB2.0のポート(端子が青色でないもの)に挿すと正常に動作することがある。
内容 PCに接続するUSB機器が正常に動作しない事象が立て続けに起こった。
USB接続スピーカー(品番失念) たまに認識しなくなり、OS再起動したり別のポートに挿すと認識したり、それでもしなかったり&amp;hellip; mouse computerの これらを、PCの仕様書からUSB2.0となっているポートに挿したところ、安定して動作するようになった。
どうも、PCのUSB3.0のポートはUSB2.0と完全に互換性があるとは限らないらしい。
http://www.akatsuki-lab.co.jp/Attention-USB3.0port.htm
検索してもUSB3.0(以降)はUSB2.0との互換性があり、かつ転送速度が速い、という記事しかないので、逆になんでUSB2.0がいまだに残っているのだろうと思っていたが、実際にUSB2.0のポートでないと動作しない機器があるということであれば納得がいく。</description>
    </item>
    
    <item>
      <title>DataGridViewの列の並び順</title>
      <link>https://blog.tack41.net/posts/2020/06/08_01/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/06/08_01/</guid>
      <description>Windows FormのDataGridView .Net Framework 4.7.2 にて
DataGridViewでDataSourceにDataTableを代入して利用する。
dataGridView1.DataSource = dt1; 1回目に列名2020/1,2020/2,2020/3,2020/4 の4つの列名を含むDataTableを設定。その後2019/10,2019/11,2019/12,2020/1 の4つを列名に含むDataTableを渡すと、重複する2020/1が 先頭に表示されてしまう。DataSource自体は全く別のオブジェクトなのだが、DataGridView側で前回のColumn情報を覚えていて、列名がマッチしたら使いまわしているのかもしれない。
対策としては、DataSourceに代入する前に
dtaGridView1.Columns.Clear(); を実行すればよい。</description>
    </item>
    
    <item>
      <title>MariaDBのWindow関数</title>
      <link>https://blog.tack41.net/posts/2020/06/03_01/</link>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/06/03_01/</guid>
      <description>MariaDB: 10.4.12 にて
要約 MariaDB 10.4.12(2020/6/3時点で最新版の1マイナーバージョンだけ前)では、Window関数は ONLY_FULL_GROUP_BY で誤動作する。
内容 MariaDBでROW_NUMBER(), SUM() OVER() 等のWindow関数を使用すると以下のようなエラーが出る。
MySql.Data.MySqlClient.MySqlException: Mixing of GROUP columns (MIN(),MAX(),COUNT(),...) with no GROUP columns is illegal if there is no GROUP BY clause Window関数に使用している列をGROUP BYに指定して支障がないところであればそれでクリアできるのだが、そうでないところはどうにもならない。 Window関数自体は10.2から有効なはずなのだが、以下の記事によると、AVGなど一部のWindow関数以外はONLY_FULL_GROUP_BY に対応していないらしい。
https://jira.mariadb.org/browse/MDEV-17785
実際、AVG関数はONLY_FULL_GROUP_BY 制約のもと、GROUP BYで指定しなくても問題なく動作する。ROW_NUMBER(), SUM() はダメ。早く対応してほしい&amp;hellip;</description>
    </item>
    
    <item>
      <title>LINQの遅延評価がマイナスに働くケース</title>
      <link>https://blog.tack41.net/posts/2020/05/30_01/</link>
      <pubDate>Sat, 30 May 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/05/30_01/</guid>
      <description>LINQに限らず遅延評価はパフォーマンスに対してプラスに働く、という説明が多いように思うが、劇的にマイナスに働くケースがあった。 商品の名前の先頭に応じてグループ分けし、残ったデータに対して同様にグループ分けする以下のようなコード
IEnumerable&amp;lt;T&amp;gt; left = .... var sub1 = left.Where(l =&amp;gt; l.StartsWith(&amp;#34;AB&amp;#34;)) left = left.Where(l =&amp;gt; sub1.All(s =&amp;gt; s.ID != l.ID)) var sub2 = left.Where(l =&amp;gt; l.StartsWith(&amp;#34;A&amp;#34;) left = left.Where(l =&amp;gt; sub2.All(s =&amp;gt; s.ID != l.ID)) var sub3 = left.Where(l =&amp;gt; l.StartsWith(&amp;#34;B&amp;#34;) left = left.Where(l =&amp;gt; sub3.All(s =&amp;gt; s.ID != l.ID)) ... このような分類が20弱続くケースで、1分たっても応答が返ってこない。 leftの型をIListとし、left = left.Where(l =&amp;gt; sub1.All(s =&amp;gt; s.ID != l.ID)).ToList()のように即時評価に書き換えると1秒せずに返ってくる。
デバッグ実行すると、left = left.Where(l =&amp;gt; sub1.All(s =&amp;gt; s.ID != l.</description>
    </item>
    
    <item>
      <title>GROUP BY省略時の弊害(MariaDB)</title>
      <link>https://blog.tack41.net/posts/2020/05/25_01/</link>
      <pubDate>Mon, 25 May 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/05/25_01/</guid>
      <description>MariaDB 10.4 にて
SQLでSELECT句に集計関数のみを指定する場合、GROUP BYは指定しなくても実行できる。 が、ヒットするレコードがない場合に全データnullのデータが1件返されてしまう。 GROUP BYに指定すれば0件が返されるので、明らかにヒットする場合を除いてGROUP BYは明示的に指定したほうがよさそう。</description>
    </item>
    
    <item>
      <title>ストレージ廃棄前のデータ消去処理</title>
      <link>https://blog.tack41.net/posts/2020/05/22_01/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/05/22_01/</guid>
      <description>2020/5/22時点で自分が行っている処理。 参考文献は以下
https://ja.wikipedia.org/wiki/%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E5%AE%8C%E5%85%A8%E6%B6%88%E5%8E%BB
https://bizgate.nikkei.co.jp/article/DGXMZO3867874007122018000000
HDD Wipe Out等の専用ツールを使用する。設定は、たいていのツールで既定の設定で十分と思われる。上記Wikipediaにもあるが、最近のHDDは微細化が進んでいるため残留磁気による復旧の難易度は相当高いとのことなので、規定値以上に何度も書き込みをする必要はないと考える。
SSD ドライブ全体に対してBitLockerによる暗号化フォーマットを実施する。 SSDには寿命を延ばすための処理がファームウェアに組み込まれており、OSからフォーマット、削除を実施してもその通りに実施されているとは限らない。ドライブ全体の暗号化が無難
その他Flashメモリ(USB,SDカード等) Windowsによる(クイックでない)完全フォーマット。現時点ではSSDほど独自の処理は行われていないので、これで十分と考える。
ちなみに、消去処理には機器の寿命を縮める副作用はある。上記処理後に以下のツールで寿命が来ていないか確認している
HDD, SSD: CrystalDiskInfo で黄色や赤の表示がされないか その他Flash: [CheckFlash]の初期値で実行してエラーが検出されないか </description>
    </item>
    
    <item>
      <title>Ubuntuのオンラインアカウント</title>
      <link>https://blog.tack41.net/posts/2020/05/20_02/</link>
      <pubDate>Wed, 20 May 2020 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/05/20_02/</guid>
      <description>Ubuntu 20.04で確認
設定に「オンラインアカウント」という設定がある。これにGoogleアカウントの設定もあり、設定したところGoogle Driveを参照できた! ローカルストレージをみると増えていっている様子はなく、閲覧、編集時に都度撮ってくる方式と思われる。素晴らしい。
私はWindows, Mac, Linuxを使っており、(ブラウザ経由ではなく)どの環境でも使えるオンラインストレージのアプリを使おうと思うとDropbox一択だと思っていた。
UbuntuであればGoogle Driveも3つのOS環境で利用できそうだ。
5/20 追記 KeePassのファイルをGoogleDriveからKeePass2で開いて保存したところ、ファイルが破損してしまった。KeePassXCでは読み取り専用でしか開けない。現時点では読み取り専用でしか使えないようだ。</description>
    </item>
    
    <item>
      <title>Ubuntu 電源ボタンでシャットダウン</title>
      <link>https://blog.tack41.net/posts/2020/05/20_01/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/05/20_01/</guid>
      <description>家族が出入りする場所にパソコンがあり、誤って電源ボタンを押してONになってしまった場合に、ログオンせずに電源ボタンでシャットダウンできないかと考えた。 逆に誤ってシャットダウンする危険性はあるが、それは自分が気をつければ良いと判断。
Ask Ubuntuにズバリの回答があり、これを適用したところ意図した動作を実現できた。
sudo nano /etc/acpi/events/power event=button/power action=https://blog.tack41.net/sbin/poweroff sudo service acpid restart https://askubuntu.com/questions/1000393/how-to-configure-the-power-off-button-to-just-power-off-instantly-in-ubuntu-17-1#answer-1081407</description>
    </item>
    
    <item>
      <title>IODATAのクラウドストレージ連携(S3)でエラー</title>
      <link>https://blog.tack41.net/posts/2020/03/26_01/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2020/03/26_01/</guid>
      <description>IODATAのNASで利用しているクラウドストレージ連携でS3にバックアップしているのだが、今日、急に以下のようなエラーが出るようになった。
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;Error&amp;gt;&amp;lt;Code&amp;gt;AuthorizationHeaderMalformed&amp;lt;/Code&amp;gt;&amp;lt;Message&amp;gt;The authorization header is malformed; the region &amp;#39;us-east-1&amp;#39; is wrong; expecting &amp;#39;ap-northeast-1&amp;#39;&amp;lt;/Message&amp;gt;&amp;lt;Region&amp;gt;ap-northeast-1&amp;lt;/Region&amp;gt;&amp;lt;RequestId&amp;gt;...&amp;lt;/RequestId&amp;gt;&amp;lt;HostId&amp;gt;...=&amp;lt;/HostId&amp;gt;&amp;lt;/Error&amp;gt; NAS, S3側で特に設定変更はしていないのだが&amp;hellip; クラウドストレージ連携のバージョン1.28が2020/2/26にリリースされているようなので、これが自動更新されたのかもしれない。 https://www.iodata.jp/support/qanda/answer/s30471.htm
https://github.community/t5/GitHub-Actions/Cannot-get-an-AWS-Action-to-run-in-the-correct-region/td-p/17413
にあるように、既定で接続するとリージョンがus-east-1となり、ap-northeast-1リージョンのS3 bucketを操作しようとしてエラーとなっていると推測される。
対応として、詳細設定にあるエンドポイント指定にて、今まで未指定だったところに「s3.ap-northeast-1.amazonaws.com」を指定したところ、接続テストが成功することを確認。</description>
    </item>
    
    <item>
      <title>WindowsFormでイベントを駆使して入力チェック等を行う場合のポイント</title>
      <link>https://blog.tack41.net/posts/2019/12/24_01/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/12/24_01/</guid>
      <description> すべてのイベントハンドラを一括で登録、削除する関数を作成する すべてのイベントハンドラの最初で削除し、最後に再登録する イベントの多重起動(Leaveイベント内で別ControlのFocusを実行して再度Leaveが実行される、等)を防ぐにはこれが確実 関数のreturn部分が複数あって複雑な場合は、try-finallyのfinally内で再登録する イベントハンドラから呼び出す関数内で削除,登録処理を行うと、その関数の呼ばれ方によって再登録が多重に行われてしまう可能性がある。関数を使う場合もイベントハンドラの中で直接一括削除、再登録を行う 複数のイベントハンドラが同じ処理をする場合でも、別のイベントハンドラを直接呼び出す実装をすると上記を満たさず破綻する。共通部分を別関数に切り出して使用する。 </description>
    </item>
    
    <item>
      <title>DataRow.Field&lt;int&gt; とConvert.ToInt32 の違い</title>
      <link>https://blog.tack41.net/posts/2019/11/08_01/</link>
      <pubDate>Fri, 08 Nov 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/11/08_01/</guid>
      <description>DataRow.Field とConvert.ToInt32 の違いについて、 int がstringになった場合でも同様。
DataRowの値がDBNullかどうかで分ける場合に
var val = (dr[&amp;#34;name&amp;#34;] == DBNull.Value) ? &amp;#34;&amp;#34; : Convert.ToString(dr[&amp;#34;name&amp;#34;]) とやっていたのだが、
var val = dr.Field&amp;lt;int?&amp;gt;(&amp;#34;name&amp;#34;) ?? &amp;#34;&amp;#34; と書けるという記事を発見し、早速使ってみたのだが&amp;hellip;
Field版では、データがdecimalの場合にInValidCastExceptionが発生してしまう。値の範囲がintの範囲に収まっているかどうかは関係ない。 利用しているデータがdecimalの桁数指定で定義している箇所がほとんどという性質のため、これでは全く使えないと判明した&amp;hellip;
ただ、Convert.ToString(DBNull.Value) はstring.empty(空文字)に、Convert.ToInt32(DBNull.Value)は0になるので、これがOKであればこれが最も手っ取り早いとわかった。
DataRowのFieldやGetValueOrDefaultのようなジェネリクスメソッドは型変換の範囲が厳しく、逆にConvert系はおおらかなのだろう。</description>
    </item>
    
    <item>
      <title>WindowsのMariaDBメジャーバージョンアップ後の運用の注意</title>
      <link>https://blog.tack41.net/posts/2019/11/03_01/</link>
      <pubDate>Sun, 03 Nov 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/11/03_01/</guid>
      <description>WindowsのMariaDBを10.2 -&amp;gt; 10.4のようにメジャーバージョンアップする場合について。
バージョンアップ自体は公式サイトの手順に従って行えば良い。インストーラにより、上記の場合はバイナリはC:\Program Files\MariaDB 10.4、データはC:\Program Files\MariaDB 10.2を参照するようになる。MySQLサービスの実行パスは
&amp;#34;c:\Program Files\MariaDB 10.4\bin\mysqld.exe&amp;#34; &amp;#34;--defaults-file=C:\Program Files\MariaDB 10.2\data\my.ini&amp;#34; &amp;#34;MySQL&amp;#34; のようになる。
で、時間があるのでデータもバイナリも10.4のフォルダにするためにバックアップを取得した上で10.4をアンインストール、再度10.4をインストールすると、サービスが起動しない。 原因は上記実行パスのサービスがアンインストール時も消されずに残ってしまうためのよう。 MariaDBをすべてアンインストールした状態でsc delete MySQLを実行して残ったサービスを削除し、再度インストールすると正しい実行パスのサービスのエントリが生成される。</description>
    </item>
    
    <item>
      <title>Accessのレポート機能の活用</title>
      <link>https://blog.tack41.net/posts/2019/10/29_01/</link>
      <pubDate>Tue, 29 Oct 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/10/29_01/</guid>
      <description>内製のシステムを、Accessベースから.Netに移行している。 その際に最大のネックになるのはレポート機能。
Accessのレポート機能は正直相当優秀だと思う。.Netの有償アプリで同等の機能を持つものを選定すると、開発者向けライセンスが100万レベルのものになってしまう。 それが、Officeの上位ライセンスに付属し、ランタイムだけなら無償で利用できる。
一方でネックはコードの開発生産性の低さ。VBAの文法は古めかしいし、何よりテキストではないのでGitで管理できない。
上記のいいとこ取りとして、Accessファイルのレポート機能だけを利用する方法を考えている。 Accessファイル側はレポートとレコードソースとなるテーブルのみ保持し、起動時にそのレポートが初期表示されるように設定しておく。
.Netのプロジェクト側では常に配布するコンテンツとしてAccessファイルを保持し、ADO経由でレコードソースとなるテーブルにデータを設定する。 その後外部プロセスとして該当のAccessを起動すると、レポートが表示される。 外部プロセスなので細かい制御はできないが、用途によっては十分だろう。
帳票数が多いアプリではきついかもしれないが、移行できない少数のレポートを活用する場合には十分かと思われる。</description>
    </item>
    
    <item>
      <title>NuGetライブラリ整理直後に謎のエラー</title>
      <link>https://blog.tack41.net/posts/2019/10/28_01/</link>
      <pubDate>Mon, 28 Oct 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/10/28_01/</guid>
      <description>NuGetで使用するライブラリをVisualStuidoの管理画面より変更(削除-&amp;gt;追加)し、合わせて削除したライブラリに依存するライブラリを削除したところ、dllが存在しない旨を表すエラーが発生。 そのdllを見ると、削除したはずのdll。
App.configを見ると、その削除したはずのdllに関するdependentAssemblyエントリが合ったため、バックアップを取得した上で該当箇所を削除したところエラーは出なくなった。
Visual StudioでNugetライブラリを削除する場合には、設定ファイル(App.config)には連動されない場合があるらしい。</description>
    </item>
    
    <item>
      <title>Visual Studio 2017でReport Viewerの表示、編集ができない</title>
      <link>https://blog.tack41.net/posts/2019/10/04_01/</link>
      <pubDate>Fri, 04 Oct 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/10/04_01/</guid>
      <description>Visual Studioで久しぶりにReport Viewerを編集しようとしたのだが、右クリックしても何も表示されない。 右上に右向きの矢印が表示されるはずなのだが、それもない&amp;hellip;
新しいフォームを作ってReportViewerをドロップしたところ、何も表示されない。
https://stackoverflow.com/questions/28179780/reportviewer-not-shown-on-form-designer-c-winform
を参考にInitializeComponentにコードを追加すると表示はされるが、やはり一切編集できない。
編集したい理由は、rdlcファイルを指定がエラーとなっていて編集し直したかったため。this.reportViewer1.LocalReport.ReportEmbeddedResource にrdlcファイルを直接指定する方法を試してみたが、GUIで指定したほうが有効になっているためか全く効かない。
最近.Net Coreのプロジェクトを作った際、Visual Studio CodeとIntellisenseがらみで干渉したため、いったんアンインストールしたことがあった。その際に設定がおかしくなったのかもしれない。 Visual StudioをいったんアンインストールしてOS再起動後にインストール。
Visual Studio 2017(Pro)をインストール後、拡張機能「Microsoft RDLC Report Designer」をインストール。 Microsoft.ReportingServices.ReportViewerControl.Winformsライブラリを、Visual Studio内のNuget管理画面にて、下げられる最低のバージョン140.337.80まで下げると編集メニューが表示される!!
ただ、既に作成済みのreportViewerはうまく動作しないため、いったん削除して同名で再作成して再配置。 その後、最新バージョンまで上げたが、正常に動作している。
一旦バージョンを下げることでキャッシュか何かがクリアされたのか? 原因不明。</description>
    </item>
    
    <item>
      <title>MySqlBulkLoaderでの取込結果が合わない</title>
      <link>https://blog.tack41.net/posts/2019/08/23_01/</link>
      <pubDate>Fri, 23 Aug 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/08/23_01/</guid>
      <description>C#でMariaDBに接続する際にMySqlConnectorを利用している。
大量のデータを取り込む必要があったため、MySqlBulkLoaderで取り込んだところ、なんかゴミデータみたいのが入るうえに数字も合わない。 よくよく調べたところ、前段のCSV出力個所と、取込時の設定にミスがあった。
CSV出力時の改行の削除 CSV出力にはCSVHelper.CsvWriterを使用しているのだが、Fieldに改行があるとそのままCSVに出力される。CSVファイルは1行1データを前提としているので、ゴミデータが発生する原因になる。
csv.WriteField(col.ToString().Replace(&amp;#34;\r&amp;#34;, &amp;#34;&amp;#34;).Replace(&amp;#34;\n&amp;#34;, &amp;#34;&amp;#34;)) のように除去することで回避できた
FieldQuatationCharacterの設定 FieldTerminator, LineTerminator は普通に設定したのだが、FieldQuatationCharacter を設定しないと、CSVHelperがせっかく括弧で囲んでくれた中にカンマが含まれていると、そこで区切られてしまう。
mySqlBulkLoader.FieldQuotationCharacter = &amp;#39;&amp;#34;&amp;#39;; と指定することで回避できた。
MySqlConnector の MySqlBulkLoader は上記のような不具合で項目数など合わなくてもエラーなしで無理やり取り込むのが困ったところ&amp;hellip;</description>
    </item>
    
    <item>
      <title>IEnumerableで受けてIReadOnlyListで返すなら</title>
      <link>https://blog.tack41.net/posts/2019/08/09_01/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/08/09_01/</guid>
      <description>http://tack41tu.hatenablog.com/entry/2019/02/28/092329
で記載した方針を受けて、最近はCollectionに関してはIEnumerableで受けて、IReadOnlyListで返す基本方針としている。 一方で、プロパティの変更による予期せぬ誤動作を防ぐために、POCOについてはコンストラクタで初期とを設定し、setterを提供しないことでImmutableな形としている。
ただ、そうなるとCollectionもコンストラクタで渡す必要があるが、アルゴリズムの関係などでCollectionのメンバーは後で追加したいことがある。例えばDBからデータを取得して、鑑データの属性として明細データのCollectionを持たせる場合に、鑑データのclassをいったん生成した後、明細データを都度追加したいことが多い。要は短期間だけメンバーを追加したい。
POCOに渡すCollectionの参照を呼び出し側で保持し、鑑データのコンストラクタに渡した後で呼び出し側で持っているCollectionの参照をもとにメンバーを追加したのだが、なぜか反映されない。
結論としては、POCO内ではCollectionをListとして保持しており、コンストラクタでIEnumerableで受けた際に直ちにtoListで変換していた。これだとその時点でオブジェクトがコピーされてしまい、呼び出し側で持っている参照とは別物になってしまう。 そこで、IEnumerableで受けたオブジェクトは内部的にもIEnumerableで保持し、getterで参照された際にtoListしてIReadOnlyList型として返すことで解決した。こうすれば呼び出し側で持っている参照とPOCOで持っているクラスは全く同じとなり、呼び出し側でメンバーを追加、削除すればPOCOにも反映される。getterで参照する場合はそもそもIReadOnlyList型としてわたるのでメンバーの編集はできない。castすればできなくもないかもしれないが、少なくともそれは保証対象外という意図を明示できる。</description>
    </item>
    
    <item>
      <title>rm /* やってしまった</title>
      <link>https://blog.tack41.net/posts/2019/07/26_01/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/07/26_01/</guid>
      <description>やってしまいました。
rm ${HOGE}/* HOGEが未定義のため、ルートディレクトリのファイルが全削除。 幸い、rfオプションは付けていなかったので、消されたのはファイルのみ。
CentOS7において、ルートディレクトリに存在するファイルは以下のシンボリックリンク。
/bin -&amp;gt; /usr/bin /lib -&amp;gt; /usr/lib /lib64 -&amp;gt; /usr/lib64 /sbin/ -&amp;gt; /usr/sbin 組み込み系のコマンドしかまともに動作せず、/usr/binフォルダに移動してコマンドを実行しても
-bash: /usr/bin/ln: /lib64/ld-linux-x86-64.so.2: bad ELF interpreter: となってしまう&amp;hellip;
なんとかググって見つけた以下のサイト
[https://ja.stackoverflow.com/questions/24643/rm-f-%E3%82%92%E5%AE%9F%E8%A1%8C%E3%81%97%E3%81%A6%E3%81%97%E3%81%BE%E3%81%84%E3%81%BE%E3%81%97%E3%81%9F:embed:cite]
# /usr/lib64/ld-linux-x86-64.so.2 --library-path /usr/lib64 /usr/bin/ln -s /usr/lib64 /lib64 # /usr/bin/ln -s /usr/bin /bin # ln -s /usr/lib /lib # ln -s /usr/lib64 /lib64 # ln -s /usr/sbin /sbin 上記コマンドで復旧した。神!! 感謝!!! 死ぬほど焦った&amp;hellip;
今覚えば、/usr/bin/busyboxを使えばよかったのかもしれない。
ちなみに、shebangにて
#!/bin/bash -eu とやっていたのだが、該当ファイルを/bin/bashの引数で呼び出したので効いていなかった&amp;hellip; shebangではなく本文中にset -euと書くことが大事だと、死ぬほど理解した.</description>
    </item>
    
    <item>
      <title>PowershellのToStringの書式指定ではまった</title>
      <link>https://blog.tack41.net/posts/2019/07/01_01/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/07/01_01/</guid>
      <description>PowerShellのToStringで数値を書式指定で出力する際にはまった2点。どちらもエラーメッセージが適切ではなく、原因特定に苦労した。 PSVersion 5.1.14393.2969, Windows Server 2016上のISEで開発。Set-StrictMode -Version latest
書式#,#はダメ $num.ToString(&amp;#39;#,#&amp;#39;) にて$numが0だと「&amp;ldquo;ToString&amp;rdquo; のオーバーロードで、引数の数が &amp;ldquo;1&amp;rdquo; であるものが見つかりません。」と出る。
$num.ToString(&amp;#39;#,0&amp;#39;) とすることで、正しく出力される。
キャスト後のtoString $s_num=&amp;#34;99,999,999,99&amp;#34; の場合に書式指定で出力したい場合、いったんlongにキャストするので
[long]$s_num.ToString(&amp;#34;#,0&amp;#34;) と書くと、同様に「&amp;ldquo;ToString&amp;rdquo; のオーバーロードで、引数の数が &amp;ldquo;1&amp;rdquo; であるものが見つかりません。」とでる。正解は
([long]$s_num).ToString(&amp;#34;#,0&amp;#34;) キャスト演算子よりもToStringの方が優先度が高いのか&amp;hellip;</description>
    </item>
    
    <item>
      <title>.netで利用可能な帳票ツール</title>
      <link>https://blog.tack41.net/posts/2019/06/28_01/</link>
      <pubDate>Fri, 28 Jun 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/06/28_01/</guid>
      <description>内製開発している.net(C#)で利用可能な帳票ツールについて調査した。結論としては、高いお金を出さないとまともなツールは手に入らないということ。 価格はすべて税抜き。
使えるが、高い Create!Form: 1帳票設計ライセンス200,000円、1WindowsServerランタイム400,000円。帳票ツールは使いやすそうで機能も十分そうだが、高い&amp;hellip; Active Reports for .Net 12.0: 1開発ライセンス300,000円、サーバーライセンス(2core)120,000円。Create!Formと同様、機能は十分だが高い&amp;hellip; iTextSharp: 保守されている最新のVer.7(iText)では、ライセンスがAGPLかCommercial License。Commercial Licenseの費用は見積もりを取らないとわからないっぽいが、このサイトによると、1920ポンド(26万程度).. JasperReport: Jaspersoft Studioという設計ツールで設計は簡単そう。.Netから利用しようとすると、Serverを立ててAPI経由での利用だがCommunity ServerのライセンスがAGPLか商用ライセンスの購入が必要。価格は見つけられなかったが、上記製品と同価格帯だろう。&amp;hellip; LibraryはLGPLなのに&amp;hellip; クライアントをJavaで開発するのは、今の自分の開発スキル的につらい、つらすぎる&amp;hellip; 安いが、あまり使えない Reports.net: 1開発ライセンス60,000円、ランタイムは無料。ヘルプ等を見る限り、ヘッダ・フッタやグルーピングという概念がなく、すべての項目を項目名を指定して出力し、ページ送りも自分で行う感じに見える。Excelに自分で出力するのと大差ない。 VB-Report 8: 1開発ライセンス85,000円、ランタイムは無料。Reports.netよりもさらに原始的で、ひな形Excelのセル番号を指定して出力する感じ。ひな形ExcelにClosedXMLあたりで出力したほうが早いやん。 Access: 14,800円。ランタイムは無料。一部内製アプリで使用しているが、 VBAは見捨てられた言語だし、ソースコードはいったんExportする必要があり、かつ元のバイナリには戻せない。開発しづらい。 無料だが、つらい [Microsoft ReportViewer]: Visual Studio Proに添付。どっちにしろうちの開発用途ではCommunityは使えないので。ただ、社内帳票でよくある、1明細が複数行にわたる場合に対応できない。 ClosedXML.Report: 無料。よさそうだが、こちらも、1明細が複数行にわたる場合に対応できないっぽい。 帳票.NET: 無料。最終リリースが2016年。継続性に不安 Excel: 全利用者に配布済みなので追加費用不要。ClosedXML等を利用して普通にセル指定で出力。プログラムで頑張ってセルを指定して出力するか、ひな形にてデータの表示とは別にデータの入力個所をまとめておいてプログラム側の負荷を下げるか、どちらにしてもめんどい。帳票の種類が増えてくるとつらさが増してくる。 まともなツールは1開発者でも300,000円から400,000円程度は最低でも必要なのだろう。が、中小企業においてこの金額はおいそれとは出ない。今後も継続的にバージョンアップする必要があるだろうし。 ひとまず、帳票部分のみAccessで開発、そのAccessを.netプログラムに同梱して帳票部分で呼び出す形にできないか調査、ダメならExcelのひな型をなるべく工夫する。あまりにつらくて上記費用が安いと感じられるようであれば購入を申請する形か。</description>
    </item>
    
    <item>
      <title>Get-ChildItemからのLengthプロパティでのファイル容量取得ではまる</title>
      <link>https://blog.tack41.net/posts/2019/06/25_01/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/06/25_01/</guid>
      <description>PowerShellで特定のフォルダ配下に存在する一定容量以上のファイルをリストアップするスクリプトを作成。
Get-ChildItem -Recurse . | Where-Object{$_.Length -ge 10*1024*1024 } よくあるお題であちこちにサンプルがあるのだが、なぜかLengthプロパティがないというエラーが出る。
色々調べた結果、Set-Strictのversionを2以上にすると発生することが分かった。1の場合には存在しないプロパティでも無視することで動作するようだ。
http://winscript.jp/powershell/131
や
https://stackoverflow.com/questions/44035319/get-childitem-length-is-wrong
によると、対象がdirectoryの場合に配下のFileInfoとDirectoryInfo配列のサイズを返すところ、配下が1つのみの場合だと存在するFileInfo,またはDirectoryInfoのLengthを返そうとするためで、無理やり配列にすればいけるとあるが、ダメ。Directoryに対しては配下にファイルが無くても、何個あってもLengthプロパティへの問い合わせはエラーとなる。PowerShell Ver.5.1.17763.503 on Win10 1809(64bit)で確認。
結論としては、Directoryの中の個数をカウントしてもしょうがないので、対象をファイルのみにすることだった。
Get-ChildItem -Recurse -File . | Where-Object{$_.Length -ge 10*1024*1024 } これであれば、Set-StrictのVersionがlatestでも通る。</description>
    </item>
    
    <item>
      <title>ClosedXMLにて印刷範囲が設定され、「(」を含むシート名を保存するとファイルが壊れる</title>
      <link>https://blog.tack41.net/posts/2019/03/11_01/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/03/11_01/</guid>
      <description>ClosedXML 0.93.1, 0.94.2で確認。
印刷範囲を設定したファイルを開いて、「(」を含むシートを作成して保存すると、ファイルが壊れてしまいExcelでは開けなくなる。 workbook.xmlを見る限り、シート名をシングルクォーテーションでエスケープできていないのが問題のようだ。 再現ケースを確定してIssueに挙げるか。</description>
    </item>
    
    <item>
      <title>Form Load時にRadioButtonのCheckedChangedイベント発生</title>
      <link>https://blog.tack41.net/posts/2019/02/28_02/</link>
      <pubDate>Thu, 28 Feb 2019 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/02/28_02/</guid>
      <description>C# WinFormにてForm Load時にRadioButtonのCheckedChangedイベントが発生する事態に遭遇。 LoadイベントではCheckedをFalseにしているだけだし、他に怪しいイベントも見当たらない。
原因はTabStopが設定された、最小のTabIndexを持つフォームがRadioButtonになっていたため。</description>
    </item>
    
    <item>
      <title>C#でのCollection系オブジェクトの受け渡し指針</title>
      <link>https://blog.tack41.net/posts/2019/02/28_01/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/02/28_01/</guid>
      <description>C#でCollection系オブジェクト(IEnumerable, ICollection, IList等)の受け渡しをどうすべきか悩んでいた。 ListよりIList, EnumerableよりIEnumerableといった実装を含まないInterfaceが好ましいのは当然として、 あらゆるオブジェクトを想定してより抽象的なクラスを選択すべきというのは感覚的にわかるのだが、どうもしっくりこない。
以下の記事を見てなるほどと思った。 https://enterprisecraftsmanship.com/2017/05/24/ienumerable-vs-ireadonlylist/
言語に依存しない一般的な方針としては、Postel’s law.として知られる(初めて知った&amp;hellip;)
be conservative in what you send, be liberal in what you accept, C#における具体的な方針として
prefer IEnumerable when accepting a collection; prefer IReadOnlyList when returning one. 確かに、引数は抽象的な方が使いやすいが、戻り値も抽象的だと結局toListしたりcastしたりしないといけないので使いにくいし、そもそもそんな使い方が正しいとは思えないので違和感があった。
IEnumerable - ICollection - IListという階層関係があるので、引数としてconservativeな(他の継承クラスも受け取れる)IEnumerableがよいというのはそのとおりだろう。 ただ、be liberal であるための解としてIReadOnlyListがあげられているが、これは利用側で内容を変更しないことがはっきりしている場合だろう。変更することが想定する場合はIListを返すべきと思われる。
複数のオブジェクトを格納する際には、IListの実装クラスがほとんどなので、これ以外を考慮する必要はとりあえずないと思われる。 DictionaryやHashtableを使う場合はIDictionaryあたりを返すのが妥当か?</description>
    </item>
    
    <item>
      <title>CentOS 7のRedmine 4.0でrmagick build error.</title>
      <link>https://blog.tack41.net/posts/2019/02/18_01/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/02/18_01/</guid>
      <description>CentOS7のDockerコンテナにてRedmineを構築中にrmagick buildにてエラー発生。 先週は動作したのだが&amp;hellip;
ログを見ると、rmagickのバージョンは3.0.0で要求するImageMagickは6.8.9以上。インストールされているのは6.7.8Q16のためエラーとなっている。
このrmagick3.0.0は2月16日にリリースされたばかりらしい。その際に要求するImageMagickのバージョンが上がったのだろう。
https://rubygems.org/gems/rmagick/
CentOSのリポジトリでは最新でも6.7しかない。remiリポジトリにあるようなのでインストールしたところ、buildエラーがなくなった。
rpm -ivh http://rpms.famillecollet.com/enterprise/remi-release-7.rpm yum -y install ImageMagick6 ImageMagick6-devel --enablerepo=remi </description>
    </item>
    
    <item>
      <title>MS Unit TestにおけるDeploymentItem</title>
      <link>https://blog.tack41.net/posts/2019/01/26_01/</link>
      <pubDate>Sat, 26 Jan 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/01/26_01/</guid>
      <description>MS Unit Testにてテストファイルを配布してテストに利用する方法がようやくわかった。
ファイルをソリューションエクスプローラー上に登録して「出力ディレクトリにコピー」を「常にコピー」あたりにすればファイル名で参照できるのだが、ディレクトリは指定できないし、何よりリリースファイルに含まれてしまう。
https://stackoverflow.com/questions/16787003/deploymentitem-not-deploying-files
にあるとおり、ファイルのパスを指定する際に「....\」を追加したところ、正常に動作するようになった。 第二引数でディレクトリ名を指定すればそのディレクトリにコピーされる。</description>
    </item>
    
    <item>
      <title>Ubuntuでmac方式のIME切り替え</title>
      <link>https://blog.tack41.net/posts/2019/01/16_02/</link>
      <pubDate>Wed, 16 Jan 2019 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/01/16_02/</guid>
      <description>macを使い始めて、IMEの切り替え方式をmac方式に切り替えています。Windows10ではIMEの設定をいじっていますが、近い将来mac方式が標準になるようです。
http://www.itmedia.co.jp/news/articles/1812/26/news094.html
Ubuntu 18.04でも変更することができました。
https://garabakos.sakura.ne.jp/Zlinux/lx061.htm</description>
    </item>
    
    <item>
      <title>C#におけるIEnumerable,IEnumerator</title>
      <link>https://blog.tack41.net/posts/2019/01/16_01/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2019/01/16_01/</guid>
      <description>IEnumerable(IEnumerator)はIListに比べると制約が多く、同じことをやろうとしても面倒、その分汎用性が高い、くらいに思ってました。
実際には、IEnumerableには要素の編集が一切できないのが最も大きな違いだと思います。
https://stackoverflow.com/questions/1210295/how-can-i-add-an-item-to-a-ienumerablet-collection
System.Linqを参照に追加すればIEnumerable.Appendが利用できますが、これはIList.Addとは違い非破壊的メソッドで自身は変更せずに要素を追加した新しいオブジェクトへの参照を返すだけです。 逆に言うと、一度設定したら編集しないCollectionを利用する場合はIEnumerableとして公開すればそとから編集されないことを保証できます。</description>
    </item>
    
    <item>
      <title>Java(Android)のService, Application(Context)</title>
      <link>https://blog.tack41.net/posts/2018/12/02_02/</link>
      <pubDate>Sun, 02 Dec 2018 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/12/02_02/</guid>
      <description>AndroidにてActivityにまたがる処理を行う処理を記述するには、Bound Serviceを使う必要がある。bindeServiceの引数ServiceConnectionのコールバック関数onServiceConnectedにて渡されるIBinderでServiceオブジェクトを取得し、必要なメソッドを実行できる。
SQLiteへの保存処理をこれで行おうと考えたのだが、そのためのSQLiteOpenHelperにはContextが必須となっている。
ServiceはActivity(Contextを継承する)に依存したくないために利用しているので、そのままContextを取得できない。 必要なメソッドの引数に都度Contextを指定する手も無くはないが、メソッドが増えるほど面倒さが増すし、そもそもDatabaseへのconnectの条件としてcontextが必要なので、メソッドの呼び出しの都度Databaseへの再接続が発生してしまう。
ApplicationもContextを継承している。これならどこからでも呼び出せそうだが、Applicationインスタンスを取得するにはActivityのメソッドを呼び出す必要がある&amp;hellip; ということで、Applicationを継承した独自クラスを作成し、Singletonとしてインスタンスを取得すると良いとわかった。よく使われている手法らしい。
http://kazuooooo.hatenablog.com/entry/2015/10/18/200949
これら独自Service, Applicationを利用する際の注意事項として、Application.manifestに宣言をしないといけない。これを忘れるとそれらをインスタンス化できずにnullになってExceptionが発生するが、エラー内容を一見してApplication.manifestが原因だとは判別できない。
Androidの各種メソッド・ライブラリには、この手のContext前提のものが多い。今回のSQLiteのライブラリに関しては内部で呼び出しているFileアクセスがContext前提となっているためのようだ。ただ、それがなぜContext前提にする必要があるかは理解できていない。C#のWPF, UWP関連でも似たような制限があった気がするので、現代的なアプリ開発には必要なセキュリティなどのための必須仕様なのかもしれない。</description>
    </item>
    
    <item>
      <title>AndroidStudioでEmulatorが起動するも接続できない。</title>
      <link>https://blog.tack41.net/posts/2018/12/02_01/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/12/02_01/</guid>
      <description>Android Studio 3.2.1(Windows64)にて、Emulataorが起動するのにアプリが全然起動しない状態になりました。 最下部にandroid waiting for target device to come onlineと表示されたままで変化せず、LogcatのデバイスリストにはにはDisconnectedと表示される状態。
https://stackoverflow.com/questions/42816127/waiting-for-target-device-to-come-online#43187806
のMarkDubyaさんが言うように、adb kill-serverを実行したらアプリが起動し、Logcatにログが出力されるようになった。 Windows 10でのadb.exeはC:\Users\(ユーザー名)\AppData\Local\Android\Sdk\platform-toolsにあった。</description>
    </item>
    
    <item>
      <title>Chromeの自動更新</title>
      <link>https://blog.tack41.net/posts/2018/11/30_02/</link>
      <pubDate>Fri, 30 Nov 2018 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/11/30_02/</guid>
      <description>Chromeの自動更新をADのグループポリシーで行っている。
https://support.google.com/chrome/a/answer/6350036?hl=ja
を参考に設定したが、更新されない。 以下の設定を追加で変更したところ、うまく動作するようになった。
[Google Update]-[Application]-[Google Chrome] Allow installation: 未構成 → 有効 [Google Update]-[Preferences] Auto-update check period override: 1400 → 60 </description>
    </item>
    
    <item>
      <title>Excelでオプションボタン</title>
      <link>https://blog.tack41.net/posts/2018/11/30_01/</link>
      <pubDate>Fri, 30 Nov 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/11/30_01/</guid>
      <description>利用者が使い慣れたExcelでアンケートシートを作ろうとした際のこと。
どれか1つを選択してほしい場合は、オプションボタンを使う。開発タブにあり、フォームコントロールとActiveXの2つがある。
フォームコントロール
フォントの見た目がActiveXと比べればマシ。 グループ化するのに、グループポックスを使用しないといけない。 行や列の追加・削除でグループボックスに入ったり外れたりすると挙動が想定外となる レイアウト上、グループボックスが不要な場合は非表示にしないといけない。が、非表示にするとどこにあったかわからなくなる。 誤ってグループボックスが重なったりするとやはり想定外の挙動となる。 ActiveX
グループ化するのにグループ名を指定できるので、フォームのように想定外の動作をすることはない フォントの見た目がひどい。クリックしたときとそうでないときで大きさが変わる? 項目Aを選択し、項目Bを選択してさらに項目Aを選択&amp;hellip;と繰り返すと、どんどんフォントが大きくなる(致命的) プロパティ上のフォントサイズは変わっておらず、コントロールのサイズを変更すると直る。 当方では2013で発生。MSも認識はしているらしいが、対応作なし&amp;hellip; https://support.microsoft.com/ja-jp/help/417966
ActiveXのフォントが大きくなる不具合は致命的なので、グループボックスの位置に注意しながらフォームコントロールを使うことにした。 どちらの場合もだが、オプションボックスをセル内に収まるようにしないと、セルの追加で配置がずれてしまうので注意。</description>
    </item>
    
    <item>
      <title>NECのEXPRESSSCOREのJavaアプレットが動かない</title>
      <link>https://blog.tack41.net/posts/2018/11/19_01/</link>
      <pubDate>Mon, 19 Nov 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/11/19_01/</guid>
      <description>当社ではNEC製サーバを導入しているのだが、NECサーバではサーバのステータス確認や設定変更にEXPRESSSCOREというWebコンソールが利用できる。 これが、一部機能がJavaアプレットで動く仕様になっている、今時&amp;hellip;
BIOS等の更新が出ているので適用しようと思い、現在のバージョンを確認しようとすると、このアプレットか、サーバを再起動して起動画面で確認するしかない&amp;hellip;
今時Javaアプレットが動くのはIEかSafariくらい。JREは8までしかサポートしない。 Windows 7 のIEでなんとか動かそうとするのだが、反応しない。
通常のブラウザで確認できる画面にsshの項目があり、これを有効にしたところsshでログインできた。ほしいバージョン情報も取得できた。 ただ、このまま開放しとくのも気持ち悪いので、必要なときだけsshを有効にする運用とした。</description>
    </item>
    
    <item>
      <title>MariaDBのON UPDATE CURRENT_TIMESTAMPに対するUPDATEの動作について</title>
      <link>https://blog.tack41.net/posts/2018/11/13_01/</link>
      <pubDate>Tue, 13 Nov 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/11/13_01/</guid>
      <description>リンク先同様、しばらく悩んでしまったのでメモ。
MySQLでON UPDATE CURRENT_TIMESTAMP で更新時にタイムスタンプを自動更新するように設定している場合でも、UPDATE前後で値に変化がなければタイムスタンプは更新されない。
[https://qiita.com/nao_tuboyaki/items/bef44862f6ddffd4f0b5][https://qiita.com/nao_tuboyaki/items/bef44862f6ddffd4f0b5)</description>
    </item>
    
    <item>
      <title>Bootstrapper().Run() 実行時にFileNotFoundException</title>
      <link>https://blog.tack41.net/posts/2018/10/09_01/</link>
      <pubDate>Tue, 09 Oct 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/10/09_01/</guid>
      <description>WPFでPrsimを習得しようと日々格闘中です。
ふとしたタイミングで、Bootstrapper().Run()実行時に
&amp;#34;ファイルまたはアセンブリ &amp;#39;System.Runtime, Version=4.1.2.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a&amp;#39;、 またはその依存関係の 1 つが読み込めませんでした。指定されたファイルが見つかりません。 &amp;#34;:&amp;#34;System.Runtime, Version=4.1.2.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a&amp;#34; なるエラーが表示されて進まなくなってしまいました。 シンプルなShellのみ起動するように修正してもダメ。NuGetですべてのライブラリを一旦アンインストールし、最小限のみとして前に正常に起動した状態に戻してもダメ。
どうやら、app.configとターゲットバージョンにより発生(自分のプロジェクトでは4.7.2)するらしい。
https://github.com/dotnet/standard/issues/567
Workaroundsにあるようにapp.configのdependentAssemblyタグをすべて削除し、ターゲットバージョンを一旦4.0にして再度4.7.2に戻したところエラーが消えて動作するようになった&amp;hellip;</description>
    </item>
    
    <item>
      <title>Visual Studio CodeでMarkdownのPreviewカスタマイズ</title>
      <link>https://blog.tack41.net/posts/2018/10/04_01/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/10/04_01/</guid>
      <description>はまった。
Windows上のVisual Studio CodeでMarkdown Previewをcssでカスタマイズすることがどうしてもできない。指定した cssファイルがないと言われる。
cssを絶対パスでは指定できないことは認識しており、Markdownファイルと同じパスにcssを置き、setting.jsonでファイル名のみ指定してもダメ。各種記事を見てそのままやってみたつもりでもうまく行かない。 markdown-pdf.styles で指定してPDF出力する分には問題ないのだが。
結論としては、ファイルサーバにおいてあるファイルの場合はダメなよう。ネットワークドライブを設定してもダメ。 ローカルに持ってきたら普通に動作した&amp;hellip; 半日無駄にした&amp;hellip; なお、ファイルサーバに置いていると画像も表示されない。Visual Studio CodeのMarkdown編集はファイルサーバ上のファイルとは相性が悪いと認識した。</description>
    </item>
    
    <item>
      <title>WPFのMVVMについて考える</title>
      <link>https://blog.tack41.net/posts/2018/10/01_01/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/10/01_01/</guid>
      <description>最近、Windows FormをやめてWPFのプログラムを書き始めている。
WPFは正直必要となる知識レベルが高く難しいというイメージで手が付けにくかった。今もそうだが。 何が難しいかといえば、MVVMの考え方をどこまで徹底するかに尽きるのではないかと思う。
MVVMについてまだまだ分からないことも多いが、今の認識をまとめる。
MVVMは、ModelとViewの間にViewModelという層を挟み、ModelとViewの依存関係を疎にするモデル WPFの場合、ViewとViewModelの間でデータを複雑なコード不要でやりとりするBindingという機構があるので、うまく記述すればViewとViewModelの間も疎にできる そうすると、Model, ViewModelは変えずにViewだけ差し替えることも可能となる。 Windows Formの場合は、Viewの一部であるコードビハインドに処理もがっつり書いてしまうため、Viewだけ差し替えるということはできず結構な書き換えが必要となる。 Windows Formもそうだが、何も考えずに書くとどうしてもViewに処理を書いて肥大化しがち。そこで、ViewはViewModelの処理の呼び出しのみにする方が良いとされ、コードビハインドには極力コードを書かない方が良いとされる。 逆にViewModel側もViewに依存してしまうと別のViewに差し替えることができなくなるので、Viewに関するコードは書かない方が良いとされる。 MessageBoxのようなダイアログや、別のWindowを直接起動する処理すら良くないとされる。 じゃあどうするんだというと、Blendと言う部品や直接呼び出さずにInterface経由とすることで直接依存を避ける手段を取るべきとされる。これが初心者には超絶難解だと思う。 逆に、上記のようなViewを差し替える事態がそもそも考えなくて良いのであれば、今まで通りコードビハインドにコードを書いても問題はない。それでもWindows Formより洗練された部品が使えるのでメリットはある。 さしあたって、すぐに直面するのはViewModelからMessageBoxのような利用者への通知処理をどう行うか。行いたいのはMessageBoxを出すことではなく利用者にメッセージを伝えることと抽象化し、ShowMessageのようなメソッドをもつInterfaceを定義してこれを利用する形とする方法をとっている。以下のページが参考になった。
http://sourcechord.hatenablog.com/entry/2016/01/23/170753
このパターンは、コンストラクタに引き渡す処理に気をつければViewModelからのViewの呼び出しが簡単にできるため、よく使っています。</description>
    </item>
    
    <item>
      <title>ClosedXMLによるExcel編集がVirusBusterに強制終了させられる</title>
      <link>https://blog.tack41.net/posts/2018/09/14_01/</link>
      <pubDate>Fri, 14 Sep 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/09/14_01/</guid>
      <description>ClosedXMLで、ファイルサーバの雛形ファイルをもとに編集して出力するということをよく行います。 この際、ClosedXMLの保存先がファイルサーバだと、当社のVirus Buster Business SecurityにUnauthorized Encryptionと言われて 強制終了させられることがあります。Excelファイルは作成できず、exeも消されてしまうので再インストールとなります。
テストした結果、ClosedXMLでの保存先がローカルであれば問題ないことが確認できたので、ClosedXMLではローカルに一時フォルダを作成してそこに保存し、System.IO.File.Copyでコピーすることで解消しました。</description>
    </item>
    
    <item>
      <title>うっかりmasterリポジトリでcommit</title>
      <link>https://blog.tack41.net/posts/2018/09/13_02/</link>
      <pubDate>Thu, 13 Sep 2018 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/09/13_02/</guid>
      <description>git管理していて、ローカルリポジトリでブランチ切り忘れてmasterブランチで作業、ローカルcommitまでして気付いた。 このままpushしても、当然リモートのmasterブランチにダイレクトにpushはできず、弾かれる。 PRも出せない、と思っていたが。
pushでは、ローカルとリモートの両方のブランチを指定できる。
git push origin &amp;lt;local_branch&amp;gt;:&amp;lt;remote_branch&amp;gt; local_branchにmaster, remote_branchに本来切ろうと思っていたブランチ名を指定し、そのブランチでPRを出す。</description>
    </item>
    
    <item>
      <title>ClosedXMLでWindows7だけレイアウトが崩れる</title>
      <link>https://blog.tack41.net/posts/2018/09/13_01/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/09/13_01/</guid>
      <description>アホな話です。
ClosedXMLで、一部コードでうっかり以下のようなコード書いてました。
using (IXLWorkbook targetBook = new XLWorkbook(filePath)) { using (IXLWorksheet targetSheet = targetBook.Worksheet(1)) { } targetBook.Save(); } usingの入れ子です。 普通、入れ子になるような階層があれば一番上位のクラスが下位のDispose呼んでくれるっと思いますよね〜。 でも、このときはusing句覚えたてで、とにかく使いたかったんです、using入れ子かっけ〜って思ってたんです&amp;hellip;
症状としては、Windows 7の場合のみシートのフォーマットが崩れます。なぜかWindows 10は大丈夫。OSによって症状が違う理由は不明。 sourceを見ると、XLWorksheetのDisposeでrange情報をクリアしてるっぽいから、そこで情報が消えて、そのまま保存すればそりゃレイアウトは崩れるな〜と。
追記) どうも、最新の0.93.1で発生し、0.92.0では発生しなかったようだ。ライブラリのバージョンアップした途端に大量に問い合わせが&amp;hellip;</description>
    </item>
    
    <item>
      <title>今日のクソVBAコード</title>
      <link>https://blog.tack41.net/posts/2018/09/10_01/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/09/10_01/</guid>
      <description>stDocName = ChrW(xx) &amp;amp; ChrW(yy) &amp;amp; ChrW(zz) &amp;amp; ChrW(abc) &amp;amp; ChrW(def) &amp;amp; ChrW(ghi) &amp;amp; ChrW(jkl) &amp;amp; ChrW(mno) &amp;amp; ChrW(pqr) &amp;amp; ChrW(stu) DoCmd.OpenReport stDocName, acPreview ChrWの引数は実際にはコードが入る。 式の右辺をイミディエイトウィンドウに入力すると、日本語のレポート名が表示される&amp;hellip;
暗号化?なんのために? あとで見る人への嫌がらせか? ちょっと意味がわからない</description>
    </item>
    
    <item>
      <title>CIの導入について検討</title>
      <link>https://blog.tack41.net/posts/2018/08/27_02/</link>
      <pubDate>Mon, 27 Aug 2018 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/08/27_02/</guid>
      <description>一人で開発していても、テストやデプロイにミスが出る可能性はある。 CIの導入を検討した。
結論としては、CI用途のサーバーを別途導入することはしない。現在主に開発しているC#プロジェクトでは、CIにもWindowsが必要となる。ライセンス費用が必要だし、Dockerでお手軽に再構築できる環境としたいため。
やりたいことは以下の通り
リポジトリのPRコードのビルド テスト、結果通知、OKならmerge DBの構成情報に関して、リポジトリと実環境で差異がないかチェック 1,2点目はWindowsを避ける以上、不可能。開発時に自端末でテストを行い、PRのコメントに記載する運用で対応。 3点目は、毎日定時に実行する普通のバッチでなんとかなるレベル。
テストに関して、DBに関連するところは一切やっていない。面倒なので。 一方で内製アプリの殆どはDBのデータを持ってきてそのまま表示し、加工して更新する程度のものがほとんどのため、結果ほとんどテストがない状態。 本番環境に接続する際には専用のクラスを利用しているので、テスト環境用にも同様のクラスを作成し、テスト実行時にはそちらを利用してDB接続するようにしてテストを行うようにする。まずこちらが優先。
Dockerでdumpファイルから空のデータベースを作成するDockerfileを作成し、開発にすぐに利用できるようにする。
その上で、上記の運用で品質をさらに高めていく。</description>
    </item>
    
    <item>
      <title>Docker Container 起動失敗</title>
      <link>https://blog.tack41.net/posts/2018/08/27_01/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/08/27_01/</guid>
      <description>Docker Hostのスタートアップサービスにて、Docker ContainerをBuild, Upするスクリプトを実行しているのですが、以下のようなエラーが大量に発生してUpしていませんでした。
8月 26 03:07:44 sever-name dockerd-current[864]: time=&amp;#34;2018-08-26T03:07:44.615597202+09:00&amp;#34; level=error msg=&amp;#34;could not calculate checksum for \&amp;#34;fb1077f711d4fc436c0b6e115f8cdb0c871f46c818ec998efbf489df5e4a4de5\&amp;#34;, \&amp;#34;devmapper: Unknown device fb1077f711d4fc436c0b6e115f8cdb0c871f46c818ec998efbf489df5e4a4de5\&amp;#34;&amp;#34; ... 8月 26 03:07:44 server-name dockerd-current[864]: time=&amp;#34;2018-08-26T03:07:44.617971873+09:00&amp;#34; level=error msg=&amp;#34;migration failed for 866ae31005298fd6f1bb2944418eb34969b16ead2a18ed332fa011a311f3b4b2, err: open /var/lib/docker/graph/60e65a8e4030022260a4f84166814b2683e1cdfc9725a9c262e90ba9c5ae2332/json: no such file or directory&amp;#34; ... ログの内容を見ると、以下のissueと同じように見える。再起動前にDockerのバージョンが1.13.1-74 に上がったようだし&amp;hellip;
https://github.com/moby/moby/issues/20147
対処方法は記事からは判明せず。
スタートアップスクリプトを手動で実行したところ、普通にupしたので、docker containerが起動していなければスクリプトを再度実行するcronジョブを登録することで暫定対処した。</description>
    </item>
    
    <item>
      <title>Access 2003からMariaDBに移行</title>
      <link>https://blog.tack41.net/posts/2018/08/19_01/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/08/19_01/</guid>
      <description>内製のAccess 2003アプリを、DB部分はMariaDBに移行している。 フロントは.Net(C#)
ツールを使って工数を削減できないかと模索したが、以下のような正攻法で攻めるしかないと言う結論に達した。
Access側のテーブルにて、極力Not Null制約を適用する&amp;hellip; 後述のデータ移行クエリ実行の際、NullがあるとINSERT SELECT 文がこけるため、Nullの場合とそうで無い場合で別クエリを実行する必要が出てくるため。
文字列型は、NULL=空文字と考えて問題ない場合がほとんどと想定されるので、以下の手順を機械的に実行する。
文字列でない場合はNULLを置き換えるべき値が自明でない場合も多いので、一旦NULL値固定で移行し、列ごとに個別で移行(UPDATE DEST.COL=SRC.COL WHERE SRC.COL IS NOT NULL) 対象列の空文字を許可する。 該当列を更新する部分にてNULLの場合は空文字に置き換える処理を追加 画面のフォームがデータと連結していてSQLではなくDoCmdで処理している場合、後付でSQLを組み込むと競合エラーが面倒なので、単純にフォームの値をNz関数でNullを置換してやれば良い ウィザードに従って作成した画面などで、データ更新処理を明示的に記載されていない場合は、フォームの追加・更新前処理イベントにてNz関数を適用する UPDATE文で該当列のNULLを空文字に置換 該当列にNOT NULL制約を適用。 MariaDB側に、同一レイアウトのテーブルを新規作成。参照制約も実装。 MariaDBのODBCドライバをインストールし、対象のMariaDBをODBC登録。 AccessのリンクテーブルとしてMariaDBのテーブルを登録 AccessのテーブルからMariaDBのテーブルにデータを流し込む(INSERT SELECT)クエリを作成、初回の移行を行う。
参照整合性制約から、移行可能な順番がはっきりする。 MariaDBのデータに対してアクセスするフロントプログラムを作成する。 移行後のテーブルレイアウトそのものでプログラムの動作検証が可能。 フロントプログラムの作成が完了したら、MariaDBの全データをTruncateしてデータの本番移行を行う。 データ移行の逆順で実行しても参照整合性制約からデータを削除できない場合がある。素直に参照整合性制約を一時削除し、データの削除完了後に再度作成する。 テーブル名や列名にスペースやマルチバイト文字が入ってて命名規則を満たしていない、明らかに数量データなのに文字列型になっている&amp;hellip;といった問題はこれ以降にじっくりリファクタリングしていく。上記の手順とリファクタリングを同時に行うのはリスクが大きい。</description>
    </item>
    
    <item>
      <title>CentOS7のDocker構築ではまったこと</title>
      <link>https://blog.tack41.net/posts/2018/08/16_01/</link>
      <pubDate>Thu, 16 Aug 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/08/16_01/</guid>
      <description>storage driverがdevice mapperの場合のディスク容量 device mapperの場合は、既定のディスク容量が10GBほどとなる。Oracle DatabaseのDockerコンテナをbuildするとこける。
storage driverを最初からoverlay2 にするための方法 インストール時にデバイスタイプにLVMを指定すると、Dockerのstorage dirverはdevice mapperになる。
https://docs.docker.com/storage/storagedriver/select-storage-driver/#supported-backing-filesystems
基本ディスクを選んで、xfsを選んでやる必要がある。
さらに、CentOS7 1511(minimal)の場合は上記の手順でもやはりdevice mapperが既定となる。overlayを使用するための設定がされていないためと想像される。
https://docs.docker.com/storage/storagedriver/overlayfs-driver/
CentOS7 1804(minimal)で基本ディスク(xfs)でインストールすれば、overlay2がstorage driverとして設定される。</description>
    </item>
    
    <item>
      <title>箱入り娘のプログラムを書いて思う</title>
      <link>https://blog.tack41.net/posts/2018/08/15_01/</link>
      <pubDate>Wed, 15 Aug 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/08/15_01/</guid>
      <description>実家に帰った際に箱入り娘のパズルがあったのでやっていた。
https://ja.m.wikipedia.org/wiki/%E7%AE%B1%E5%85%A5%E3%82%8A%E5%A8%98_(%E3%83%91%E3%82%BA%E3%83%AB)
全然解けなかったが、プログラムで力技で解きたいと思い、やってみた 結論として、解けずに終わった。 Pythonで再帰関数で解こうとして、再帰呼び出しの上限に引っかかって30sほどでエラーとなった。 将棋などと比較すると取ることができる手ににかなりきつい制限があるので、全探索余裕と思ってしまったのだが、完全に間違っていた。 一応、盤面を都度記録し、同じ盤面になったらそれ以上は探索しないようにしたのだが、それでも解空間は大きかった。
まず、再帰による解法の選択について。現代のプログラムにおいては、上限の大きさは違えど再帰呼出の階数には制限がある。ので、対象としている問題で想定される階数に比較してプログラミング言語の制約が十分かどうか判断しなければいけなかった。あるいは、階数をパラメータとして保持しておき、起動時に何階層まで探索するか指定するような形にすればよかった。
再帰ではなく、盤面をメモリかファイルに記録し、都度記録から次の盤面を探してスタックを使用しない形にしても良かった。
そもそも論で行くと、パズルは頭の体操として娯楽としてあるもので、力技で解くことに意味あるのか? というのもある。
今回は、初めてPythonを使って割としっかりとしたプログラムが書けたので、練習として良かったということにした。</description>
    </item>
    
    <item>
      <title>Excelで「このワークシート内にある1つ以上の式の参照に問題が見つかりました」</title>
      <link>https://blog.tack41.net/posts/2018/08/03_01/</link>
      <pubDate>Fri, 03 Aug 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/08/03_01/</guid>
      <description>Excelで解決がとてもめんどくさいエラー。
このワークシート内にある１つ以上の式の参照に問題がみつかりました。数式内のセル参照、範囲名、定義名、および他のブックへのリンクがすべて正しいことをご確認ください。 Excel 2013で発生し、どう考えても参照する箇所がなくなるくらい該当シート、セルを削除しても保存のたびにエラーが出る。
で、一旦保存して終了して開き直すと出なくなることも&amp;hellip; 全てではないのだが、エラー箇所を修正しても保存して開き直すまでエラーが出続けることがあるらしい&amp;hellip; そもそも、エラーを出すのだからそのエラー箇所を素直に指摘してくれよと思うのだが&amp;hellip;</description>
    </item>
    
    <item>
      <title>64bit OSでのレジストリ操作時の注意事項</title>
      <link>https://blog.tack41.net/posts/2018/07/30_03/</link>
      <pubDate>Mon, 30 Jul 2018 02:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/07/30_03/</guid>
      <description>http://tack41tu.hatenablog.com/entry/2018/07/30/214927
でClickOnceアプリをインストールする際にレジストリを編集する必要がある事を書いた。
レジストリエディタで編集するのは面倒だし運用も大変なので、レジストリを編集するアプリを作成した。
https://msdn.microsoft.com/en-us/library/ee308453.aspx
にある以下のコードを書いて実行し、正常終了するのだがレジストリエディタで確認すると変更が反映されておらず、ClickOnceの動作も変わらない。
Microsoft.Win32.RegistryKey key; key = Microsoft.Win32.Registry.LocalMachine.CreateSubKey(&amp;#34;SOFTWARE\\MICROSOFT\\.NETFramework\\Security\\TrustManager\\PromptingLevel&amp;#34;); key.SetValue(&amp;#34;LocalIntranet&amp;#34;, &amp;#34;Enabled&amp;#34;); key.Close(); どうもレジストリは32bit, 64bitで別の領域らしく、プログラム作成時にターゲットCPUをAnyとし、x86優先とした結果、32bitの領域を更新してしまっているらしい。
https://aonasuzutsuki.hatenablog.jp/entry/2015/12/08/173819
を参考に以下のように記載したところ、想定通りに動作するようになった。
Microsoft.Win32.RegistryKey key_base, key; key_base = RegistryKey.OpenBaseKey(RegistryHive.LocalMachine, RegistryView.Registry64); var key = prerKey.CreateSubKey(&amp;#34;SOFTWARE\\MICROSOFT\\.NETFramework\\Security\\TrustManager\\PromptingLevel&amp;#34;,); key.SetValue(&amp;#34;LocalIntranet&amp;#34;, &amp;#34;Enabled&amp;#34;); key.Close(); </description>
    </item>
    
    <item>
      <title>Microsoft Report使用時のビルド時の警告</title>
      <link>https://blog.tack41.net/posts/2018/07/30_02/</link>
      <pubDate>Mon, 30 Jul 2018 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/07/30_02/</guid>
      <description>Visual Studio 2017にてMicrosoft Reportを使用するために、Nugetで[Microsoft Rdlc Report Designer for Visual Studio]をインストールすると、ビルド時に「同じ依存アセンブリの異なるバージョン間での競合が見つかりました。」と警告が表示される。実行自体は問題なくできる。
https://qiita.com/hahifu/items/8dba20cd06fb0c3a9fa7
を参考に出力の詳細レベルを上げて確認すると、ReportのアセンブリがSQLServer.Typesの12.0.0に依存している一方で、NugetでReportインストール時に一緒にインストールされるSQLServer.Typesは14.0.0であるためのようだ&amp;hellip;
依存関係の解消方法が思い付かず、また動作には影響はないため以下のサイトを参考に
https://docs.microsoft.com/ja-jp/dotnet/framework/configure-apps/how-to-enable-and-disable-automatic-binding-redirection
自動バインド リダイレクトを有効化したところ、警告は出なくなった。</description>
    </item>
    
    <item>
      <title>ClickOnceでハマる</title>
      <link>https://blog.tack41.net/posts/2018/07/30_01/</link>
      <pubDate>Mon, 30 Jul 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/07/30_01/</guid>
      <description>C#で開発したクライアントアプリケーションをClickOnceで配布する際にハマった2点
Windows10へのインストール イントラのファイルサーバに置いてある証明書が設定されていないClickOnceをWindows 10で実行すると、「コンピューターにセキュリティ上の問題を発生させるため、管理者がこのアプリケーションをブロックしました。&amp;hellip;」と表示され、[閉じる]ボタンしか表示されないために、インストールができない。 Windows 7では普通にインストールできる。
https://answers.microsoft.com/ja-jp/windows/forum/apps_windows_10-winapps-appscat_tools/%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC/45f6621c-35ca-4395-bdd4-685705e9fae0
にあるレジストリの[LocaIntranet]の値をEnabledにする必要があった。 設定変更は直ちに反映される(OS再起動は不要)
関連アセンブリの添付 上記をクリアしたうえでClickOnceを公開し、クライアントで実行すると以下のエラーが表示される。
このアプリケーションをインストールまたは実行できません。このアプリケーションでは、まずグローバルアセンブリキャッシュ(GAC)にアセンブリ Microsoft.**** バージョン *** をインストールする必要があります。 ****にはVisualStudio関連のアセンブリ各種が出力される。Visual Studio 2017 Express Desktopの時は発生しなかったのだが、2017 Professionalにしたら発生した。 どうも必要なアセンブリ(.dll)を添付できていないようで、事例は異なるが、
http://thinkami.hatenablog.com/entry/2014/09/09/062440
にあるように公開設定で全てのアセンブリを「必須コンポーネント(自動)」→「含む」に変更すると解消した。</description>
    </item>
    
    <item>
      <title>実行順序に依存する複数LINQ実行時の遅延評価による副作用</title>
      <link>https://blog.tack41.net/posts/2018/07/19_01/</link>
      <pubDate>Thu, 19 Jul 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/07/19_01/</guid>
      <description>例えば、LINQ1にて元データよりデータを抽出し、これをデータセット1とする。 次に、LINQ2にて、元データからデータセット1を除いたデータセットに対して抽出し、これをデータセット2とする。 これをLINQ3にて、元データからデータセット1とデータセット2を除いたデータセットに対して抽出し、これをデータ・セット3とする。 &amp;hellip;.
上記のような処理を1メソッドで行う。 後続のLINQで除外するために、除外するためのデータセットを例えばListとして保持する。
LINQ2はLINQ1の結果が決まらないと決まらない。LINQ3はLINQ2, LINQ1の結果が決まらないと決まらない。だが、後続のLINQに対して結果を伝えるのは(LINQとは無関係の)Listオブジェクト。
このような場合に、上記LINQを順番にコードで記載したとしても、除外Listの値は後続に伝わらない(ことがある?)。おそらく、プログラムの動作として最初にLINQ3の結果を参照した場合にLINQ1,LINQ2の結果を行ってから、という動きはしてくれず、結果、空の除外Listに対してLINQ3を実行してしまっているためと思われる。
遅延されるのが問題なので、LINQの実行結果 IEnumerable型のオブジェクトに対してToList()を実行してやれば即時に確定してこのような副作用は発生しなくなる。遅延評価のメリットは当然なくなるが。</description>
    </item>
    
    <item>
      <title>C#でExcelのバージョンに依存しないCOM経由での操作</title>
      <link>https://blog.tack41.net/posts/2018/07/04_01/</link>
      <pubDate>Wed, 04 Jul 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/07/04_01/</guid>
      <description>C#での社内プログラムでExcelを操作する際、大部分はClosedXMLを利用しているのだが、ActiveXを使用しているなどでうまく動作しない場合にはCOM経由で操作している。
Visual Studioで参照ツリーにExcelのCOM参照を追加するのだが、その時点でPCにインストールされているOfficeのバージョンに対応したCOMを追加する形になる。
ビルド時に参照ツリーにあるCOMを参照するため、参照追加時のPCとビルド時のPCでインストールされているOfficeのバージョンが異なると、ビルド時に警告、またはエラーとなる。
参照追加時には2013、ビルド時に2016だったためにビルド時に警告が出て、そのまま実行すると該当箇所でRuntime Errorでコケる事象が発生した。 社内には、今後2013, 2016が混在する予定のため、どちらかだけしか対応できないとなると困るので、対応方法を調査した。
参照ツリーに追加して開発する形式を事前バインディング、実行時にCOMの名前から該当のCOMを参照する形式を遅延(動的)バインディングというらしい。
事前バインディング Visual StudioでCOMオブジェクトの仕様を把握しているため、補完が効いて開発効率が高い 型情報なども取得済みでコンパイルするため、実行速度は遅延バインディングと比較して速い 使用するOfficeのバージョンを指定する必要がある。 遅延バインディング 使用するOfficeのバージョンを指定する必要がない Visual Studioでの補完は効かず、各オブジェクト、メソッドの情報を調べながら呼び出す必要がある。大変。 実行時に型チェックを行うため、遅い。実行時エラーが出る可能性も。 遅延バインディングは、各メソッドをInvokeMemberで引数を調査しながら呼び出す必要があり、とても大変。以下のサイトにこの大変さをWrapするコードが公開されていた。
https://zenmai.wordpress.com/2011/06/24/excel%E3%81%AE%E5%8F%82%E7%85%A7%E3%82%92%E8%BF%BD%E5%8A%A0%E3%81%9B%E3%81%9A%E3%81%ABexcel%E3%82%92%E4%BD%BF%E3%81%86c/
とても素晴らしいのでぜひ利用しようと考えたのだが、(当然ながら)COMオブジェクトのすべてが実装されているわけではないので不足個所を追加実装する必要があり、結構大幅な追加が必要と思われた。
で、たどり着いたのがこちらの記事。
https://teratail.com/questions/109579
なんと、dynamicという宣言に変更するだけで、ビルド時のチェックはやめて実行時に動的に呼び出してくれるとのこと。 (COMオブジェクトの生成部分は固有の書き方への変更が必要)。素晴らしい!!
実際にdyamicに変更したところ、WorkbookオブジェクトへのReleaseComObject呼び出し時にエラーが発生。
http://hiro-syumi.ldblog.jp/archives/36511362.html
こちらの記事を参照させてもらってエラー箇所のみobject型へのキャスト処理を追加したところ、問題なく動作するようになった。
このdynamicの利用だが、最初からこれを前提に行うと上記の通りVisualStudioによるサポートが効かないので開発効率はかなり落ちると思われる。今回のようにCOM参照を追加して事前バインディングで実装したうえで、dynamicに書き換えるという形が効率が良いと感じた。</description>
    </item>
    
    <item>
      <title>Windows 2016でプログラムが起動しない</title>
      <link>https://blog.tack41.net/posts/2018/05/15_01/</link>
      <pubDate>Tue, 15 May 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/05/15_01/</guid>
      <description>当社で利用している手形管理のシステムにて、辞書の更新をしようとしたところ、なぜかexeをクリックしても起動しない症状が発生した。
イベントログにて、以下のような内容が出力されている
ProviderName : Microsoft-Windows-Immersive-Shell Id : 5973 Message : アプリ Microsoft.Windows.Apprep.ChxApp_cw5n1h2txyewy:App.AppXc99k5qnnsvxj5szemm7fp3g7y08we5vm.mca のライセンス認証がエラーで失敗しました: このアプリは、ビルトイン Administrator ではアクティブ化できません。。詳しくは、Microsoft-Windows-TWinUI/Operational ログをご覧ください。 ググっては見たが、
https://support.microsoft.com/ja-jp/help/3064045/windows-store-apps-may-not-open-and-event-id-5973-is-logged-in-the-app
のように、ストアアプリを開くときの権限の問題しかヒットしない。 エクスプローラーからダブルクリックしているのだが、ひょっとしてストアアプリ起動と認識されてしまっているのかも、と思いコマンドプロンプトで起動したところ正常に起動した。
Windows 2016の不具合なのだろうか?</description>
    </item>
    
    <item>
      <title>thinクライアントとして使える古いPCの限界</title>
      <link>https://blog.tack41.net/posts/2018/05/03_01/</link>
      <pubDate>Thu, 03 May 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/05/03_01/</guid>
      <description>手元に、使わなくなったノートPCが2台あったため、Windowsにリモート接続するthinクライアントとして利用してみた。 1台はメモリ512MB, もう一台は768MBでPAE非対応というところからスペックはお察し&amp;hellip;
Linuxを探したのだが、2018/5現在、PAE非対応という時点でインストールできるディストリビューションはかなり限られる。 2,3年前はOKだったLubuntu,XubuntuですらNG。 PuppyLinuxは日本語サイトは情報が古かったため本家を見たが、PAEまたはUEFI必須のようだ&amp;hellip; 今回はKona LinuxのLightをインストールした。
時間はかかったがインストールは成功、最初からRemminaがインストールされていたためRDP接続もできた。 &amp;hellip;が、遅い。キーボードの入力が画面に反映されるのにワンテンポ、タイミングによっては数秒遅れるため、作業が止まってしまう。 さすがに、この程度のスペックでは、Thinクライアントにはスペック不足ということのようだ。10年前にはストレスなく動作したはずなので、kernelが重くなったのか、Remminaが軽くないのか、RDPの通信量がそもそも少なくないのか&amp;hellip;
少なくともメモリは2GB、CPUは2つ以上、要は無印のKona Linuxがインストールできるくらいのスペックがないと再利用すらできないことを実感した。</description>
    </item>
    
    <item>
      <title>GitBookでフッターを変更する方法、目次にページ数を記載する方法がわからない</title>
      <link>https://blog.tack41.net/posts/2018/04/17_01/</link>
      <pubDate>Tue, 17 Apr 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/04/17_01/</guid>
      <description>最近、マニュアル等を単体ではmarkdown、複数文書をまとめる必要がある場合はGitBookで作成している。
GitBookで出版、のような記事も見受けられるため、かなりのことができるのかと思っていたのだが、タイトルにある以下の2件がどうしても解決できない
フッターのカスタマイズ([現ページ]/[総ページ数]のような表示) 目次でページ数を表示 1点目は、book.jsonにカスタマイズを加える方法、
https://qiita.com/nutti/items/96e7194c82b8d04382e2
及び、_layouts/ebook/pdf_footer.htmlを作成する方法
https://github.com/GitbookIO/gitbook/issues/1661
いずれもフッターは変更できなかった。
2点目は、ページ数が表示されてほしいところになぜか1.1のような表示がされてしまい、GitHubで掲載されている、表示自体を消す方法しか見つからなかった。
https://github.com/GitbookIO/gitbook/issues/1223</description>
    </item>
    
    <item>
      <title>Windows 2016のWindows Update</title>
      <link>https://blog.tack41.net/posts/2018/03/16_01/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/03/16_01/</guid>
      <description>今年に入って稼働を始めたWindows Server 2016で、原因不明の再起動が発生。 Hyper-Vホストでも発生するため、ゲストOSが未起動の状態で朝を迎え、利用者から問い合わせを受けていた。
原因はタイトルの通り。 信じられないのだが、Windows 2016ではどのように設定しても一度Windows Updateを動かすとactive hourの後で勝手に再起動するらしい&amp;hellip;
https://social.technet.microsoft.com/Forums/Lync/en-US/d6cde72c-80a5-418b-9a49-8a604e35d41b/windows-server-2016-automatically-restart?forum=ws2016
上記記事の最後に、荒っぽいタスクを30分おきに起動して再起動を止める、というworkaroundが紹介されていた。
Command: schtasks Arguments: /change /tn \Microsoft\Windows\UpdateOrchestrator\Reboot /DISABLE うちはそれほど社員数もおらず、夜間にサーバー使えないと困るという人はいないので再起動は止めず、再起動後にゲストOSを自動起動するよう設定した。 併せて、以下の記事を参考に再起動後にメール、LINE通知するようにした。
http://kokura.hatenadiary.jp/entry/2018/02/01/145500
改めて、Windows奥が深い</description>
    </item>
    
    <item>
      <title>特定PCから特定サーバのみホスト名でUNCアクセスできない</title>
      <link>https://blog.tack41.net/posts/2018/03/12_01/</link>
      <pubDate>Mon, 12 Mar 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/03/12_01/</guid>
      <description>社内情シスには常について回る、ファイルサーバーアクセスできない問題。 私も過去何度も経験しているし、WINS, SMBなどの知識もあるのでそんなに悩むことはここのところありませんでした。
しかし、今回は様子が異なり、以下のような症状。
\\SVRNAME でアクセスできない。 \\SVRNAME.domain.name のようなFQDNでもダメ 他のサーバに対しての\\SVRNAME2 のアクセスは可能。ダメなのは1台のサーバのみ(?) ping SVRNAME は通る(!?) \\IPアドレス であれば該当のサーバでもアクセスできる NetBIOS over TCP/IPは有効になっている %WINDIR%\system32\drivers\etc にあるhosts, lmhosts にエントリはない 上から見ていって、1,2番目まではよくあるNetBIOSの名前解決エラーかと思ったのだが、3,4番目あたりからどうも様子が違う&amp;hellip;
結果は、Windowsのコンパネ-[ユーザーアカウント]-[資格情報マネージャ]に、サーバー名で認証情報が登録されており、指定されたアカウントが無効となっていたため。 こんなところで指定しなくてもADログインすれば自動で認証するので、登録情報を削除したところアクセス可能となった。
Windows は奥が深い #いい意味ではない</description>
    </item>
    
    <item>
      <title>COM経由でのExcel操作は地獄?</title>
      <link>https://blog.tack41.net/posts/2018/02/24_01/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/02/24_01/</guid>
      <description>VBAでExcelを操作するプログラムをC#に移行。 印刷に使用するActiveXオブジェクトを含む雛形ファイルを対象とするため、Managedな操作をするClosedXMLやNPOIではうまく動作せず、Interop.Excel経由で行った。
ClosedXML等と比較して圧倒的に動作が遅いのは当然として、シートをある程度(10枚以上?)コピーするとtmpファイルを書き込めない旨のエラーが発生する。 タイミングは実施するたびに違い、運が良ければエラーが発生しないこともある。
同様のエラーを探したが、結論としてはエラー時にリトライする処理を追加するくらいしかないらしい&amp;hellip;
https://answers.microsoft.com/ja-jp/msoffice/forum/msoffice_excel-mso_winother-mso_2010/vba%E3%81%A7%E3%82%B7%E3%83%BC%E3%83%88%E3%82%B3/b8b84a3e-d1f8-48a5-8623-04023c8510e8
こういった対処方法は、仕方ないとしても凹みますね。 機会があればネックとなっているActiveXオブジェクトをManagedな操作で置き換えていきたい。</description>
    </item>
    
    <item>
      <title>AccessにOleDbアクセス時、日付型のパラメータを使用する場合は型を明示する必要あり</title>
      <link>https://blog.tack41.net/posts/2018/02/20_01/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/02/20_01/</guid>
      <description>はまった&amp;hellip; Accessのときのみ発生。
Parameterを使う際、通常、設定した値の型からよきにはからって処理してくれるが、AccessでDateTime、特に時刻部分が設定されている場合ではエラーとなる。
http://yan-note.blogspot.jp/2008/08/systemdatacommondbparameteraccessdate.html</description>
    </item>
    
    <item>
      <title>C#でのDbTransaction.Rollback</title>
      <link>https://blog.tack41.net/posts/2018/02/02_01/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/02/02_01/</guid>
      <description>C#のTransactionにて、DbTransactionをusing句で使えば、Disposeの際にRollbackされるので、明示的なRollbackが不要とあったのだが、どうもそのように記載しているサイトのほうが少ないように見える。
MSDNで確認したところ、そうあるべきではるが、ベンダー依存のため前提とするのはだめらしい。
Dispose should rollback the transaction. However, the behavior of Dispose is provider specific, and should not replace calling Rollback. https://msdn.microsoft.com/ja-jp/library/bf2cw321(v=vs.110).aspx
SqlTransactionだけならいいかもしれないが、OleDb(Access)やMySQLも共通化している今のコードでは駄目なようだ。try catch使うしかない。
https://msdn.microsoft.com/ja-jp/library/system.data.idbtransaction.rollback(v=vs.110).aspx</description>
    </item>
    
    <item>
      <title>iPad(9.7)でMicrosoft Remote Desktop使用時の注意事項</title>
      <link>https://blog.tack41.net/posts/2018/01/27_01/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/01/27_01/</guid>
      <description>会社で支給されたiPad Pro 9.7inchで、Microsoft Remote Desktopを利用してWindows 10にアクセスしたところ、その後Windows10にローカルアクセスした際に英語キーボードの設定になっていた。
iPad Pro 9.7inchはSmartKeyboardを使用していて、英語キーボードしかないモデル。おそらくこの設定をMicrosoft Remote Desktopが設定してくれたのだろう。 賢いと言えば賢いのだが&amp;hellip;
Windows 10の設定を見ても日本語キーボードとなっている。一旦英語キーボードに変えようとするとサインアウトを促されるので、キーボードレイアウトの変更はサインアウトをしないと反映されないのだろう。 今回も一旦再起動することで日本語キーボードに戻った。</description>
    </item>
    
    <item>
      <title>redmineのwikiにおけるhtmlのサポート</title>
      <link>https://blog.tack41.net/posts/2018/01/25_01/</link>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/01/25_01/</guid>
      <description>redmineで、markdown形式を使っていると、文字に色を付ける方法がない。 セキュリティの観点から、あえてすべてのhtmlタグをフィルタしているようだ&amp;hellip;
http://www.redmine.org/issues/20497
社内で運用している場合にセキュリティを気にして表現力が落ちてもしょうがないので、管理画面で切り替えるなどできるといいのだが&amp;hellip; 以下のサイトを参考に設定ファイルを直接書き換え、利用できるようになった。
http://redmine.jp/faq/wiki/use-html-tag-in-wiki/</description>
    </item>
    
    <item>
      <title>DockerのHostの設定変更のcontainerへの反映</title>
      <link>https://blog.tack41.net/posts/2018/01/21_02/</link>
      <pubDate>Sun, 21 Jan 2018 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/01/21_02/</guid>
      <description>Host側でのresolv.confを変更したのだが、containerには、docker-compose restartやstop -&amp;gt; startでは反映されない。 一度downしてからupする必要がある。</description>
    </item>
    
    <item>
      <title>AccessでのYes/No型を外部結合してGroupByすると「カレントレコードがありません」</title>
      <link>https://blog.tack41.net/posts/2018/01/21_01/</link>
      <pubDate>Sun, 21 Jan 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/01/21_01/</guid>
      <description>タイトルの通り。
Accessで、OLEDB経由でもAccessで直接クエリをたたいても「カレントレコードがありません」と表示されるエラーに遭遇し、SQLを切り分けたところ、Yes/No型のフィールドが原因と判明。 ググってみると、Yes/No型を外部結合してGroupByすると、Nullが発生した場合に処理できず、このようなエラーが出るらしい。
https://www.pcreview.co.uk/threads/no-current-record-error-in-group-by-query-with-outer-joins-solution.2126293/
対処法は、リンク先にある通り、SELECT、GROUP BYの双方をNzでNullの場合の値を指定すること。
OLEDB接続の場合はNz関数が利用できないので、IIfとIsNullを組み合わせる。
Access嫌だ&amp;hellip;</description>
    </item>
    
    <item>
      <title>RTX1200でL2TP,IPSECによるVPN接続</title>
      <link>https://blog.tack41.net/posts/2018/01/14_01/</link>
      <pubDate>Sun, 14 Jan 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/01/14_01/</guid>
      <description>RTX1200でL2TP,IPSECによるVPN接続を行った。
iOS11(iPhone 7, iPad Pro 1st)では問題なく接続できるのだが、Android, Windows, Linux(Ubuntu)はことごとくダメだった。Windowsはそもそも保証対象外と明記されているらしいのだが、iOSがつながるのならAndroidもつながっても良いと思うのだが&amp;hellip;
Ubuntuの事例として、あわしろさんの記事を見つけたので、これを参考に再チャレンジしようと思う。</description>
    </item>
    
    <item>
      <title>iPhoneのすばらしさに気づく(いまさら)</title>
      <link>https://blog.tack41.net/posts/2018/01/11_01/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/01/11_01/</guid>
      <description>今日は有給をとって近くをドライブした。 Web+DBでYahooマップの記事があったので、ナビを使ってみようと思ったのだ。
そもそもにしてYahooマップとYahooナビは別アプリなのだが&amp;hellip;
手持ちのNexus5Xで試した。アプリの機能としては問題ないと思うのだが&amp;hellip; それよりもバッテリーのヘリが気になってしまう。充電しながら使っているのだが、それでも2,30分で10%は減る。これでは、そもそも長距離ドライブには使えない。ナビなんて長距離でしか使わないのに&amp;hellip;
で、会社で支給されているiPhone7にGoogle Mapを入れてナビを使ってみたところ、充電中は電池が減らないどころか、少しずつ充電されてる!!! iPhone使ってる人や、バッテリの持ちの良いAndroid使ってる人なら当然かもしれないが、その世界を知らない僕はふつうに驚いた。
やはり、Androidスマホと比較するとiPhoneは素晴らしいと。今回はバッテリーでその点に気付いたが、社内のスマホに関する障害の問い合わせもiPhoneよりAndroidの方が圧倒的に多い。
それも当然で、AndroidとiPhoneでは1機種にかける開発・保守費用が全然違う。Androidの代表としてGoogleのPixelを参照したとしても1桁どころか2,3桁は違うのではないだろうか。 ソフトウェアと違ってハードウェアはかけた金額が性能により効いてくると思う。正直Appleにばかり儲けさせるのは気に食わないという気持ちもあるが、価格以上の性能、信頼性があるのだと実感する。 この構造は、独禁法などで介入でもされない限り今後も当面変わらないのではないか。
今後は、Androidでしかないアプリがあるとか、ハードも含めてガンガンいじって開発したいとかでなければiPhoneを薦めたいと思う。公私ともに。 自分はAndroidが好きなので使うが、割り切って安いモデルを2年間使い倒すのが、今のAndroidには合っていると思われる。iPhoneのように長く使うには向いていない。</description>
    </item>
    
    <item>
      <title>zabbix share のtemplteは素晴らしい</title>
      <link>https://blog.tack41.net/posts/2018/01/10_01/</link>
      <pubDate>Wed, 10 Jan 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/01/10_01/</guid>
      <description>社内にて、NAS(Buffalo Terastation)、UPS(APC)の切替を行った。 社内の機器の監視はzabbixで行っており、これらの設定をする際、Zabbix Share のテンプレートが使えたのは非常にありがたかった。
Terastationは3.2用のテンプレートだったが、社内では3.0を運用しているためバージョンの指定を変更後、mokeblogさんのエントリを参考に不要なタグを削除してインポートした。 APCは2.0用だったが、バージョンの指定を変更するだけでインポートできた。(電圧上限、下弦の閾値は200V前提となっていたため、下限:190-&amp;gt;90,上限250-&amp;gt;120に修正した)
これらのSNMP MIBを調べて設定するのは時間がかかるので、こういうのが公開されているのは時間がない管理者としてはありがたい。細かいところを自社に合わせて修正して利用しようと思う。</description>
    </item>
    
    <item>
      <title>ファイルサーバーの移行</title>
      <link>https://blog.tack41.net/posts/2018/01/08_01/</link>
      <pubDate>Mon, 08 Jan 2018 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2018/01/08_01/</guid>
      <description>以下の要件で、ファイルサーバーの移行を行った。
移行元サーバー: Windows Server 2008 R2 (Enterprise) 移行先サーバー: Windows Server 2016 (Standard) 移行容量: 150GB程度 移行に使用した方法: Windows Server移行ツール 結果は、権限はNTFS、共有のものも含めて完璧に移行できた。移行後は既に公開設定が済んだ状態となっていた。 時間は8時間ちょっとかかった。複数の対象フォルダがあったため、Powershellでのバッチを作成して両方で動作させたため、つきっきりだったわけではない。
移行は2段階で行い、最初に10GBほどのフォルダの移行を行った。この移行では暗号化を行うのだが、これによるCPUの負荷が大きいことに気付き、2段階目ではCPUを2-&amp;gt;4に増強した(共にHyper-V上のVM)。 2段階目において、Trend Micro Business Securityのスキャンが開始されたことに気付いたのだが、管理者権限で停止しようとしても受け付けてもらえず、結局アンインストールすることで停止するしかなかった。その間1.5時間ほどメモリ、ディスクIOがかなり高い状態だった。
上記の問題がなかったとしても6-7時間はかかったと思われる。容量に対してあまりに時間がかかりすぎている。同ツールでは移行後に権限だけ付け直す「-Include Share」オプションがあるようなので、robocopyでファイルだけ移行し、「-Include Share」オプションで権限を移行する方法が最も時間をかけずに確実に移行できたのではないかと思う。</description>
    </item>
    
    <item>
      <title>テーブル定義の移行でよく使う方法</title>
      <link>https://blog.tack41.net/posts/2017/11/30_01/</link>
      <pubDate>Thu, 30 Nov 2017 10:51:34 +0000</pubDate>
      
      <guid>https://blog.tack41.net/posts/2017/11/30_01/</guid>
      <description>社内DBを試行錯誤しているため、DB間データ移行の前段としてテーブル定義をコピーしたいことがある。 大抵のDBでは無料でもツールが充実しており、ODBCライブラリを入れればよっぽど問題ないと思うのだが&amp;hellip;
MySQL &amp;hellip; Workbench Oracle &amp;hellip; SQL Developer SQL Server &amp;hellip; SQL Server Management Studio(SSMS) Windows 10 Pro 64bitで、SSMSからOracleにアクセスしようとしたところ、どうにもエラーでうまく行かない。64bitのInstant Client + ODBCをインストールし、OSのODBC管理ツールでテスト接続は成功しているのだが&amp;hellip;
で、こういう時はAccessでODBC経由でリンクを貼る分にはまず失敗しない。この状態でテーブルをAccessにテーブル定義のみコピーし、そのAccessのテーブルをSSMSでインポートするとうまくいく。</description>
    </item>
    
    <item>
      <title>redmine, zabbixのActive Directory(LDAP)認証</title>
      <link>https://blog.tack41.net/posts/2017/11/24_01/</link>
      <pubDate>Fri, 24 Nov 2017 13:11:09 +0000</pubDate>
      
      <guid>https://blog.tack41.net/posts/2017/11/24_01/</guid>
      <description>redmine, zabbix共にActive DirectoryのLDAP機能を利用して認証の統合ができる。が、設定方法が引っかかった。
redmineはアカウントごとに認証方式の設定が可能。「管理」の「LDAP認証」にAD認証の設定をしたうえで、AD認証したいアカウントを作成して認証方法をADと指定してやればよい。
一方、zabbixは認証方法を変えるとそれが全ユーザーに適用される。ユーザーグループごとに認証方式が指定できるのだが、既定では「デフォルト」となっている。 認証を変えると、この「デフォルト」の認証方式が変わるので、結果として全ユーザーグループの認証方式が変更されてしまう。なので、「Zabbix administrators」グループの認証方式を事前にローカルに変更しておく必要がある。
だが、インストール時に作成される管理者アカウントでログインした状態だと、この「Zabbix administrators」グループの認証方式を変更できない。自分、及び自分のプライマリグループに関する情報は変更できないらしい。なので、別のユーザーグループを作成し、そこに所属するアカウントを作成。アカウントに「Zabbix特権管理者」権限を付与。そのアカウントでログインして「Zabbix administrators」グループの認証方式を「Zabbixデータベース内のユーザー情報」に変更する、という手順を踏む必要がある。 zabbixめんどい。</description>
    </item>
    
    <item>
      <title>ClosedXMLの画像追加におけるWorksheetの取り扱いについて</title>
      <link>https://blog.tack41.net/posts/2017/11/07_01/</link>
      <pubDate>Tue, 07 Nov 2017 10:20:41 +0000</pubDate>
      
      <guid>https://blog.tack41.net/posts/2017/11/07_01/</guid>
      <description>C#でClosedXMLを使用してExcelに画像を追加する処理をしていた際、なぜかWorkbookの保存時にObjectDisposedExceptionが発生するという事態になりました。
以下のようなコードです
using (XLWorkbook wb = new XLWorkbook(filePath)) { IXLWorksheet ws_src = wb.Worksheet(&amp;#34;Template&amp;#34;); using (IXLWorksheet ws = ws_src.CopyTo(&amp;#34;1&amp;#34;)) { var image = ws.AddPicture(imagePath1); image.MoveTo(ws.Cell(3, 3).Address); image.Scale(.5); image = ws.AddPicture(imagePath2); image.MoveTo(ws.Cell(20, 3).Address); image.Scale(2); } using (IXLWorksheet ws = ws_src.CopyTo(&amp;#34;2&amp;#34;)) { var image = ws.AddPicture(imagePath3); image.MoveTo(ws.Cell(3, 3).Address); image.Scale(.5); } ws_src.Delete(); wb.Save(); } wb.Save() を実行すると例外が発生します。imageの処理をコメントアウトするとエラーは発生しません。
結論として、Worksheetを割り当てるusing句を外したところ、正常に動作するようになりました。エラー調査の際にOpenXMLのコードもちらっと見たのですが、おそらく画像を追加する際にいったんWorksheetの情報を更新して再割り当てするような処理が必要となります。usingを使っていると再割り当てができないのでエラーになったのではないかと。
ただ、エラー箇所がusing句の中ではなく、Saveを実行した場所というのはよくわからないのですが&amp;hellip; 再割り当てできない状態で内部変数をいろいろいじくって、それをファイルに保存する際にそれが検知されてエラーとなる、とかではないかと。
ClosedXMLのサンプルコードを見ていると、Workbookにusing句を使用するものはあるが、Worksheetに使用するものはほとんどない。WorkbookのDisposeで配下のすべてのリソースが解放されるので不要なのだろう。上記書き方が一般的ではないのかも。</description>
    </item>
    
    <item>
      <title>MySQL Workbenchに切り替え</title>
      <link>https://blog.tack41.net/posts/2017/10/19_02/</link>
      <pubDate>Thu, 19 Oct 2017 19:18:47 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2017/10/19_02/</guid>
      <description>前回の記事で、HeidiSQLがうまく動作しない(DEFAULT CURRENT_TIMESTAMPを表示できない)件で、クライアントをMySQL Workbenchに切り替えた。
実は以前も試していたのだが、ホスト名のみで指定した場合に、Test Connectionは成功するのに実際に接続する際にエラーで落ちてしまっていて中止していた。IPアドレスで指定したところ正常に動作したので、こちらに切り替えることにした。</description>
    </item>
    
    <item>
      <title>HeidiSQLがDEFAULT CURRENT句を認識しない</title>
      <link>https://blog.tack41.net/posts/2017/10/19_01/</link>
      <pubDate>Thu, 19 Oct 2017 16:45:52 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2017/10/19_01/</guid>
      <description>社内データベースをMariaDBで構築しており、Windows 10からHeidiSQLにてアクセスしているのだが、TIMESTAMP型の列にDEFAULT CURRENT_TIMESTAMP を設定すると、更新は成功するのだが、画面上表示されない。コメントまで表示されなくなる。
値が設定されていないわけではなく、
show full columns from テーブル名 で確認するとちゃんと設定されているので、別画面で確認しながら進めないといけない。めんどい。
OS: Windows Server 2008 R2 SP1 MariaDB: 10.2.9 HeidiSQL: 9.4.0.5125 本家のForumを見ると、2件同様の報告が上がっているが、コメントがついていない。 別のツールに切り替えるか。</description>
    </item>
    
    <item>
      <title>.Netプログラムの配布</title>
      <link>https://blog.tack41.net/posts/2017/10/12_01/</link>
      <pubDate>Thu, 12 Oct 2017 17:52:37 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2017/10/12_01/</guid>
      <description>今さら、とは思われるとは思いますが&amp;hellip;
当社の社内システムは、外部業者に保守を依頼している販売管理システムとパッケージの会計システムを除いて、はほぼAccessでした。データもファイルに含んでいるタイプ。 なので、各自ファイルをデスクトップにコピーするとデータが共有できなくなるので、ファイルサーバにファイルを置いて、各自が直接実行する形で利用していました。たまに動作がおかしくなったのは、同時起動でファイルが壊れたりしたのではないかと思ってます。
現在、社内システムをC# + RDBMS(SQL Server, MariaDB)に移行中。 上記の感覚で、C#のプログラムは、dllも含めてファイルサーバに置いて、各自直接実行してもらってました。さすがに動作がおかしくなることはないのですが、dllも含めて手動で配置しないといけないとか、ファイルサーバの場所を忘れると実行できないとか、いまいちだな～と思ってました。
そう、ClickOnce。 プロジェクトの設定にて「発行」の項目でファイルサーバを指定して発行すれば、インストーラが生成され、それをインストールしてもらえば以降はスタートメニューから起動可能。バージョンアップ時の更新も勝手に検知してやってくれる。最高!!
10年遅れ? でMicrosoftさんの素晴らしさを実感しました。</description>
    </item>
    
    <item>
      <title>MariaDBからSQL Serverを直接参照するテーブルを作成</title>
      <link>https://blog.tack41.net/posts/2017/10/10_01/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2017/10/10_01/</guid>
      <description>概要 Windows上のMariaDBからSQL Serverを直接参照するテーブルを作成します。Accessのリンクテーブル。 Connect Storageという機能を利用します。
経緯 社内データの保管に、以下の理由でSQL Serverを利用していました。
ODBCを設定せずにExcelから参照できる。 Windows認証を利用できるので、アプリで認証を考慮する必要がない。 後者に関しては、エラー時の対応等、逆にややこしくなりそうでメリットにならないと判断。ただ、前者を利用した、簡易BIとしてのExcelピボットテーブルファイルが利用されているため、うまく対応する必要がありました。
将来性を考えると、10GBに制限されるSQL Server Express Editionは避けたいところ。そこで、まずMariaDBサーバを立ててSQL Serverのデータを参照する形で運用を開始することにしました。
MariaDBには、異種データベースを参照するConnect Storage Engineという機能があることが分かり、これを利用して実装しました。
前提 OS: Windows Server 2008 R2 Maria DB: 10.2.9 SQL Server: SQL Server 2008 R2 Express Edition データベース名: DBTEST DBユーザー名: USERTEST, パスワード: PASSTEST テーブル名: TABLETEST 手順 管理ツールの「データソース(ODBC)」にて、SQL ServerへのDSNを登録(DSN名を「SQLSVR」とする)
MariaDBにmysqlクライアントで接続し、以下のコマンドでConnect Storage Engineを有効化する。
INSTALL SONAME &amp;#39;ha_connect&amp;#39; 以下のコマンドでConnect Storage Engine経由での参照を利用したテーブルエントリを作成する。
CREATE TABLE TABLETEST ENGINE=CONNECT DEFAULT CHARSET=cp932 TABLE_TYPE=ODBC CONNECTION=&amp;#39;DSN=SQLSVR;UID=USERTEST;PWD=PASSTEST&amp;#39;; 問題点 上記手順だと、該当のデータベースの一覧(show tables)まではできるが、内容を取得(select * from &amp;hellip;)できない。 SELECTしか必要ない場合においても、全データベースに対する全操作の権限(grant all on .</description>
    </item>
    
    <item>
      <title>Dockerでstorageにoverlayを使う際の注意事項(2016/2時点,CentOS7)</title>
      <link>https://blog.tack41.net/posts/2016/02/09_02/</link>
      <pubDate>Tue, 09 Feb 2016 02:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2016/02/09_02/</guid>
      <description>Dockerでstorage driverにoverlayを使ってはまったこと。
2016/2時点 CentOS7でのdocker(1.8.2)においては、コンテナのファイルが2GBを超えると、読み込めなくなるようだ。
mariadbにて、dumpファイルの取り込みまでは問題ないのだが、これを一旦停止し、再度立ち上げようとすると「27: File too large」というメッセージが出て起動できない。 ググってみたところ、どうもこのメッセージはMariaDBというよりもOSが出しているようだ。そのことに気づいてoverlayをdevicemapperに戻したところ、現象は発生しなくなった。
開発者サイドでも、まだoverlayは何が起こるかわからない、というスタンスらしいので、要注意。</description>
    </item>
    
    <item>
      <title>Dockerでのmysql利用時の注意</title>
      <link>https://blog.tack41.net/posts/2016/02/09_01/</link>
      <pubDate>Tue, 09 Feb 2016 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2016/02/09_01/</guid>
      <description>Dockerでmysqlを利用する際にはまったこと。
Dockerfile等で初期データを流し込みたい場合、mysqld_safeを「バックグラウンド」で起動しておいてmysqlコマンドで流しこみを行うのだが、
nohup mysqld_safe &amp;amp; mysql -u root &amp;lt; init.sql のように実行してしまうと、 mysqlサーバが起動する前にコマンドが帰ってきてしまうため2行目で「mysql.sockがない」という旨のエラーが返ってきてしまう。
このような場合、1行目の後に以下のようなループを噛ませるとうまく行くはず。(bashの場合)
nohup mysqld_safe &amp;amp; for {1..10}; do if [ -e /var/lib/mysql/mysql.sock ]; then break fi sleep 1 done </description>
    </item>
    
    <item>
      <title>VPSのCentOS7にRails環境構築</title>
      <link>https://blog.tack41.net/posts/2015/08/09_01/</link>
      <pubDate>Sun, 09 Aug 2015 00:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2015/08/09_01/</guid>
      <description>さくらのVPS上にCentOS7.0でRails環境を構築したのでそのメモ。 一般ユーザーにて、必要に応じてsudoをかませて実行。
ユーティリティプログラムをインストール git clone https://github.com/sstephenson/rbenv.git ~/.rbenv git clone https://github.com/sstephenson/ruby-build.git ~/.rbenv/plugins/ruby-build echo &amp;#39;export PATH=&amp;#34;$HOME/.rbenv/bin:$PATH&amp;#34;&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile echo &amp;#39;eval &amp;#34;$(rbenv init -)&amp;#34;&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile exec $SHELL 必要なパッケージのインストール $ sudo yum install libffi-devel zlib zlib-devel openssl openssl-devel readline-devel sqlite-devel ruby 2.2.0をインストール rbenv install 2.2.0 rbenv global 2.2.0 railsをインストール gem update --system gem install --no-ri --no-rdoc rails gem install bundler rbenv rehash rails -v 動作確認 rails s -b 0.0.0.0 </description>
    </item>
    
    <item>
      <title>ESXi 5.1.0上でWin2012 Hyper-Vがインストールできない</title>
      <link>https://blog.tack41.net/posts/2013/05/06_01/</link>
      <pubDate>Mon, 06 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.tack41.net/posts/2013/05/06_01/</guid>
      <description>VMware ESXi .5.1.0上で検証目的のためにWindows 2012 StandardをインストールしてHyper-Vの役割を追加しようとすると「すでにインストールされています」と表示されてしまう。VMware Toolsをアンインストールしてもだめ。
そういうもんなんかなぁ。
ESXi on VMware Playerは昔動いた記憶があるんだけど、Hyper-V on ESXiは無理なのか?</description>
    </item>
    
    <item>
      <title>FreeNAS8.3.1でiSCSI target</title>
      <link>https://blog.tack41.net/posts/2013/05/04_01/</link>
      <pubDate>Sat, 04 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.tack41.net/posts/2013/05/04_01/</guid>
      <description>オープンソースでiSCSIターゲットを実装可能なFreeNASを利用し、Windows 2012より利用する。
1. 初期設定 FreeNAS 8.3.1のインストール CPU: i5 2405S 1c MEM: 1GB Disk1: 30GB(OS Install) Disk2 :10GB(iSCSI Volume) CUIにてNWアドレスを設定 2. iSCSI targetの設定 WebUIにてアクセス ボリュームの追加 [Volume]-[Volume Manager]にてボリュームを追加する。 上段[Servies]-[Core]にてiSCSIをオンにする
iSCSIポータルの設定
[iSCSI]-[ポータル]を選択し、アクセス制限を設定する(ここではオールOKとした)
Initiatorの許可
[iSCSI]-[Initiator]で接続元のInitiatorを制限する(下図では制限なし)
ポータルの追加
[iSCSI]-[Portal]を選択し、ポータルを追加する(下図では全アクセスを許可)
Initiatorの設定
[iSCSI]-[Initiators]よりInitiatorのアクセス制限をかける。下図では制限なし。 ターゲットの追加
[iSCSI]-[Targets]を開き、[Add Target]ボタンをクリック
すべて入力して[OK]をクリック。 ターゲットにエクステントを追加
[iSCSI]-[Associated Targets]を開き、[Add Extend to Target]をクリックする
これまで入力した内容を入力する
WindowsやLinuxのiSCSI initiatorから接続できることを確認。 </description>
    </item>
    
    <item>
      <title>Windows Server 2012でiSCSI target (2)initiator側</title>
      <link>https://blog.tack41.net/posts/2013/04/19_02/</link>
      <pubDate>Fri, 19 Apr 2013 02:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2013/04/19_02/</guid>
      <description>[管理ツール]-[iSCSIイニシエーター]を起動 初回はサービス起動確認のダイアログが表示されるので[はい]をクリック
[ターゲット]にiSCSI TargetサーバのIPアドレスを入力して[クイック接続]をクリック
Targetが認識されているのを確認し、[完了]をクリックする。
[ディスクの管理]にて作成したディスクが認識されていることを確認する。</description>
    </item>
    
    <item>
      <title>Windows Server 2012でiSCSI target (1)target側</title>
      <link>https://blog.tack41.net/posts/2013/04/19_01/</link>
      <pubDate>Fri, 19 Apr 2013 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2013/04/19_01/</guid>
      <description>iSCSI target, initiator共にWindows Server 2012(Full)
[iSCSI target]
[ローカルサーバー]-[管理]-[役割と機能の追加]を選択
[次へ]をクリック
[役割ベースまたは機能ベースのインストール]を選択
自身のサーバを選択
[ファイルサービスおよび記憶域サービス]-[ファイルサービスおよびiSCSIサービス]-[iSCSIターゲットサーバー]、[iSCSIターゲット記憶域プロバイダー]を選択
機能は追加せずに[次へ]をクリック
[インストール]を選択
[閉じる]を選択
サーバマネージャーに戻り、[ファイルサービスと記憶域…]を選択
[iSCSI]を選択
[タスク]-[新しいiSCSI仮想ディスク]を選択
ディスクを作成するボリュームを選択し、「次へ」をクリック。
適当な名前を入力し、次へをクリック
割り当て容量を入力し、次へをクリック
[新しいiSCSIターゲット]を選択
適当な名前を入力し、[次へ]をクリック。
[追加]をクリック
iSCSI initiatorの情報を入力
必要に応じてCHAP, リバースCHAPを有効にする
[作成]をクリックして完了する
正常に作成されたのを確認し、[閉じる]をクリック。</description>
    </item>
    
    <item>
      <title>FreeNAS(8.3.0)にてCIFS設定</title>
      <link>https://blog.tack41.net/posts/2012/12/11_01/</link>
      <pubDate>Tue, 11 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.tack41.net/posts/2012/12/11_01/</guid>
      <description>任意のユーザーにアクセス許可を与える場合 CDにてインストール 初回起動後、コンソールにてIPアドレス、DNSを設定 Webコンソールにて[Storage]-[Active Volumes]-[Volume Manager]を選択
対象のボリュームを選択し、必要な情報を入力して[Add Volume]をクリック
[Storage]にて先ほど作成した「Volume1」にて[Change Permissions]をクリック。
Owner(user/group)にて適切な所有者を指定する。今回は全ユーザーに許可を与えるためnobodyをOwnerに指定している。
[Shares]-[Windows(CIFS)]-[Add Windows(CIFS) Share]をクリック。
必要な情報を入力する。ポイントは以下の通り。 [Path]には前で作成したボリューム(/mnt/Volume1)を入力する。 以下のチェックボックスにチェックを入れる。 Browsable to Network Clients Allow Guests Access Only Allow Guest Access CIFSサービスを起動するかどうか確認ダイアログが表示されるので、Yesをクリックする。
[Services]にて[CIFS]が[ON]になっていることを確認し、右にあるスパナのアイコンをクリックする。
CIFSの各種設定を行う。ポイントは以下の通り。 Authentication Modelは「Local User」を指定する。「Anonymous」を指定するとファイルを作成できるが変更・削除ができなくなる。 DOS charsetは「CP932」を指定。 上記以外はデフォルトのまま
Explorerにて上記で作成したフォルダが見えることを確認。
ファイルやフォルダを作成できることを確認。 特定ユーザーにアクセス許可を与える場合 (上記任意のユーザーにアクセス許可を与える作業は実施済みとする)
[Account]-[Users]-[Add User]にてアクセス許可を与えるユーザーを作成する。 [Shares]-[Windows(CIFS)]にて作成済みの共有フォルダの[Edit]ボタンをクリックする。
最下部の「Allow Guest Access」「Only Allow Guest Access」のチェックを外して[OK]ボタンをクリックする。
[Services]にてCIFSサービスを再起動する。 エクスプローラにて該当フォルダにアクセスすると認証ダイアログが表示される。
ID欄には「(ワークグループ名)\(ユーザー名)」の形で入力する。
アクセスが許可され、任意のファイル、フォルダを作成できることを確認する。</description>
    </item>
    
    <item>
      <title>Ubuntu12.10でHulu</title>
      <link>https://blog.tack41.net/posts/2012/12/03_01/</link>
      <pubDate>Mon, 03 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.tack41.net/posts/2012/12/03_01/</guid>
      <description>Ubuntu12.10 64bitにてHuluの字幕が文字化けする。
ネットで検索してフォント関連をインストールしてみたがうまく行かない。
同様の現象に悩んでいる人もいるようだ…
http://solvedmyquestions.blogspot.jp/2012/11/ubuntu-hulu.html</description>
    </item>
    
    <item>
      <title>Ubuntu 12.10でkvm</title>
      <link>https://blog.tack41.net/posts/2012/12/02_01/</link>
      <pubDate>Sun, 02 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.tack41.net/posts/2012/12/02_01/</guid>
      <description>以下を参照。
http://blog.livedoor.jp/shota_soga_/archives/3527400.html
sudo apt-get install kvm qemu-kvm libvirt-bin virt-viewer virt-manager sudo modprobe kvm sudo service libvirt-bin start sudo virt-manager sudo virt-manager 引き続き、他のPCと同じNW環境にするためのブリッジ設定。
http://tipspc.blogspot.jp/2011/09/qemu-kvm-ubuntu-debian.html NetworkManagerを削除 sudo apt-get remove network-manager &amp;ldquo;/etc/network/interfaces&amp;quot;を以下のとおり編集。 auto lo iface lo inet loopback auto eth0 iface eth0 inet manual auto br0 iface br0 inet dhcp bridge_ports eth0 bridge_maxwait 0 bridge_fd 0 bridge_stp off </description>
    </item>
    
    <item>
      <title>Ubuntu12.10の初期設定</title>
      <link>https://blog.tack41.net/posts/2012/11/29_02/</link>
      <pubDate>Thu, 29 Nov 2012 02:00:00 +0000</pubDate>
      
      <guid>https://blog.tack41.net/posts/2012/11/29_02/</guid>
      <description>下記参照。 http://ubuntuapps.blog67.fc2.com/blog-entry-446.html
ipv6の無効化 /etc/sysctl.confの最終行に以下のコメントを追加
net.ipv6.conf.all.disable_ipv6 = 1 OS再起動
ファイアウォールを有効にし、ssh, vncを許可
sudo ufw enable sudo ufw default DENY sudo ufw allow 22 sudo ufw allow 5900 sudo ufw status </description>
    </item>
    
    <item>
      <title>VMware, Hyper-V, kvm(&#43;VirtualBox)のトリプルブート</title>
      <link>https://blog.tack41.net/posts/2012/11/29_01/</link>
      <pubDate>Thu, 29 Nov 2012 01:00:00 +0000</pubDate>
      
      <guid>https://blog.tack41.net/posts/2012/11/29_01/</guid>
      <description>VMware, Hyper-V, kvm(+VirtualBox)のトリプルブート環境構築時のメモ。 HDD構成は以下を想定、HDDは2TBを使用。
HDD1: VMware ESXi 5.1 (2TB) HDD2: Hyper-V Server (1TB) kvm(+Virtual Box) (1TB) ブートローダは
USBメモリ-VMware HDD2-grub(Hyper-V/Linux) 通常はUSBメモリよりVMwareをブート。Hyper-V or Linuxブートの際にはUSBメモリを抜き、画面よりどちらかを選択する。
VMware ESXi 5.1.0をUSBメモリにインストール datastoreにHDD1を追加。当初以下のエラーが表示されていた
これは日本語化によるバグらしく、起動時に「-locale en_US」とつけることで回避可能。
Hyper-V Server 2012のインストール
ディスクの指定でHDD1の半分程度を指定する。この時点で、 デフォルトでHyper-Vが起動 BIOSにてHDD2を指定するとVMwareが起動
という状態。ただ、Hyper-VにWindows7で管理するための設定が難しく、ブートはするが使用できない状態… CentOS 6.3のインストール
HDD1の後半の空き領域をインストール先に指定し、デフォルトのブートデバイスとしてHDD2を指定。インストールオプションは「Virtual Host」を指定。
CUIで起動する。VirtualBoxはGUIがないと操作できないので以下のインストールを実施。 yum groupinstall &amp;#34;X Window System&amp;#34; yum groupinstall &amp;#34;Desktop&amp;#34; yum groupinstall &amp;#34;General Purpose Desktop&amp;#34; grubではvmwareに対してはディスクを「(hd1)」と指定する。 Virtual Box
kernel-devel, gccをインストール後、ホームページよりCentOS6用のrppmをダウンロードしてインストール </description>
    </item>
    
    <item>
      <title>Adempiereインストール</title>
      <link>https://blog.tack41.net/posts/2012/4/01_01/</link>
      <pubDate>Sun, 01 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.tack41.net/posts/2012/4/01_01/</guid>
      <description>CentOS6.2にAdempiereインストール
[前提条件]
CentOS 6.2(x86_64) JDK1.6.0u31 Adempiere 3.6.0J_CE PostgreSQL管理者 postgres/postgrespw Adempiere用DBユーザ adempiere/adempierepw Adempiereインストールパス /opt/Adempiere3.6.0J_CE/ AdempiereKeystoreインストールパス /opt/Adempiere3.6.0J_CE/keystore Adempiere Keystore パスワード adempierekeypw CentOS6.2 インストール(Minimal) PostgreSQLインストール yum install postgresql-server PostgreSQL初期化 service postgresql initdb service postgresql start chkconfig postgresql on PostgreSQL接続設定 service postgresql stop vi /var/lib/pgsql/data/pg_hba.conf ----- local all all trust host all all 127.0.0.1/32 trust host all all ::1/128 trust ----- vi /var/lib/pgsql/data/postgresql.conf ----- listen_address = &amp;#39;*&amp;#39; port = 5432 ----- service postgresql start PostgreSQLユーザ設定 psql --u postgres ----- postgres=#ALTER USER postgres encrypted password &amp;#39;postgrespw&amp;#39;; postgres=#CREATE DATABASE adempiere; postgres=#CREATE USER adempiere WITH ENCRYPTED PASSWORD &amp;#39;adempierepw&amp;#39;; postgres=#\q ----- JDKインストール bash jdk-6u31-linux-x64-rpm.</description>
    </item>
    
    <item>
      <title>Androidフォンをひかり電話の子機化、VPN接続で屋外でも家電(いえでん)</title>
      <link>https://blog.tack41.net/posts/2012/1/28_02/</link>
      <pubDate>Sat, 28 Jan 2012 02:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2012/1/28_02/</guid>
      <description>ネットと同時にひかり電話をひいていたこともあり、興味があって手持ちのAndroidフォン(HTC Evo Wimax)を子機化し、さらにVPNで自宅外でも家電をかけられるように設定した。
SIPサーバに接続するネットワークと、PPPoE経由で外部と接続する家庭内ネットワークがどうしても別々となり、VPNで内部に入った際にSIPサーバに接続できない(一般にSIPクライアントはNAT超えができない)のがネックになりそうだったが、以下の記事を参考にこの2つのネットワークを入り口が2つある同一ネットワークとすることで希望を満たすことができた。
http://musemd.at.webry.info/201107/article_1.html
ONUからの線を分岐させるためのハブが別途必要となる。</description>
    </item>
    
    <item>
      <title>Oracle 11g Express EditionをCentOSにインストール</title>
      <link>https://blog.tack41.net/posts/2012/1/28_01/</link>
      <pubDate>Sat, 28 Jan 2012 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2012/1/28_01/</guid>
      <description>インストール要件は以下のURLを参照。
http://docs.oracle.com/cd/E17781_01/install.112/e18802/toc.htm#autoId3
CentOS5.2にインストールする(vault.centos.orgより)。
CentOSインストール Desktop - GNOME Server Firewall無効 SELinux無効
※swapを2006MB以上確保しないとoracleインストールチェックで弾かれるので注意 更新適用、再起動 yum update reboot 必要なパッケージがインストールされていることを確認 rpm -qa | grep -E &amp;#39;glibc|make|binutils|gcc|libaio&amp;#39; VMWare Toolsインストール、再起動 Oracleインストール unzip oracle-xe-11.2.0-1.0.x86_64.rpm.zip rpm -ivh oracle-xe-11.2.0-1.0.x86_64.rpm 環境変数設定 cd /u01/app/oracle/product/11.2.0/xe/bin . ./oracle_env.sh bashrcに以下の行を追加 . /u01/app/oracle/product/11.2.0/xe/bin/oracle_env.sh リモートアクセスを可能にする sqlplus system SQL&amp;gt; EXEC DBMS_XDB.SETLISTENERLOCALACCESS(FALSE); </description>
    </item>
    
    <item>
      <title>SCOM ワークグループ環境でのエージェントインストール手順</title>
      <link>https://blog.tack41.net/posts/2012/1/09_04/</link>
      <pubDate>Mon, 09 Jan 2012 04:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2012/1/09_04/</guid>
      <description>スタンドアロンルート証明局を立てて行う。 エンタープライズ証明局の場合は、後述の手順が追加で必要となる。
A. Workgroup環境のコンピュータにAgentを登録する手順 &amp;lt;管理サーバー&amp;gt;
(1)-(a) CA に証明書を要求する。 (2)-(b) 保留中の証明書要求を承認する。 (3)-(c) 証明書を取得する。 (* 4)-(d) 証明書のエクスポート &amp;lt;エージェントインストール対象のサーバー&amp;gt;
(5)-(e) 証明書チェーンをインストールする (6)-(f) 信頼されたルート証明書をローカルコンピュータにコピーする (7)-(a) CA に証明書を要求する。 (8)-(b) 保留中の証明書要求を承認する。 (9)-(c) 証明書を取得する。 (10)-(d) 証明書のエクスポート &amp;lt;管理サーバー&amp;gt;
(11)-(g) MOMCertImport を使用して証明書をインポートする &amp;lt;エージェントインストール対象のサーバー&amp;gt;
(12)-(g) MOMCertImport を使用して証明書をインポートする (a) CA に証明書を要求する。 証明書をインストールするコンピュータ (管理サーバーやエージェントインストール対象のサーバー) にログオンする。 Internet Explorer を起動し、証明書サービスのホスト コンピュータ (http://&amp;lt;サーバー名&amp;gt;/certsrv など) に接続する。 [Microsoft 証明書サービス] ページで [証明書を要求する] をクリックする。 [証明書の要求] ページで [証明書の要求の詳細設定] をクリックする。 [証明書の要求の詳細設定] ページで [この CA への要求を作成し送信する。] をクリックする。 [証明書の要求の詳細設定] ページで次の処理を行う。 [識別情報] の [名前] フィールドに、証明書の要求対象のコンピュータ(管理サーバーやエージェントインストール対象のサーバー) の完全修飾ドメイン名 (FQDN) を入力します。残りのフィールドに、適切な情報を入力する。</description>
    </item>
    
    <item>
      <title>SCOM クラスタ環境の監視について</title>
      <link>https://blog.tack41.net/posts/2012/1/09_03/</link>
      <pubDate>Mon, 09 Jan 2012 03:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2012/1/09_03/</guid>
      <description>クラスタ環境で仮想ホストの監視を行う場合、エージェントプロキシを有効にする必要がある。
エージェントプロキシを有効にすると、監視対象ホスト一覧に仮想ホストも表示されるようになる。</description>
    </item>
    
    <item>
      <title>SCOM レポートスケジュールのバグ</title>
      <link>https://blog.tack41.net/posts/2012/1/09_02/</link>
      <pubDate>Mon, 09 Jan 2012 02:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2012/1/09_02/</guid>
      <description>SQL Server 2008のバグにより、レポートのスケジュール機能が動作しない場合がある。
Scheduled reports that you create by using SQL Server 2008 Reporting Services (SSRS) do not display chart data in System Center Operations Manager 2007 R2
対策 SQL Server の稼動しているコンピューターに、管理者権限のあるユーザーでログイン エクスプローラで以下のフォルダを開きます。Reporting Services フォルダは、SQL Server Reporting Services のインストールフォルダにある
¥Reporting Services¥ReportServer¥bin 開いたフォルダにある ReportingServicesService.exe.config をコピーし (バックアップ)、メモ帳で開く 下記の内容を、&amp;lt;dependentAssembly&amp;gt; と &amp;lt;/dependentAssembly&amp;gt; に囲まれた部分に追加する &amp;lt;assemblyIdentity name=&amp;#34;Microsoft.ReportingServices.ProcessingCore&amp;#34; publicKeyToken=&amp;#34;89845dcd8080cc91&amp;#34; culture=&amp;#34;neutral&amp;#34; /&amp;gt; &amp;lt;bindingRedirect oldVersion=&amp;#34;9.0.242.0&amp;#34; newVersion=&amp;#34;10.0.0.0&amp;#34; /&amp;gt; &amp;lt;/dependentAssembly&amp;gt; &amp;lt;dependentAssembly xmlns=&amp;#34;urn:schemas-microsoft-com:asm.v1&amp;#34;&amp;gt; &amp;lt;assemblyIdentity name=&amp;#34;Microsoft.ReportingServices.ProcessingCore&amp;#34; publicKeyToken=&amp;#34;89845dcd8080cc91&amp;#34; culture=&amp;#34;neutral&amp;#34; /&amp;gt; &amp;lt;bindingRedirect oldVersion=&amp;#34;9.0.242.0&amp;#34; newVersion=&amp;#34;10.0.0.0&amp;#34; /&amp;gt; 変更を保存して、ファイルを閉じる SQL Server Reporting Services を再起動する </description>
    </item>
    
    <item>
      <title>SCOM 2007 R2 インストール手順</title>
      <link>https://blog.tack41.net/posts/2012/1/09_01/</link>
      <pubDate>Mon, 09 Jan 2012 01:00:00 +0900</pubDate>
      
      <guid>https://blog.tack41.net/posts/2012/1/09_01/</guid>
      <description>Windows Server 2008 R2 Enterpriseを前提とする。
ドメイン参加 SQL Server 2008のインストール
Windows Server 2008 R2ではSQL Server 2008をインストールする際はService Pack1移行の適用が必要となるため、以下のURLを参考にスリップストリームインストールを行う。 新規スタンドアロン データベースエンジンサービス, Reporting Services, 管理ツール - 基本, 完全 ネイティブモードの既存の構成をインストールする
※ SQL Server 2008 R2をインストールする場合、SCOMインストール時に下記URLにあるとおり手動作業が必要となる。 http://engineer-memo.com/blogs/engineer-memo/archive/2010/10/27/sql-server-2008-r2-opsmgr.aspx 役割の追加にて「Webサーバ(IIS)」をインストールし、以下のURLにあるとおり、以下の項目を有効にする。
http://support.microsoft.com/kb/973451/ja [役割サービス] ページで、[HTTP 基本機能] を展開し、以下のチェック ボックスをオンにします。 [静的なコンテンツ] [既定のドキュメント] [ディレクトリの参照] [HTTP エラー] [HTTP リダイレクション] [アプリケーション開発] を展開し、以下のチェック ボックスをオンにします。 [ASP.NET] [.NET 拡張性] [ASP] [ISAPI 拡張] [ISAPI フィルタ]
注 : 必要な役割サービスを追加するように求めるメッセージが表示されたら、[OK] をクリックします。 [状態と診断] を展開し、以下のチェック ボックスをオンにします。 [HTTP ログ] [要求の監視] [セキュリティ] を展開し、以下のチェック ボックスをオンにします。 [Windows 認証] [要求フィルタ] [管理ツール] を展開し、以下のチェック ボックスをオンにします。 [IIS 管理コンソール] [IIS 6 管理互換] さらに [IIS 6 管理互換] を展開し、以下のチェック ボックスをオンにします。 [IIS 6 メタベース互換] [IIS 6 WMI 互換] [IIS 6 スクリプトツール] [IIS 6 管理コンソール] ASP.</description>
    </item>
    
  </channel>
</rss>
